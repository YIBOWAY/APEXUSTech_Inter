{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599f119b",
   "metadata": {},
   "source": [
    "# ä¸€ä½“åŒ–é‡åŒ–å›æµ‹æ¡†æ¶ - é˜¶æ®µä¸€ä¼˜åŒ–ç‰ˆ\n",
    "\n",
    "## ğŸ¯ é¡¹ç›®æ¦‚è¿°\n",
    "åŸºäºäº‹ä»¶é©±åŠ¨æ¶æ„çš„ä¸“ä¸šæœŸè´§æ—¥å†ä»·å·®ç­–ç•¥å›æµ‹æ¡†æ¶ï¼Œç°å·²è¿›å…¥ç»“æ„ä¼˜åŒ–å’ŒåŠŸèƒ½å¢å¼ºé˜¶æ®µã€‚\n",
    "\n",
    "## ğŸ“‹ ä¼˜åŒ–è®¡åˆ’è¿›åº¦\n",
    "- âœ… **é˜¶æ®µä¸€**: Notebookç»“æ„ä¼˜åŒ–ä¸ä»£ç å°è£… (å½“å‰é˜¶æ®µ)\n",
    "  - [x] é€»è¾‘åˆ†åŒºé‡æ„\n",
    "  - [x] é›†ä¸­å‚æ•°é…ç½®\n",
    "  - [ ] å¼ºå¤§åˆçº¦å±•æœŸç®¡ç†å™¨\n",
    "  - [ ] ç²¾ç»†åŒ–äº¤æ˜“æˆæœ¬æ¨¡å‹\n",
    "- â³ **é˜¶æ®µäºŒ**: ç­–ç•¥ä¼˜åŒ–ä¸åŠ¨æ€é£é™©è°ƒæ•´\n",
    "- â³ **é˜¶æ®µä¸‰**: å‚æ•°ä¼˜åŒ–ä¸å‹åŠ›æµ‹è¯•  \n",
    "- â³ **é˜¶æ®µå››**: æŠ•èµ„ç»„åˆçº§é£é™©ç®¡ç†\n",
    "- â³ **é˜¶æ®µäº”**: é«˜çº§æ€§èƒ½åˆ†æä¸å½’å› \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793cf5c",
   "metadata": {},
   "source": [
    "## 1. é…ç½®ä¸­å¿ƒ (Configuration Center)\n",
    "é›†ä¸­ç®¡ç†æ‰€æœ‰å›æµ‹å‚æ•°ï¼Œå®ç°ä¸€å¤„ä¿®æ”¹ã€å…¨å±€ç”Ÿæ•ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52835ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é…ç½®ä¸­å¿ƒåˆå§‹åŒ–å®Œæˆ\n",
      "   â€¢ æ•°æ®æ–‡ä»¶: demo_spread_data.csv\n",
      "   â€¢ åˆå§‹èµ„é‡‘: $500,000\n",
      "   â€¢ ç­–ç•¥å‚æ•°: å›çœ‹30å¤©, Z-scoreé˜ˆå€¼Â±1.5\n",
      "   â€¢ äº¤æ˜“æˆæœ¬: ä½£é‡‘$5.0/æ‰‹, æ»‘ç‚¹0.01\n",
      "   â€¢ è¾“å‡ºç›®å½•: backtest_results\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, Optional\n",
    "import os\n",
    "from datetime import datetime, date\n",
    "\n",
    "@dataclass\n",
    "class BacktestConfig:\n",
    "    \"\"\"é›†ä¸­çš„å›æµ‹é…ç½®ç®¡ç†å™¨\"\"\"\n",
    "    \n",
    "    # === æ•°æ®é…ç½® ===\n",
    "    data_path: str = \"demo_spread_data.csv\"\n",
    "    symbols: list = None\n",
    "    start_date: Optional[date] = None\n",
    "    end_date: Optional[date] = None\n",
    "    \n",
    "    # === ç­–ç•¥å‚æ•° ===\n",
    "    strategy_name: str = \"CalendarSpreadZScore\"\n",
    "    lookback_window: int = 30\n",
    "    z_threshold: float = 1.5\n",
    "    exit_z_threshold: float = 0.5\n",
    "    \n",
    "    # === é£é™©ç®¡ç†å‚æ•° ===\n",
    "    initial_capital: float = 500000.0\n",
    "    position_size: int = 10  # åŸºç¡€æ‰‹æ•°\n",
    "    max_positions: int = 5   # æœ€å¤§åŒæ—¶æŒä»“æ•°\n",
    "    \n",
    "    # === äº¤æ˜“æˆæœ¬å‚æ•° ===\n",
    "    commission_per_trade: float = 5.0  # æ¯æ‰‹ä½£é‡‘\n",
    "    slippage_per_trade: float = 0.01   # æ»‘ç‚¹ (ä»·æ ¼å•ä½)\n",
    "    commission_type: str = \"fixed\"     # \"fixed\" æˆ– \"percentage\"\n",
    "    commission_rate: float = 0.0001    # æŒ‰æ¯”ä¾‹æ”¶å–æ—¶çš„è´¹ç‡\n",
    "    \n",
    "    # === åˆçº¦å±•æœŸå‚æ•° ===\n",
    "    rollover_method: str = \"panama_canal\"  # \"panama_canal\" æˆ– \"ratio_adjustment\"\n",
    "    rollover_calendar_path: str = \"rollover_calendar.csv\"\n",
    "    \n",
    "    # === å›æµ‹æ§åˆ¶å‚æ•° ===\n",
    "    run_optimization: bool = False\n",
    "    optimization_params: Dict[str, Any] = None\n",
    "    monte_carlo_runs: int = 1000\n",
    "    \n",
    "    # === è¾“å‡ºæ§åˆ¶ ===\n",
    "    save_results: bool = True\n",
    "    output_dir: str = \"backtest_results\"\n",
    "    plot_results: bool = True\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"åˆå§‹åŒ–åçš„éªŒè¯å’Œè®¾ç½®\"\"\"\n",
    "        if self.symbols is None:\n",
    "            self.symbols = [\"SPREAD\"]\n",
    "        \n",
    "        if self.start_date is None:\n",
    "            self.start_date = date(2022, 1, 1)\n",
    "            \n",
    "        if self.end_date is None:\n",
    "            self.end_date = date(2024, 12, 31)\n",
    "            \n",
    "        if self.optimization_params is None:\n",
    "            self.optimization_params = {\n",
    "                'lookback_window': range(20, 61, 10),\n",
    "                'z_threshold': [1.0, 1.5, 2.0, 2.5]\n",
    "            }\n",
    "        \n",
    "        # åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "        if self.save_results and not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "    \n",
    "    def get_file_path(self, filename: str) -> str:\n",
    "        \"\"\"è·å–å®Œæ•´æ–‡ä»¶è·¯å¾„\"\"\"\n",
    "        if os.path.isabs(self.data_path):\n",
    "            return os.path.join(os.path.dirname(self.data_path), filename)\n",
    "        return filename\n",
    "    \n",
    "    def update_params(self, **kwargs):\n",
    "        \"\"\"åŠ¨æ€æ›´æ–°å‚æ•°\"\"\"\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown parameter: {key}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"è½¬æ¢ä¸ºå­—å…¸æ ¼å¼\"\"\"\n",
    "        return {\n",
    "            field.name: getattr(self, field.name) \n",
    "            for field in self.__dataclass_fields__.values()\n",
    "        }\n",
    "\n",
    "# åˆ›å»ºå…¨å±€é…ç½®å®ä¾‹\n",
    "config = BacktestConfig()\n",
    "\n",
    "print(\"âœ… é…ç½®ä¸­å¿ƒåˆå§‹åŒ–å®Œæˆ\")\n",
    "print(f\"   â€¢ æ•°æ®æ–‡ä»¶: {config.data_path}\")\n",
    "print(f\"   â€¢ åˆå§‹èµ„é‡‘: ${config.initial_capital:,.0f}\")\n",
    "print(f\"   â€¢ ç­–ç•¥å‚æ•°: å›çœ‹{config.lookback_window}å¤©, Z-scoreé˜ˆå€¼Â±{config.z_threshold}\")\n",
    "print(f\"   â€¢ äº¤æ˜“æˆæœ¬: ä½£é‡‘${config.commission_per_trade}/æ‰‹, æ»‘ç‚¹{config.slippage_per_trade}\")\n",
    "print(f\"   â€¢ è¾“å‡ºç›®å½•: {config.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5c0de8",
   "metadata": {},
   "source": [
    "## 2. ç¯å¢ƒä¸åº“åŠ è½½ (Environment & Libraries)\n",
    "æ‰€æœ‰importè¯­å¥å’Œç¯å¢ƒè®¾ç½®é›†ä¸­äºæ­¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af991c6",
   "metadata": {},
   "source": [
    "## Commodity Futures Calendar Spread Backtesting Engine\n",
    "\n",
    "### Project Overview\n",
    "This Jupyter Notebook implements an event-driven backtesting framework for testing a Z-score based mean reversion strategy on commodity futures calendar spreads. The framework is modular, using real data (soybean meal, WTI crude oil), including data processing, strategy generation, portfolio management, execution simulation, and performance analysis.\n",
    "\n",
    "#### Main Components\n",
    "- **Event-Driven Architecture**: Handles market updates, signals, orders, and fills.\n",
    "- **Strategy**: CalendarSpreadZScoreStrategy, uses rolling Z-score to generate buy/sell spread signals.\n",
    "- **Backtest Coordination**: Backtest class, runs the event loop and calculates performance metrics (such as Sharpe ratio, maximum drawdown).\n",
    "- **Data Support**: Loads from CSV, supports AKShare real data and generated sample data.\n",
    "- **Visualization**: Equity curve, spread behavior, and trading signal charts.\n",
    "\n",
    "#### Dataset\n",
    "- **Soybean Meal**: Downloaded using the Akshare API.\n",
    "- **WTI crude oil**: Initially attempted to download via APIs from Nasdaq Data Link and yfinance, but after failures, manually obtained from Investing.com.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f144ea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç¯å¢ƒé…ç½®å®Œæˆ\n",
      "   â€¢ Pythonç‰ˆæœ¬: 3.11.13\n",
      "   â€¢ Pandasç‰ˆæœ¬: 2.3.1\n",
      "   â€¢ NumPyç‰ˆæœ¬: 2.3.2\n",
      "   â€¢ å·¥ä½œç›®å½•: e:\\programs\\APEXUSTech_Inter\\project5\n",
      "   â€¢ æ—¥å¿—è®°å½•: å·²å¯ç”¨\n"
     ]
    }
   ],
   "source": [
    "# === æ ¸å¿ƒæ•°æ®å¤„ç†åº“ ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "# === ç³»ç»Ÿå’Œå·¥å…·åº“ ===\n",
    "import os\n",
    "import sys\n",
    "import queue\n",
    "import time\n",
    "import warnings\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Optional, Any, Union\n",
    "from pathlib import Path\n",
    "\n",
    "# === æ•°å­¦å’Œç»Ÿè®¡åº“ ===\n",
    "import scipy.stats as stats\n",
    "from scipy import optimize\n",
    "\n",
    "# === å¯è§†åŒ–åº“ ===\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "# === æ•°æ®è·å–åº“ ===\n",
    "import requests\n",
    "import yfinance as yf\n",
    "\n",
    "# === è®¾ç½®ç¯å¢ƒ ===\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# === æ—¥å¿—é…ç½® ===\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler('backtest.log')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒé…ç½®å®Œæˆ\")\n",
    "print(f\"   â€¢ Pythonç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
    "print(f\"   â€¢ Pandasç‰ˆæœ¬: {pd.__version__}\")\n",
    "print(f\"   â€¢ NumPyç‰ˆæœ¬: {np.__version__}\")\n",
    "print(f\"   â€¢ å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "print(f\"   â€¢ æ—¥å¿—è®°å½•: å·²å¯ç”¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63574389",
   "metadata": {},
   "source": [
    "## 3. æ•°æ®å¤„ç†æ¨¡å— (Data Handling Module)\n",
    "åŒ…å«æ•°æ®åŠ è½½ã€æ¸…æ´—ã€åˆçº¦å±•æœŸå’Œæ•°æ®éªŒè¯åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c9a6c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åˆçº¦å±•æœŸç®¡ç†å™¨å®šä¹‰å®Œæˆ\n",
      "   â€¢ æ”¯æŒå·´æ‹¿é©¬è¿æ²³æ³•å’Œæ¯”ç‡è°ƒæ•´æ³•\n",
      "   â€¢ æ”¯æŒå¤–éƒ¨å±•æœŸæ—¥å†\n",
      "   â€¢ åŒ…å«æ•°æ®è´¨é‡éªŒè¯åŠŸèƒ½\n"
     ]
    }
   ],
   "source": [
    "class ContractRolloverManager:\n",
    "    \"\"\"\n",
    "    å¼ºå¤§çš„åˆçº¦å±•æœŸç®¡ç†å™¨\n",
    "    æ”¯æŒå¤šç§ä»·æ ¼è°ƒæ•´æ–¹æ³•å’Œå¤–éƒ¨å±•æœŸæ—¥å†\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.rollover_calendar = None\n",
    "        self.adjustment_method = config.rollover_method\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n",
    "        \n",
    "    def load_rollover_calendar(self, calendar_path: str = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        åŠ è½½åˆçº¦å±•æœŸæ—¥å†\n",
    "        æ ¼å¼: Date, OldContract, NewContract\n",
    "        \"\"\"\n",
    "        if calendar_path is None:\n",
    "            calendar_path = self.config.rollover_calendar_path\n",
    "            \n",
    "        try:\n",
    "            if os.path.exists(calendar_path):\n",
    "                calendar = pd.read_csv(calendar_path, parse_dates=['Date'])\n",
    "                calendar.set_index('Date', inplace=True)\n",
    "                self.rollover_calendar = calendar\n",
    "                self.logger.info(f\"å·²åŠ è½½å±•æœŸæ—¥å†: {len(calendar)} ä¸ªå±•æœŸç‚¹\")\n",
    "                return calendar\n",
    "            else:\n",
    "                self.logger.warning(f\"å±•æœŸæ—¥å†æ–‡ä»¶ä¸å­˜åœ¨: {calendar_path}\")\n",
    "                return self._create_default_calendar()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"åŠ è½½å±•æœŸæ—¥å†å¤±è´¥: {e}\")\n",
    "            return self._create_default_calendar()\n",
    "    \n",
    "    def _create_default_calendar(self) -> pd.DataFrame:\n",
    "        \"\"\"åˆ›å»ºé»˜è®¤çš„å±•æœŸæ—¥å†ï¼ˆæ¯3ä¸ªæœˆå±•æœŸä¸€æ¬¡ï¼‰\"\"\"\n",
    "        date_range = pd.date_range(\n",
    "            start=self.config.start_date, \n",
    "            end=self.config.end_date, \n",
    "            freq='3M'\n",
    "        )\n",
    "        \n",
    "        calendar = pd.DataFrame({\n",
    "            'OldContract': [f'Contract_{i}' for i in range(len(date_range))],\n",
    "            'NewContract': [f'Contract_{i+1}' for i in range(len(date_range))]\n",
    "        }, index=date_range)\n",
    "        \n",
    "        self.rollover_calendar = calendar\n",
    "        self.logger.info(f\"åˆ›å»ºé»˜è®¤å±•æœŸæ—¥å†: {len(calendar)} ä¸ªå±•æœŸç‚¹\")\n",
    "        return calendar\n",
    "    \n",
    "    def panama_canal_adjustment(self, price_series: pd.Series, rollover_date: pd.Timestamp, \n",
    "                               old_price: float, new_price: float) -> pd.Series:\n",
    "        \"\"\"\n",
    "        å·´æ‹¿é©¬è¿æ²³æ³• (ä»·æ ¼å¹³ç§»æ³•)\n",
    "        é€šè¿‡åŠ å‡ä»·å·®æ¥æ¶ˆé™¤è·³ç©ºï¼Œä¿æŒç‚¹ä½è¿ç»­æ€§\n",
    "        é€‚ç”¨äºä»·å·®ç±»ç­–ç•¥\n",
    "        \"\"\"\n",
    "        adjustment = old_price - new_price\n",
    "        \n",
    "        # å±•æœŸæ—¥ä¹‹åçš„æ‰€æœ‰ä»·æ ¼éƒ½åŠ ä¸Šè°ƒæ•´å€¼\n",
    "        mask = price_series.index > rollover_date\n",
    "        adjusted_series = price_series.copy()\n",
    "        adjusted_series.loc[mask] += adjustment\n",
    "        \n",
    "        self.logger.info(f\"å·´æ‹¿é©¬è¿æ²³æ³•è°ƒæ•´: å±•æœŸæ—¥ {rollover_date.date()}, è°ƒæ•´å€¼ {adjustment:.4f}\")\n",
    "        return adjusted_series\n",
    "    \n",
    "    def ratio_adjustment(self, price_series: pd.Series, rollover_date: pd.Timestamp,\n",
    "                        old_price: float, new_price: float) -> pd.Series:\n",
    "        \"\"\"\n",
    "        æ¯”ç‡è°ƒæ•´æ³•\n",
    "        é€šè¿‡ä¹˜é™¤æ¯”ç‡æ¥è°ƒæ•´ï¼Œä¿æŒæ”¶ç›Šç‡è¿ç»­æ€§\n",
    "        é€‚ç”¨äºè¶‹åŠ¿ç±»ç­–ç•¥\n",
    "        \"\"\"\n",
    "        if new_price == 0:\n",
    "            self.logger.warning(\"æ–°åˆçº¦ä»·æ ¼ä¸º0ï¼Œè·³è¿‡æ¯”ç‡è°ƒæ•´\")\n",
    "            return price_series\n",
    "            \n",
    "        ratio = old_price / new_price\n",
    "        \n",
    "        # å±•æœŸæ—¥ä¹‹åçš„æ‰€æœ‰ä»·æ ¼éƒ½ä¹˜ä»¥è°ƒæ•´æ¯”ç‡\n",
    "        mask = price_series.index > rollover_date\n",
    "        adjusted_series = price_series.copy()\n",
    "        adjusted_series.loc[mask] *= ratio\n",
    "        \n",
    "        self.logger.info(f\"æ¯”ç‡è°ƒæ•´æ³•: å±•æœŸæ—¥ {rollover_date.date()}, è°ƒæ•´æ¯”ç‡ {ratio:.6f}\")\n",
    "        return adjusted_series\n",
    "    \n",
    "    def apply_rollover_adjustments(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        å¯¹æ•´ä¸ªæ•°æ®é›†åº”ç”¨å±•æœŸè°ƒæ•´\n",
    "        \"\"\"\n",
    "        if self.rollover_calendar is None:\n",
    "            self.load_rollover_calendar()\n",
    "        \n",
    "        adjusted_data = data.copy()\n",
    "        \n",
    "        for rollover_date in self.rollover_calendar.index:\n",
    "            if rollover_date in data.index:\n",
    "                # è·å–å±•æœŸæ—¥çš„ä»·æ ¼\n",
    "                old_price = data.loc[rollover_date, 'NEAR']  # ä½¿ç”¨NEARä½œä¸ºåŸºå‡†\n",
    "                \n",
    "                # è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥çš„ä»·æ ¼ä½œä¸ºæ–°åˆçº¦ä»·æ ¼\n",
    "                next_dates = data.index[data.index > rollover_date]\n",
    "                if len(next_dates) > 0:\n",
    "                    new_price = data.loc[next_dates[0], 'NEAR']\n",
    "                    \n",
    "                    # å¯¹æ‰€æœ‰ä»·æ ¼åˆ—åº”ç”¨è°ƒæ•´\n",
    "                    for col in ['NEAR', 'FAR']:\n",
    "                        if col in data.columns:\n",
    "                            if self.adjustment_method == 'panama_canal':\n",
    "                                adjusted_data[col] = self.panama_canal_adjustment(\n",
    "                                    adjusted_data[col], rollover_date, old_price, new_price\n",
    "                                )\n",
    "                            elif self.adjustment_method == 'ratio_adjustment':\n",
    "                                adjusted_data[col] = self.ratio_adjustment(\n",
    "                                    adjusted_data[col], rollover_date, old_price, new_price\n",
    "                                )\n",
    "        \n",
    "        self.logger.info(f\"å±•æœŸè°ƒæ•´å®Œæˆï¼Œæ–¹æ³•: {self.adjustment_method}\")\n",
    "        return adjusted_data\n",
    "    \n",
    "    def validate_continuous_data(self, data: pd.DataFrame, \n",
    "                                max_gap_threshold: float = 0.1) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        éªŒè¯è¿ç»­æ•°æ®çš„è´¨é‡\n",
    "        æ£€æŸ¥ä»·æ ¼è·³ç©ºã€æ•°æ®ç¼ºå¤±ç­‰é—®é¢˜\n",
    "        \"\"\"\n",
    "        validation_results = {\n",
    "            'total_observations': len(data),\n",
    "            'missing_data': data.isnull().sum().to_dict(),\n",
    "            'price_gaps': {},\n",
    "            'outliers': {},\n",
    "            'data_quality_score': 0.0\n",
    "        }\n",
    "        \n",
    "        for col in ['NEAR', 'FAR']:\n",
    "            if col in data.columns:\n",
    "                # æ£€æŸ¥ä»·æ ¼è·³ç©º\n",
    "                daily_returns = data[col].pct_change().dropna()\n",
    "                large_gaps = daily_returns[abs(daily_returns) > max_gap_threshold]\n",
    "                validation_results['price_gaps'][col] = len(large_gaps)\n",
    "                \n",
    "                # æ£€æŸ¥å¼‚å¸¸å€¼ (3å€æ ‡å‡†å·®)\n",
    "                z_scores = np.abs(stats.zscore(daily_returns.dropna()))\n",
    "                outliers = z_scores > 3\n",
    "                validation_results['outliers'][col] = np.sum(outliers)\n",
    "        \n",
    "        # è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†\n",
    "        total_gaps = sum(validation_results['price_gaps'].values())\n",
    "        total_outliers = sum(validation_results['outliers'].values())\n",
    "        total_missing = sum(validation_results['missing_data'].values())\n",
    "        \n",
    "        quality_score = max(0, 100 - (total_gaps + total_outliers + total_missing) / len(data) * 100)\n",
    "        validation_results['data_quality_score'] = quality_score\n",
    "        \n",
    "        self.logger.info(f\"æ•°æ®è´¨é‡éªŒè¯å®Œæˆï¼Œè¯„åˆ†: {quality_score:.1f}/100\")\n",
    "        return validation_results\n",
    "\n",
    "print(\"âœ… åˆçº¦å±•æœŸç®¡ç†å™¨å®šä¹‰å®Œæˆ\")\n",
    "print(\"   â€¢ æ”¯æŒå·´æ‹¿é©¬è¿æ²³æ³•å’Œæ¯”ç‡è°ƒæ•´æ³•\")\n",
    "print(\"   â€¢ æ”¯æŒå¤–éƒ¨å±•æœŸæ—¥å†\")\n",
    "print(\"   â€¢ åŒ…å«æ•°æ®è´¨é‡éªŒè¯åŠŸèƒ½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cd6270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event:\n",
    "    \"\"\"Base class for all event types.\"\"\"\n",
    "    pass\n",
    "\n",
    "class MarketEvent(Event):\n",
    "    \"\"\"Handles the event of receiving new market data.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.type = 'MARKET'\n",
    "\n",
    "class SignalEvent(Event):\n",
    "    \"\"\"Handles the event of sending a signal from a strategy object.\"\"\"\n",
    "    def __init__(self, symbol, datetime, signal_type, strength=1.0):\n",
    "        self.type = 'SIGNAL'\n",
    "        self.symbol = symbol\n",
    "        self.datetime = datetime\n",
    "        self.signal_type = signal_type # 'LONG_SPREAD' or 'SHORT_SPREAD'\n",
    "        self.strength = strength\n",
    "\n",
    "class OrderEvent(Event):\n",
    "    \"\"\"Handles the event of sending an order to the execution system.\"\"\"\n",
    "    def __init__(self, symbol, order_type, quantity, direction):\n",
    "        self.type = 'ORDER'\n",
    "        self.symbol = symbol\n",
    "        self.order_type = order_type # 'MKT' (market order) or 'LMT' (limit order)\n",
    "        self.quantity = quantity\n",
    "        self.direction = direction # 'BUY' or 'SELL'\n",
    "\n",
    "class FillEvent(Event):\n",
    "    \"\"\"Encapsulates the execution of an order, i.e., a trade.\"\"\"\n",
    "    def __init__(self, timeindex, symbol, exchange, quantity, direction, fill_cost, commission=0.0):\n",
    "        self.type = 'FILL'\n",
    "        self.timeindex = timeindex\n",
    "        self.symbol = symbol\n",
    "        self.exchange = exchange\n",
    "        self.quantity = quantity\n",
    "        self.direction = direction\n",
    "        self.fill_cost = fill_cost\n",
    "        self.commission = commission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01bc2e",
   "metadata": {},
   "source": [
    "### 3.1 äº‹ä»¶ç³»ç»Ÿ (Event System)\n",
    "å®šä¹‰æ‰€æœ‰äº‹ä»¶ç±»å‹ï¼Œæ”¯æŒäº‹ä»¶é©±åŠ¨çš„å›æµ‹æ¶æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "651311d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataHandler:\n",
    "    \"\"\"Reads data from CSV files and provides it bar by bar.\"\"\"\n",
    "    def __init__(self, events_queue, csv_path, symbols):\n",
    "        self.events = events_queue\n",
    "        self.csv_path = csv_path\n",
    "        self.symbols = symbols\n",
    "        self.symbol_data = {}\n",
    "        self.latest_symbol_data = {}\n",
    "        self.continue_backtest = True\n",
    "        \n",
    "        self._open_convert_csv_files()\n",
    "\n",
    "    def _open_convert_csv_files(self):\n",
    "        self.symbol_data = pd.read_csv(\n",
    "            self.csv_path, header=0, index_col=0, parse_dates=True\n",
    "        ).to_records(index=True)\n",
    "        self.data_iterator = self.symbol_data.__iter__()\n",
    "\n",
    "    def get_latest_bar(self, symbol):\n",
    "        \"\"\"Returns the latest bar data for a given trading symbol.\"\"\"\n",
    "        try:\n",
    "            return self.latest_symbol_data[symbol]\n",
    "        except KeyError:\n",
    "            print(\"This trading symbol is not available in the historical dataset.\")\n",
    "            return None\n",
    "\n",
    "    def update_bars(self):\n",
    "        \"\"\"Pushes the next bar from the data source to latest_symbol_data.\"\"\"\n",
    "        try:\n",
    "            bar = next(self.data_iterator)\n",
    "        except StopIteration:\n",
    "            self.continue_backtest = False\n",
    "            return\n",
    "        \n",
    "        # We use a single 'symbol' for spread pairs\n",
    "        self.latest_symbol_data[self.symbols[0]] = bar\n",
    "        self.events.put(MarketEvent())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957259aa",
   "metadata": {},
   "source": [
    "### 3.2 å¢å¼ºæ•°æ®å¤„ç†å™¨ (Enhanced Data Handler)\n",
    "é›†æˆå±•æœŸç®¡ç†å’Œæ•°æ®éªŒè¯çš„é«˜çº§æ•°æ®å¤„ç†å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "417c9de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¢å¼ºæ•°æ®å¤„ç†å™¨å®šä¹‰å®Œæˆ\n",
      "   â€¢ é›†æˆåˆçº¦å±•æœŸç®¡ç†\n",
      "   â€¢ åŒ…å«æ•°æ®æ¸…æ´—å’ŒéªŒè¯\n",
      "   â€¢ æ”¯æŒå¤šç§æ•°æ®æºæ ¼å¼\n"
     ]
    }
   ],
   "source": [
    "class EnhancedDataHandler:\n",
    "    \"\"\"\n",
    "    å¢å¼ºçš„æ•°æ®å¤„ç†å™¨\n",
    "    é›†æˆåˆçº¦å±•æœŸç®¡ç†ã€æ•°æ®éªŒè¯å’Œå¤šç§æ•°æ®æºæ”¯æŒ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, events_queue, config):\n",
    "        self.events = events_queue\n",
    "        self.config = config\n",
    "        self.symbols = config.symbols\n",
    "        self.symbol_data = None\n",
    "        self.latest_symbol_data = {}\n",
    "        self.continue_backtest = True\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n",
    "        \n",
    "        # åˆå§‹åŒ–å±•æœŸç®¡ç†å™¨\n",
    "        self.rollover_manager = ContractRolloverManager(config)\n",
    "        \n",
    "        # æ•°æ®éªŒè¯ç»“æœ\n",
    "        self.validation_results = None\n",
    "        \n",
    "        self._load_and_process_data()\n",
    "\n",
    "    def _load_and_process_data(self):\n",
    "        \"\"\"åŠ è½½å¹¶å¤„ç†æ•°æ®\"\"\"\n",
    "        try:\n",
    "            # 1. åŠ è½½åŸå§‹æ•°æ®\n",
    "            self.logger.info(f\"å¼€å§‹åŠ è½½æ•°æ®: {self.config.data_path}\")\n",
    "            raw_data = self._load_raw_data()\n",
    "            \n",
    "            # 2. æ•°æ®æ¸…æ´—å’ŒéªŒè¯\n",
    "            cleaned_data = self._clean_data(raw_data)\n",
    "            \n",
    "            # 3. åº”ç”¨å±•æœŸè°ƒæ•´ï¼ˆå¦‚æœéœ€è¦ï¼‰\n",
    "            if self.config.rollover_method != \"none\":\n",
    "                adjusted_data = self.rollover_manager.apply_rollover_adjustments(cleaned_data)\n",
    "            else:\n",
    "                adjusted_data = cleaned_data\n",
    "            \n",
    "            # 4. æœ€ç»ˆéªŒè¯\n",
    "            self.validation_results = self.rollover_manager.validate_continuous_data(adjusted_data)\n",
    "            \n",
    "            # 5. è½¬æ¢ä¸ºè¿­ä»£å™¨æ ¼å¼\n",
    "            self.symbol_data = adjusted_data.to_records(index=True)\n",
    "            self.data_iterator = iter(self.symbol_data)\n",
    "            \n",
    "            self.logger.info(f\"æ•°æ®å¤„ç†å®Œæˆ: {len(adjusted_data)} æ¡è®°å½•\")\n",
    "            self.logger.info(f\"æ•°æ®è´¨é‡è¯„åˆ†: {self.validation_results['data_quality_score']:.1f}/100\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"æ•°æ®å¤„ç†å¤±è´¥: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _load_raw_data(self) -> pd.DataFrame:\n",
    "        \"\"\"åŠ è½½åŸå§‹æ•°æ®\"\"\"\n",
    "        file_path = self.config.get_file_path(self.config.data_path)\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}\")\n",
    "        \n",
    "        # è¯»å–CSVæ•°æ®\n",
    "        df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "        \n",
    "        # éªŒè¯å¿…è¦çš„åˆ—\n",
    "        required_columns = ['NEAR', 'FAR']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"æ•°æ®æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}\")\n",
    "        \n",
    "        # æŒ‰æ—¥æœŸæ’åº\n",
    "        df = df.sort_index()\n",
    "        \n",
    "        # è¿‡æ»¤æ—¥æœŸèŒƒå›´\n",
    "        if self.config.start_date:\n",
    "            df = df[df.index >= pd.Timestamp(self.config.start_date)]\n",
    "        if self.config.end_date:\n",
    "            df = df[df.index <= pd.Timestamp(self.config.end_date)]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _clean_data(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"æ•°æ®æ¸…æ´—\"\"\"\n",
    "        cleaned_data = data.copy()\n",
    "        \n",
    "        # åˆ é™¤å«æœ‰NaNçš„è¡Œ\n",
    "        initial_rows = len(cleaned_data)\n",
    "        cleaned_data = cleaned_data.dropna()\n",
    "        removed_rows = initial_rows - len(cleaned_data)\n",
    "        \n",
    "        if removed_rows > 0:\n",
    "            self.logger.warning(f\"åˆ é™¤äº† {removed_rows} è¡Œå«æœ‰ç¼ºå¤±å€¼çš„æ•°æ®\")\n",
    "        \n",
    "        # åˆ é™¤ä»·æ ¼ä¸º0æˆ–è´Ÿæ•°çš„è¡Œ\n",
    "        invalid_price_mask = (cleaned_data['NEAR'] <= 0) | (cleaned_data['FAR'] <= 0)\n",
    "        invalid_rows = invalid_price_mask.sum()\n",
    "        if invalid_rows > 0:\n",
    "            cleaned_data = cleaned_data[~invalid_price_mask]\n",
    "            self.logger.warning(f\"åˆ é™¤äº† {invalid_rows} è¡Œæ— æ•ˆä»·æ ¼æ•°æ®\")\n",
    "        \n",
    "        # æ£€æŸ¥æç«¯å¼‚å¸¸å€¼\n",
    "        for col in ['NEAR', 'FAR']:\n",
    "            Q1 = cleaned_data[col].quantile(0.01)\n",
    "            Q99 = cleaned_data[col].quantile(0.99)\n",
    "            outlier_mask = (cleaned_data[col] < Q1) | (cleaned_data[col] > Q99)\n",
    "            outlier_count = outlier_mask.sum()\n",
    "            \n",
    "            if outlier_count > 0:\n",
    "                self.logger.warning(f\"{col}åˆ—å‘ç° {outlier_count} ä¸ªæç«¯å¼‚å¸¸å€¼ (< {Q1:.2f} æˆ– > {Q99:.2f})\")\n",
    "                # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬è®°å½•ä½†ä¸åˆ é™¤å¼‚å¸¸å€¼ï¼Œè®©ç”¨æˆ·å†³å®š\n",
    "        \n",
    "        return cleaned_data\n",
    "    \n",
    "    def get_latest_bar(self, symbol):\n",
    "        \"\"\"è·å–æœ€æ–°çš„æ•°æ®æ¡\"\"\"\n",
    "        try:\n",
    "            return self.latest_symbol_data[symbol]\n",
    "        except KeyError:\n",
    "            self.logger.error(f\"äº¤æ˜“ä»£ç ä¸åœ¨å†å²æ•°æ®ä¸­: {symbol}\")\n",
    "            return None\n",
    "\n",
    "    def update_bars(self):\n",
    "        \"\"\"æ›´æ–°åˆ°ä¸‹ä¸€æ ¹Kçº¿\"\"\"\n",
    "        try:\n",
    "            bar = next(self.data_iterator)\n",
    "            # ä½¿ç”¨ç¬¬ä¸€ä¸ªäº¤æ˜“ä»£ç å­˜å‚¨æ•°æ®\n",
    "            self.latest_symbol_data[self.symbols[0]] = bar\n",
    "            self.events.put(MarketEvent())\n",
    "        except StopIteration:\n",
    "            self.continue_backtest = False\n",
    "            self.logger.info(\"æ•°æ®éå†å®Œæˆï¼Œå›æµ‹ç»“æŸ\")\n",
    "    \n",
    "    def get_data_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–æ•°æ®æ‘˜è¦\"\"\"\n",
    "        if self.symbol_data is None:\n",
    "            return {}\n",
    "        \n",
    "        # è½¬æ¢å›DataFrameè¿›è¡Œç»Ÿè®¡\n",
    "        df = pd.DataFrame(self.symbol_data)\n",
    "        df.set_index('Date', inplace=True)\n",
    "        \n",
    "        summary = {\n",
    "            'total_records': len(df),\n",
    "            'date_range': (df.index.min(), df.index.max()),\n",
    "            'price_statistics': df[['NEAR', 'FAR']].describe().to_dict(),\n",
    "            'validation_results': self.validation_results\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "print(\"âœ… å¢å¼ºæ•°æ®å¤„ç†å™¨å®šä¹‰å®Œæˆ\")\n",
    "print(\"   â€¢ é›†æˆåˆçº¦å±•æœŸç®¡ç†\")\n",
    "print(\"   â€¢ åŒ…å«æ•°æ®æ¸…æ´—å’ŒéªŒè¯\")\n",
    "print(\"   â€¢ æ”¯æŒå¤šç§æ•°æ®æºæ ¼å¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9efd7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalendarSpreadZScoreStrategy:\n",
    "    \"\"\"\n",
    "    A simple strategy for trading calendar spreads based on Z-score.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_handler, events_queue, symbol, lookback_window=60, z_threshold=2.0):\n",
    "        self.data_handler = data_handler\n",
    "        self.events = events_queue\n",
    "        self.symbol = symbol\n",
    "        self.lookback_window = lookback_window\n",
    "        self.z_threshold = z_threshold\n",
    "        \n",
    "        self.spread_history = pd.Series(dtype=float)\n",
    "        self.bought = False # A simple flag to track if we are in a position\n",
    "        self.sold = False\n",
    "\n",
    "    def calculate_signals(self, event):\n",
    "        \"\"\"Calculate signals upon receiving a MarketEvent.\"\"\"\n",
    "        if event.type == 'MARKET':\n",
    "            bar = self.data_handler.get_latest_bar(self.symbol)\n",
    "            if bar is not None:\n",
    "                # Calculate spread: far-month price - near-month price\n",
    "                spread = bar['FAR'] - bar['NEAR']\n",
    "                self.spread_history[bar['Date']] = spread\n",
    "\n",
    "                if len(self.spread_history) > self.lookback_window:\n",
    "                    # Calculate rolling mean, standard deviation, and Z-score\n",
    "                    rolling_mean = self.spread_history.rolling(window=self.lookback_window).mean().iloc[-1]\n",
    "                    rolling_std = self.spread_history.rolling(window=self.lookback_window).std().iloc[-1]\n",
    "                    \n",
    "                    if rolling_std > 0: # Avoid division by zero\n",
    "                        z_score = (spread - rolling_mean) / rolling_std\n",
    "\n",
    "                        # --- Trading logic ---\n",
    "                        # If we are not in a position\n",
    "                        if not self.bought and not self.sold:\n",
    "                            if z_score > self.z_threshold:\n",
    "                                # Spread is unusually high -> sell spread (sell far-month, buy near-month)\n",
    "                                signal = SignalEvent(self.symbol, bar['Date'], 'SHORT_SPREAD')\n",
    "                                self.events.put(signal)\n",
    "                                self.sold = True\n",
    "                            elif z_score < -self.z_threshold:\n",
    "                                # Spread is unusually low -> buy spread (buy far-month, sell near-month)\n",
    "                                signal = SignalEvent(self.symbol, bar['Date'], 'LONG_SPREAD')\n",
    "                                self.events.put(signal)\n",
    "                                self.bought = True\n",
    "                        \n",
    "                        # If we are in a position, check for exit\n",
    "                        elif self.sold and z_score < 0.5:\n",
    "                            # Spread reverts to mean -> exit short position\n",
    "                            signal = SignalEvent(self.symbol, bar['Date'], 'EXIT_SHORT')\n",
    "                            self.events.put(signal)\n",
    "                            self.sold = False\n",
    "                        elif self.bought and z_score > -0.5:\n",
    "                            # Spread reverts to mean -> exit long position\n",
    "                            signal = SignalEvent(self.symbol, bar['Date'], 'EXIT_LONG')\n",
    "                            self.events.put(signal)\n",
    "                            self.bought = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2868b765",
   "metadata": {},
   "source": [
    "## 4. ç­–ç•¥å®šä¹‰æ¨¡å— (Strategy Definition Module)\n",
    "åŒ…å«ç­–ç•¥åŸºç±»å’Œå¢å¼ºçš„ä¿¡å·ç”Ÿæˆç®—æ³•ï¼Œæ”¯æŒè¿‡æ»¤å™¨å’ŒåŠ¨æ€å‚æ•°è°ƒæ•´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9131146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¢å¼ºç­–ç•¥å®šä¹‰å®Œæˆ\n",
      "   â€¢ å®ç°ç­–ç•¥åŸºç±»å’Œä¿¡å·è¿‡æ»¤å™¨\n",
      "   â€¢ é›†æˆæ³¢åŠ¨ç‡è¿‡æ»¤å’Œæ—¶é—´è¿‡æ»¤\n",
      "   â€¢ æ”¯æŒåŠ¨æ€å‚æ•°è°ƒæ•´å’Œæ€§èƒ½è¿½è¸ª\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseStrategy(ABC):\n",
    "    \"\"\"ç­–ç•¥åŸºç±»ï¼Œå®šä¹‰æ‰€æœ‰ç­–ç•¥çš„é€šç”¨æ¥å£\"\"\"\n",
    "    \n",
    "    def __init__(self, data_handler, events_queue, config):\n",
    "        self.data_handler = data_handler\n",
    "        self.events = events_queue\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n",
    "        \n",
    "        # äº¤æ˜“çŠ¶æ€\n",
    "        self.position_status = {'LONG': False, 'SHORT': False}\n",
    "        self.last_signal_time = None\n",
    "        \n",
    "        # æ€§èƒ½è¿½è¸ª\n",
    "        self.signal_history = []\n",
    "        self.trade_count = 0\n",
    "    \n",
    "    @abstractmethod\n",
    "    def calculate_signals(self, event):\n",
    "        \"\"\"è®¡ç®—äº¤æ˜“ä¿¡å·çš„æŠ½è±¡æ–¹æ³•\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def can_generate_signal(self, current_time, min_interval_hours=1):\n",
    "        \"\"\"æ£€æŸ¥æ˜¯å¦å¯ä»¥ç”Ÿæˆæ–°ä¿¡å·ï¼ˆé˜²æ­¢è¿‡åº¦äº¤æ˜“ï¼‰\"\"\"\n",
    "        if self.last_signal_time is None:\n",
    "            return True\n",
    "        \n",
    "        time_diff = current_time - self.last_signal_time\n",
    "        if hasattr(time_diff, 'total_seconds'):\n",
    "            hours_passed = time_diff.total_seconds() / 3600\n",
    "        else:\n",
    "            hours_passed = float(time_diff) / pd.Timedelta(hours=1)\n",
    "        \n",
    "        return hours_passed >= min_interval_hours\n",
    "    \n",
    "    def log_signal(self, signal_type, timestamp, additional_info=None):\n",
    "        \"\"\"è®°å½•ä¿¡å·å†å²\"\"\"\n",
    "        signal_record = {\n",
    "            'timestamp': timestamp,\n",
    "            'signal_type': signal_type,\n",
    "            'additional_info': additional_info or {}\n",
    "        }\n",
    "        self.signal_history.append(signal_record)\n",
    "        self.last_signal_time = timestamp\n",
    "\n",
    "class SignalFilter:\n",
    "    \"\"\"ä¿¡å·è¿‡æ»¤å™¨ç±»ï¼Œç”¨äºå‡å°‘å™ªéŸ³äº¤æ˜“\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n",
    "    \n",
    "    def time_filter(self, signal, current_bar):\n",
    "        \"\"\"æ—¶é—´è¿‡æ»¤å™¨ï¼šè¦æ±‚ä¿¡å·æŒç»­Nä¸ªæ—¶é—´å‘¨æœŸ\"\"\"\n",
    "        # è¿™é‡Œå¯ä»¥å®ç°æŒç»­ä¿¡å·æ£€æŸ¥\n",
    "        return True  # ç®€åŒ–å®ç°\n",
    "    \n",
    "    def volatility_filter(self, signal, price_series, volatility_threshold=(0.01, 0.05)):\n",
    "        \"\"\"\n",
    "        æ³¢åŠ¨ç‡è¿‡æ»¤å™¨ï¼šåœ¨æé«˜æˆ–æä½æ³¢åŠ¨ç‡æ—¶æš‚åœäº¤æ˜“\n",
    "        \n",
    "        Args:\n",
    "            signal: äº¤æ˜“ä¿¡å·\n",
    "            price_series: ä»·æ ¼åºåˆ—\n",
    "            volatility_threshold: (æœ€å°æ³¢åŠ¨ç‡, æœ€å¤§æ³¢åŠ¨ç‡)\n",
    "        \"\"\"\n",
    "        if len(price_series) < 20:\n",
    "            return True  # æ•°æ®ä¸è¶³æ—¶ä¸è¿‡æ»¤\n",
    "        \n",
    "        # è®¡ç®—20æ—¥å·²å®ç°æ³¢åŠ¨ç‡\n",
    "        daily_returns = price_series.pct_change().dropna()\n",
    "        if len(daily_returns) < 10:\n",
    "            return True\n",
    "        \n",
    "        realized_vol = daily_returns.tail(20).std() * np.sqrt(252)\n",
    "        \n",
    "        min_vol, max_vol = volatility_threshold\n",
    "        \n",
    "        if realized_vol < min_vol:\n",
    "            self.logger.info(f\"æ³¢åŠ¨ç‡è¿‡ä½({realized_vol:.3f} < {min_vol})ï¼Œè¿‡æ»¤ä¿¡å·\")\n",
    "            return False\n",
    "        elif realized_vol > max_vol:\n",
    "            self.logger.info(f\"æ³¢åŠ¨ç‡è¿‡é«˜({realized_vol:.3f} > {max_vol})ï¼Œè¿‡æ»¤ä¿¡å·\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def apply_filters(self, signal, current_bar, price_history):\n",
    "        \"\"\"åº”ç”¨æ‰€æœ‰è¿‡æ»¤å™¨\"\"\"\n",
    "        if not self.time_filter(signal, current_bar):\n",
    "            return False\n",
    "        \n",
    "        if not self.volatility_filter(signal, price_history):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "class EnhancedCalendarSpreadStrategy(BaseStrategy):\n",
    "    \"\"\"\n",
    "    å¢å¼ºçš„æ—¥å†ä»·å·®Z-scoreç­–ç•¥\n",
    "    é›†æˆä¿¡å·è¿‡æ»¤å™¨å’ŒåŠ¨æ€å‚æ•°è°ƒæ•´\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_handler, events_queue, config):\n",
    "        super().__init__(data_handler, events_queue, config)\n",
    "        \n",
    "        self.symbol = config.symbols[0]\n",
    "        self.lookback_window = config.lookback_window\n",
    "        self.z_threshold = config.z_threshold\n",
    "        self.exit_z_threshold = config.exit_z_threshold\n",
    "        \n",
    "        # ä»·å·®å†å²æ•°æ®\n",
    "        self.spread_history = pd.Series(dtype=float)\n",
    "        self.near_history = pd.Series(dtype=float)\n",
    "        self.far_history = pd.Series(dtype=float)\n",
    "        \n",
    "        # ä¿¡å·è¿‡æ»¤å™¨\n",
    "        self.signal_filter = SignalFilter(config)\n",
    "        \n",
    "        # åŠ¨æ€æŒ‡æ ‡\n",
    "        self.rolling_stats = {}\n",
    "        \n",
    "    def calculate_signals(self, event):\n",
    "        \"\"\"å¢å¼ºçš„ä¿¡å·è®¡ç®—é€»è¾‘\"\"\"\n",
    "        if event.type != 'MARKET':\n",
    "            return\n",
    "            \n",
    "        bar = self.data_handler.get_latest_bar(self.symbol)\n",
    "        if bar is None:\n",
    "            return\n",
    "        \n",
    "        # è·å–æ—¶é—´æˆ³\n",
    "        if hasattr(bar, 'Date'):\n",
    "            bar_date = bar['Date']\n",
    "        elif hasattr(bar, 'index'):\n",
    "            bar_date = bar['index']\n",
    "        else:\n",
    "            bar_date = bar[0] if len(bar) > 0 else pd.Timestamp.now()\n",
    "        \n",
    "        # æ›´æ–°ä»·æ ¼å†å²\n",
    "        spread = bar['FAR'] - bar['NEAR']\n",
    "        self.spread_history[bar_date] = spread\n",
    "        self.near_history[bar_date] = bar['NEAR']\n",
    "        self.far_history[bar_date] = bar['FAR']\n",
    "        \n",
    "        # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®\n",
    "        if len(self.spread_history) <= self.lookback_window:\n",
    "            return\n",
    "        \n",
    "        # è®¡ç®—æ»šåŠ¨ç»Ÿè®¡æŒ‡æ ‡\n",
    "        self._update_rolling_stats()\n",
    "        \n",
    "        # è®¡ç®—Z-score\n",
    "        rolling_mean = self.rolling_stats['spread_mean']\n",
    "        rolling_std = self.rolling_stats['spread_std']\n",
    "        \n",
    "        if rolling_std <= 0:\n",
    "            return\n",
    "        \n",
    "        current_z_score = (spread - rolling_mean) / rolling_std\n",
    "        \n",
    "        # ç”Ÿæˆäº¤æ˜“ä¿¡å·\n",
    "        signal_generated = self._generate_trading_signals(\n",
    "            bar_date, current_z_score, spread\n",
    "        )\n",
    "        \n",
    "        if signal_generated:\n",
    "            self.trade_count += 1\n",
    "    \n",
    "    def _update_rolling_stats(self):\n",
    "        \"\"\"æ›´æ–°æ»šåŠ¨ç»Ÿè®¡æŒ‡æ ‡\"\"\"\n",
    "        recent_spreads = self.spread_history.tail(self.lookback_window)\n",
    "        \n",
    "        self.rolling_stats = {\n",
    "            'spread_mean': recent_spreads.mean(),\n",
    "            'spread_std': recent_spreads.std(),\n",
    "            'spread_min': recent_spreads.min(),\n",
    "            'spread_max': recent_spreads.max(),\n",
    "            'near_volatility': self.near_history.tail(self.lookback_window).pct_change().std(),\n",
    "            'far_volatility': self.far_history.tail(self.lookback_window).pct_change().std()\n",
    "        }\n",
    "    \n",
    "    def _generate_trading_signals(self, timestamp, z_score, current_spread):\n",
    "        \"\"\"ç”Ÿæˆäº¤æ˜“ä¿¡å·çš„æ ¸å¿ƒé€»è¾‘\"\"\"\n",
    "        signal_generated = False\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦å¯ä»¥ç”Ÿæˆæ–°ä¿¡å·\n",
    "        if not self.can_generate_signal(timestamp, min_interval_hours=24):\n",
    "            return False\n",
    "        \n",
    "        # === å¼€ä»“ä¿¡å· ===\n",
    "        if not self.position_status['LONG'] and not self.position_status['SHORT']:\n",
    "            \n",
    "            if z_score > self.z_threshold:\n",
    "                # ä»·å·®è¿‡é«˜ -> å–å‡ºä»·å·® (SHORT_SPREAD)\n",
    "                signal = SignalEvent(self.symbol, timestamp, 'SHORT_SPREAD')\n",
    "                \n",
    "                # åº”ç”¨è¿‡æ»¤å™¨\n",
    "                if self.signal_filter.apply_filters(signal, None, self.spread_history):\n",
    "                    self.events.put(signal)\n",
    "                    self.position_status['SHORT'] = True\n",
    "                    self.log_signal('SHORT_SPREAD', timestamp, {'z_score': z_score})\n",
    "                    signal_generated = True\n",
    "                    self.logger.info(f\"ç”ŸæˆSHORTä¿¡å·: Z-score={z_score:.3f}, ä»·å·®={current_spread:.3f}\")\n",
    "            \n",
    "            elif z_score < -self.z_threshold:\n",
    "                # ä»·å·®è¿‡ä½ -> ä¹°å…¥ä»·å·® (LONG_SPREAD)\n",
    "                signal = SignalEvent(self.symbol, timestamp, 'LONG_SPREAD')\n",
    "                \n",
    "                # åº”ç”¨è¿‡æ»¤å™¨\n",
    "                if self.signal_filter.apply_filters(signal, None, self.spread_history):\n",
    "                    self.events.put(signal)\n",
    "                    self.position_status['LONG'] = True\n",
    "                    self.log_signal('LONG_SPREAD', timestamp, {'z_score': z_score})\n",
    "                    signal_generated = True\n",
    "                    self.logger.info(f\"ç”ŸæˆLONGä¿¡å·: Z-score={z_score:.3f}, ä»·å·®={current_spread:.3f}\")\n",
    "        \n",
    "        # === å¹³ä»“ä¿¡å· ===\n",
    "        elif self.position_status['SHORT'] and z_score < self.exit_z_threshold:\n",
    "            # å¹³ç©ºå¤´ä»·å·®ä»“ä½\n",
    "            signal = SignalEvent(self.symbol, timestamp, 'EXIT_SHORT')\n",
    "            self.events.put(signal)\n",
    "            self.position_status['SHORT'] = False\n",
    "            self.log_signal('EXIT_SHORT', timestamp, {'z_score': z_score})\n",
    "            signal_generated = True\n",
    "            self.logger.info(f\"å¹³ç©ºä»“ä¿¡å·: Z-score={z_score:.3f}\")\n",
    "            \n",
    "        elif self.position_status['LONG'] and z_score > -self.exit_z_threshold:\n",
    "            # å¹³å¤šå¤´ä»·å·®ä»“ä½\n",
    "            signal = SignalEvent(self.symbol, timestamp, 'EXIT_LONG')\n",
    "            self.events.put(signal)\n",
    "            self.position_status['LONG'] = False\n",
    "            self.log_signal('EXIT_LONG', timestamp, {'z_score': z_score})\n",
    "            signal_generated = True\n",
    "            self.logger.info(f\"å¹³å¤šä»“ä¿¡å·: Z-score={z_score:.3f}\")\n",
    "        \n",
    "        return signal_generated\n",
    "    \n",
    "    def get_current_stats(self):\n",
    "        \"\"\"è·å–å½“å‰ç­–ç•¥ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        if not self.rolling_stats:\n",
    "            return {}\n",
    "        \n",
    "        current_spread = self.spread_history.iloc[-1] if len(self.spread_history) > 0 else 0\n",
    "        current_z_score = ((current_spread - self.rolling_stats['spread_mean']) / \n",
    "                          self.rolling_stats['spread_std'] if self.rolling_stats['spread_std'] > 0 else 0)\n",
    "        \n",
    "        return {\n",
    "            'current_spread': current_spread,\n",
    "            'current_z_score': current_z_score,\n",
    "            'position_status': self.position_status.copy(),\n",
    "            'trade_count': self.trade_count,\n",
    "            'rolling_stats': self.rolling_stats.copy()\n",
    "        }\n",
    "\n",
    "print(\"âœ… å¢å¼ºç­–ç•¥å®šä¹‰å®Œæˆ\")\n",
    "print(\"   â€¢ å®ç°ç­–ç•¥åŸºç±»å’Œä¿¡å·è¿‡æ»¤å™¨\")\n",
    "print(\"   â€¢ é›†æˆæ³¢åŠ¨ç‡è¿‡æ»¤å’Œæ—¶é—´è¿‡æ»¤\")\n",
    "print(\"   â€¢ æ”¯æŒåŠ¨æ€å‚æ•°è°ƒæ•´å’Œæ€§èƒ½è¿½è¸ª\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dc5f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicPortfolio:\n",
    "    \"\"\"\n",
    "    Manages positions, cash, and performance.\n",
    "    Generates orders based on signals.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_handler, events_queue, start_date, initial_capital=100000.0):\n",
    "        self.data_handler = data_handler\n",
    "        self.events = events_queue\n",
    "        self.start_date = start_date\n",
    "        self.initial_capital = initial_capital\n",
    "\n",
    "        # Positions is a dictionary mapping trading symbols to quantities\n",
    "        # For a spread, we hold two positions: e.g., {'NEAR': 10, 'FAR': -10}\n",
    "        self.current_positions = {'NEAR': 0, 'FAR': 0}\n",
    "        \n",
    "        # Holdings is a dictionary tracking the portfolio's value over time\n",
    "        self.all_holdings = []\n",
    "        self.current_holdings = self._construct_current_holdings()\n",
    "\n",
    "    def _construct_current_holdings(self):\n",
    "        \"\"\"Constructs the dictionary for current holdings.\"\"\"\n",
    "        d = {'datetime': self.start_date, 'cash': self.initial_capital, 'commission': 0.0, 'total': self.initial_capital}\n",
    "        return d\n",
    "    \n",
    "    def update_timeindex(self, event):\n",
    "        \"\"\"\n",
    "        Updates the portfolio's holdings value when a new market bar arrives.\n",
    "        This is our mark-to-market calculation.\n",
    "        \"\"\"\n",
    "        if event.type == 'MARKET':\n",
    "            bar = self.data_handler.get_latest_bar(self.data_handler.symbols[0])\n",
    "            dt = bar['Date']\n",
    "            \n",
    "            # Update holdings dictionary\n",
    "            self.current_holdings['datetime'] = dt\n",
    "            \n",
    "            # Update total value\n",
    "            total_value = self.current_holdings['cash']\n",
    "            total_value += self.current_positions['NEAR'] * bar['NEAR']\n",
    "            total_value += self.current_positions['FAR'] * bar['FAR']\n",
    "            self.current_holdings['total'] = total_value\n",
    "            \n",
    "            # Add to the list of all holdings\n",
    "            self.all_holdings.append(self.current_holdings.copy())\n",
    "\n",
    "    def update_positions_from_fill(self, fill):\n",
    "        \"\"\"Receives a FillEvent and updates the positions dictionary.\"\"\"\n",
    "        fill_dir = 1 if fill.direction == 'BUY' else -1\n",
    "        \n",
    "        # FillEvent's 'symbol' will be 'NEAR' or 'FAR'\n",
    "        self.current_positions[fill.symbol] += fill_dir * fill.quantity\n",
    "\n",
    "    def update_holdings_from_fill(self, fill):\n",
    "        \"\"\"Receives a FillEvent and updates the holdings dictionary.\"\"\"\n",
    "        fill_dir = 1 if fill.direction == 'BUY' else -1\n",
    "        \n",
    "        # Update cash\n",
    "        cost = fill.fill_cost * fill_dir\n",
    "        self.current_holdings['cash'] -= (cost + fill.commission)\n",
    "        self.current_holdings['commission'] += fill.commission\n",
    "\n",
    "    def generate_naive_order(self, signal):\n",
    "        \"\"\"\n",
    "        Simply converts a Signal object into OrderEvents for both legs of the spread.\n",
    "        Uses a fixed quantity for simplicity.\n",
    "        \"\"\"\n",
    "        if signal.type == 'SIGNAL':\n",
    "            quantity = 10 # Use a fixed quantity in this simple model\n",
    "            \n",
    "            if signal.signal_type == 'LONG_SPREAD': # Buy far-month, sell near-month\n",
    "                order_far = OrderEvent('FAR', 'MKT', quantity, 'BUY')\n",
    "                order_near = OrderEvent('NEAR', 'MKT', quantity, 'SELL')\n",
    "            elif signal.signal_type == 'SHORT_SPREAD': # Sell far-month, buy near-month\n",
    "                order_far = OrderEvent('FAR', 'MKT', quantity, 'SELL')\n",
    "                order_near = OrderEvent('NEAR', 'MKT', quantity, 'BUY')\n",
    "            elif signal.signal_type == 'EXIT_LONG': # Close long spread -> sell far-month, buy near-month\n",
    "                order_far = OrderEvent('FAR', 'MKT', self.current_positions['FAR'], 'SELL')\n",
    "                order_near = OrderEvent('NEAR', 'MKT', abs(self.current_positions['NEAR']), 'BUY')\n",
    "            elif signal.signal_type == 'EXIT_SHORT': # Close short spread -> buy far-month, sell near-month\n",
    "                order_far = OrderEvent('FAR', 'MKT', abs(self.current_positions['FAR']), 'BUY')\n",
    "                order_near = OrderEvent('NEAR', 'MKT', self.current_positions['NEAR'], 'SELL')\n",
    "            \n",
    "            self.events.put(order_far)\n",
    "            self.events.put(order_near)\n",
    "\n",
    "    def create_equity_curve_dataframe(self):\n",
    "        \"\"\"Creates a pandas DataFrame from the all_holdings list.\"\"\"\n",
    "        curve = pd.DataFrame(self.all_holdings)\n",
    "        curve.set_index('datetime', inplace=True)\n",
    "        curve['returns'] = curve['total'].pct_change()\n",
    "        curve['equity_curve'] = (1.0 + curve['returns']).cumprod()\n",
    "        return curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd83355d",
   "metadata": {},
   "source": [
    "## 5. ç»„åˆä¸æ‰§è¡Œæ¨¡å— (Portfolio & Execution Module)\n",
    "åŒ…å«åŠ¨æ€å¤´å¯¸ç®¡ç†ã€ç²¾ç»†åŒ–äº¤æ˜“æˆæœ¬æ¨¡å‹å’Œé£é™©æ§åˆ¶åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e558a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åŠ¨æ€å¤´å¯¸ç®¡ç†å™¨å’Œäº¤æ˜“æˆæœ¬æ¨¡å‹å®šä¹‰å®Œæˆ\n",
      "   â€¢ æ”¯æŒå›ºå®šå¤´å¯¸ã€å›ºå®šé£é™©ã€æ³¢åŠ¨ç‡å€’æ•°ä¸‰ç§æ–¹æ³•\n",
      "   â€¢ å®ç°åŠ¨æ€æ»‘ç‚¹å’Œä½£é‡‘è®¡ç®—\n",
      "   â€¢ åŒ…å«å¤§å•å†²å‡»å’Œæ³¢åŠ¨ç‡è°ƒæ•´æœºåˆ¶\n"
     ]
    }
   ],
   "source": [
    "class PositionSizer:\n",
    "    \"\"\"\n",
    "    åŠ¨æ€å¤´å¯¸è§„æ¨¡ç®¡ç†å™¨\n",
    "    æ”¯æŒå¤šç§å¤´å¯¸è®¡ç®—æ–¹æ³•\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n",
    "    \n",
    "    def fixed_size(self, **kwargs):\n",
    "        \"\"\"å›ºå®šæ‰‹æ•°æ–¹æ³•\"\"\"\n",
    "        return self.config.position_size\n",
    "    \n",
    "    def fixed_risk_percentage(self, portfolio_value, entry_price, stop_loss_price, \n",
    "                             risk_percentage=0.01):\n",
    "        \"\"\"\n",
    "        å›ºå®šé£é™©ç™¾åˆ†æ¯”æ–¹æ³•\n",
    "        æ¯ç¬”äº¤æ˜“çš„é£é™©é‡‘é¢ = æŠ•èµ„ç»„åˆä»·å€¼ * é£é™©ç™¾åˆ†æ¯”\n",
    "        \"\"\"\n",
    "        if stop_loss_price == 0 or entry_price == stop_loss_price:\n",
    "            return self.fixed_size()\n",
    "        \n",
    "        risk_amount = portfolio_value * risk_percentage\n",
    "        price_risk_per_unit = abs(entry_price - stop_loss_price)\n",
    "        \n",
    "        position_size = int(risk_amount / price_risk_per_unit)\n",
    "        \n",
    "        # é™åˆ¶æœ€å¤§å¤´å¯¸\n",
    "        max_size = self.config.position_size * 3\n",
    "        position_size = min(position_size, max_size)\n",
    "        position_size = max(position_size, 1)  # è‡³å°‘1æ‰‹\n",
    "        \n",
    "        self.logger.debug(f\"å›ºå®šé£é™©ç™¾åˆ†æ¯”: é£é™©é‡‘é¢={risk_amount:.2f}, å¤´å¯¸={position_size}\")\n",
    "        return position_size\n",
    "    \n",
    "    def inverse_volatility(self, price_series, portfolio_value, target_volatility=0.15):\n",
    "        \"\"\"\n",
    "        æ³¢åŠ¨ç‡å€’æ•°æ¨¡å‹\n",
    "        ä¸ºä½æ³¢åŠ¨ç‡çš„èµ„äº§åˆ†é…æ›´é«˜çš„æƒé‡\n",
    "        \"\"\"\n",
    "        if len(price_series) < 20:\n",
    "            return self.fixed_size()\n",
    "        \n",
    "        # è®¡ç®—å·²å®ç°æ³¢åŠ¨ç‡\n",
    "        daily_returns = price_series.pct_change().dropna()\n",
    "        if len(daily_returns) < 10:\n",
    "            return self.fixed_size()\n",
    "        \n",
    "        realized_vol = daily_returns.tail(20).std() * np.sqrt(252)\n",
    "        \n",
    "        if realized_vol == 0:\n",
    "            return self.fixed_size()\n",
    "        \n",
    "        # è®¡ç®—ç›®æ ‡å¤´å¯¸\n",
    "        vol_adjusted_weight = target_volatility / realized_vol\n",
    "        \n",
    "        # åŸºç¡€å¤´å¯¸ * æ³¢åŠ¨ç‡è°ƒæ•´ç³»æ•°\n",
    "        base_size = self.config.position_size\n",
    "        adjusted_size = int(base_size * vol_adjusted_weight)\n",
    "        \n",
    "        # é™åˆ¶å¤´å¯¸èŒƒå›´\n",
    "        min_size = max(1, base_size // 2)\n",
    "        max_size = base_size * 3\n",
    "        adjusted_size = max(min(adjusted_size, max_size), min_size)\n",
    "        \n",
    "        self.logger.debug(f\"æ³¢åŠ¨ç‡å€’æ•°: å·²å®ç°æ³¢åŠ¨ç‡={realized_vol:.3f}, è°ƒæ•´åå¤´å¯¸={adjusted_size}\")\n",
    "        return adjusted_size\n",
    "    \n",
    "    def calculate_position_size(self, method=\"fixed\", **kwargs):\n",
    "        \"\"\"\n",
    "        æ ¹æ®æŒ‡å®šæ–¹æ³•è®¡ç®—å¤´å¯¸å¤§å°\n",
    "        \n",
    "        Args:\n",
    "            method: 'fixed', 'fixed_risk', 'inverse_volatility'\n",
    "            **kwargs: å„æ–¹æ³•æ‰€éœ€çš„é¢å¤–å‚æ•°\n",
    "        \"\"\"\n",
    "        if method == \"fixed\":\n",
    "            return self.fixed_size()\n",
    "        elif method == \"fixed_risk\":\n",
    "            return self.fixed_risk_percentage(**kwargs)\n",
    "        elif method == \"inverse_volatility\":\n",
    "            return self.inverse_volatility(**kwargs)\n",
    "        else:\n",
    "            self.logger.warning(f\"æœªçŸ¥çš„å¤´å¯¸è®¡ç®—æ–¹æ³•: {method}ï¼Œä½¿ç”¨å›ºå®šå¤´å¯¸\")\n",
    "            return self.fixed_size()\n",
    "\n",
    "class CostModel:\n",
    "    \"\"\"\n",
    "    ç²¾ç»†åŒ–çš„äº¤æ˜“æˆæœ¬æ¨¡å‹\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n",
    "    \n",
    "    def calculate_commission(self, quantity, price):\n",
    "        \"\"\"è®¡ç®—ä½£é‡‘\"\"\"\n",
    "        if self.config.commission_type == \"fixed\":\n",
    "            commission = self.config.commission_per_trade * abs(quantity)\n",
    "        elif self.config.commission_type == \"percentage\":\n",
    "            commission = price * abs(quantity) * self.config.commission_rate\n",
    "        else:\n",
    "            commission = self.config.commission_per_trade * abs(quantity)\n",
    "        \n",
    "        return commission\n",
    "    \n",
    "    def calculate_slippage(self, direction, price, quantity, volatility=None):\n",
    "        \"\"\"\n",
    "        è®¡ç®—æ»‘ç‚¹\n",
    "        æ”¯æŒå›ºå®šæ»‘ç‚¹å’ŒåŠ¨æ€æ»‘ç‚¹\n",
    "        \"\"\"\n",
    "        base_slippage = self.config.slippage_per_trade\n",
    "        \n",
    "        # æ ¹æ®äº¤æ˜“æ–¹å‘è°ƒæ•´\n",
    "        if direction == 'BUY':\n",
    "            slippage = base_slippage\n",
    "        else:  # SELL\n",
    "            slippage = -base_slippage\n",
    "        \n",
    "        # å¦‚æœæä¾›äº†æ³¢åŠ¨ç‡ï¼Œå¯ä»¥åŠ¨æ€è°ƒæ•´æ»‘ç‚¹\n",
    "        if volatility is not None:\n",
    "            # é«˜æ³¢åŠ¨ç‡æ—¶å¢åŠ æ»‘ç‚¹\n",
    "            volatility_multiplier = max(1.0, volatility * 10)\n",
    "            slippage *= volatility_multiplier\n",
    "        \n",
    "        # å¤§å•å½±å“ï¼šå¤´å¯¸è¶Šå¤§ï¼Œæ»‘ç‚¹è¶Šå¤§\n",
    "        if abs(quantity) > self.config.position_size:\n",
    "            size_multiplier = abs(quantity) / self.config.position_size\n",
    "            slippage *= (1 + 0.1 * (size_multiplier - 1))  # æ¯å¢åŠ 1å€å¤´å¯¸ï¼Œæ»‘ç‚¹å¢åŠ 10%\n",
    "        \n",
    "        return slippage\n",
    "    \n",
    "    def calculate_bid_ask_spread(self, price, spread_percentage=0.001):\n",
    "        \"\"\"\n",
    "        è®¡ç®—ä¹°å–ä»·å·®æˆæœ¬\n",
    "        åœ¨æ²¡æœ‰å®é™…ä¹°å–ä»·æ—¶çš„ä¼°ç®—\n",
    "        \"\"\"\n",
    "        spread = price * spread_percentage\n",
    "        return spread / 2  # å•è¾¹æˆæœ¬\n",
    "\n",
    "print(\"âœ… åŠ¨æ€å¤´å¯¸ç®¡ç†å™¨å’Œäº¤æ˜“æˆæœ¬æ¨¡å‹å®šä¹‰å®Œæˆ\")\n",
    "print(\"   â€¢ æ”¯æŒå›ºå®šå¤´å¯¸ã€å›ºå®šé£é™©ã€æ³¢åŠ¨ç‡å€’æ•°ä¸‰ç§æ–¹æ³•\")\n",
    "print(\"   â€¢ å®ç°åŠ¨æ€æ»‘ç‚¹å’Œä½£é‡‘è®¡ç®—\")\n",
    "print(\"   â€¢ åŒ…å«å¤§å•å†²å‡»å’Œæ³¢åŠ¨ç‡è°ƒæ•´æœºåˆ¶\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0df70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¢å¼ºæŠ•èµ„ç»„åˆç®¡ç†å™¨å®šä¹‰å®Œæˆ\n",
      "   â€¢ é›†æˆåŠ¨æ€å¤´å¯¸ç®¡ç†å’Œäº¤æ˜“æˆæœ¬æ¨¡å‹\n",
      "   â€¢ å®ç°é£é™©é™åˆ¶å’Œå›æ’¤æ§åˆ¶\n",
      "   â€¢ åŒ…å«è¯¦ç»†çš„äº¤æ˜“è®°å½•å’Œæ€§èƒ½è¿½è¸ª\n"
     ]
    }
   ],
   "source": [
    "class EnhancedPortfolio:\n",
    "    \"\"\"\n",
    "    å¢å¼ºçš„æŠ•èµ„ç»„åˆç®¡ç†å™¨\n",
    "    é›†æˆåŠ¨æ€å¤´å¯¸ç®¡ç†å’Œé£é™©æ§åˆ¶\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_handler, events_queue, config):\n",
    "        self.data_handler = data_handler\n",
    "        self.events = events_queue\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n",
    "        \n",
    "        # åˆå§‹åŒ–ç»„ä»¶\n",
    "        self.position_sizer = PositionSizer(config)\n",
    "        self.cost_model = CostModel(config)\n",
    "        \n",
    "        # æŠ•èµ„ç»„åˆçŠ¶æ€\n",
    "        self.initial_capital = config.initial_capital\n",
    "        self.current_positions = {'NEAR': 0, 'FAR': 0}\n",
    "        self.position_history = []\n",
    "        \n",
    "        # èµ„é‡‘ç®¡ç†\n",
    "        self.all_holdings = []\n",
    "        self.current_holdings = self._construct_current_holdings()\n",
    "        \n",
    "        # é£é™©æŒ‡æ ‡\n",
    "        self.max_drawdown = 0.0\n",
    "        self.peak_value = self.initial_capital\n",
    "        self.drawdown_history = []\n",
    "        \n",
    "        # äº¤æ˜“ç»Ÿè®¡\n",
    "        self.trade_log = []\n",
    "        self.performance_metrics = {}\n",
    "    \n",
    "    def _construct_current_holdings(self):\n",
    "        \"\"\"æ„å»ºå½“å‰æŒä»“å­—å…¸\"\"\"\n",
    "        d = {\n",
    "            'datetime': self.config.start_date,\n",
    "            'cash': self.initial_capital,\n",
    "            'commission': 0.0,\n",
    "            'total': self.initial_capital,\n",
    "            'unrealized_pnl': 0.0,\n",
    "            'realized_pnl': 0.0\n",
    "        }\n",
    "        return d\n",
    "    \n",
    "    def update_timeindex(self, event):\n",
    "        \"\"\"æ›´æ–°æ—¶é—´ç´¢å¼•å’Œå¸‚å€¼è®¡ç®—\"\"\"\n",
    "        if event.type != 'MARKET':\n",
    "            return\n",
    "        \n",
    "        bar = self.data_handler.get_latest_bar(self.data_handler.symbols[0])\n",
    "        if bar is None:\n",
    "            return\n",
    "        \n",
    "        # è·å–æ—¶é—´æˆ³\n",
    "        if hasattr(bar, 'Date'):\n",
    "            dt = bar['Date']\n",
    "        elif hasattr(bar, 'index'):\n",
    "            dt = bar['index']\n",
    "        else:\n",
    "            dt = bar[0] if len(bar) > 0 else self.current_holdings['datetime']\n",
    "        \n",
    "        # æ›´æ–°æŒä»“å¸‚å€¼\n",
    "        self.current_holdings['datetime'] = dt\n",
    "        \n",
    "        # è®¡ç®—æŒä»“å¸‚å€¼\n",
    "        position_value = (self.current_positions['NEAR'] * bar['NEAR'] + \n",
    "                         self.current_positions['FAR'] * bar['FAR'])\n",
    "        \n",
    "        # è®¡ç®—æœªå®ç°ç›ˆäº\n",
    "        total_value = self.current_holdings['cash'] + position_value\n",
    "        self.current_holdings['total'] = total_value\n",
    "        self.current_holdings['unrealized_pnl'] = position_value\n",
    "        \n",
    "        # æ›´æ–°æœ€å¤§å›æ’¤\n",
    "        self._update_drawdown_metrics(total_value)\n",
    "        \n",
    "        # ä¿å­˜å†å²è®°å½•\n",
    "        self.all_holdings.append(self.current_holdings.copy())\n",
    "        \n",
    "        # è®°å½•å¤´å¯¸å†å²\n",
    "        position_record = {\n",
    "            'datetime': dt,\n",
    "            'near_position': self.current_positions['NEAR'],\n",
    "            'far_position': self.current_positions['FAR'],\n",
    "            'total_value': total_value\n",
    "        }\n",
    "        self.position_history.append(position_record)\n",
    "    \n",
    "    def _update_drawdown_metrics(self, current_value):\n",
    "        \"\"\"æ›´æ–°å›æ’¤æŒ‡æ ‡\"\"\"\n",
    "        if current_value > self.peak_value:\n",
    "            self.peak_value = current_value\n",
    "        \n",
    "        current_drawdown = (self.peak_value - current_value) / self.peak_value\n",
    "        self.max_drawdown = max(self.max_drawdown, current_drawdown)\n",
    "        \n",
    "        self.drawdown_history.append({\n",
    "            'datetime': self.current_holdings['datetime'],\n",
    "            'drawdown': current_drawdown,\n",
    "            'peak_value': self.peak_value\n",
    "        })\n",
    "    \n",
    "    def generate_orders(self, signal):\n",
    "        \"\"\"\n",
    "        æ ¹æ®ä¿¡å·ç”Ÿæˆè®¢å•\n",
    "        é›†æˆåŠ¨æ€å¤´å¯¸ç®¡ç†\n",
    "        \"\"\"\n",
    "        if signal.type != 'SIGNAL':\n",
    "            return\n",
    "        \n",
    "        # è·å–å½“å‰å¸‚åœºæ•°æ®\n",
    "        bar = self.data_handler.get_latest_bar(self.data_handler.symbols[0])\n",
    "        if bar is None:\n",
    "            return\n",
    "        \n",
    "        # è·å–ä»·æ ¼å†å²ç”¨äºå¤´å¯¸è®¡ç®—\n",
    "        price_history = pd.Series([h['total'] for h in self.all_holdings[-30:]])  # æœ€è¿‘30å¤©\n",
    "        \n",
    "        # è®¡ç®—å¤´å¯¸å¤§å°\n",
    "        position_size = self.position_sizer.calculate_position_size(\n",
    "            method=\"inverse_volatility\",\n",
    "            price_series=price_history,\n",
    "            portfolio_value=self.current_holdings['total']\n",
    "        )\n",
    "        \n",
    "        # æ£€æŸ¥é£é™©é™åˆ¶\n",
    "        if not self._check_risk_limits(position_size):\n",
    "            self.logger.warning(\"å¤´å¯¸è¶…è¿‡é£é™©é™åˆ¶ï¼Œæ‹’ç»äº¤æ˜“\")\n",
    "            return\n",
    "        \n",
    "        # ç”Ÿæˆè®¢å•\n",
    "        orders = self._create_orders(signal, position_size)\n",
    "        \n",
    "        for order in orders:\n",
    "            self.events.put(order)\n",
    "            self.logger.info(f\"ç”Ÿæˆè®¢å•: {order.symbol} {order.direction} {order.quantity}æ‰‹\")\n",
    "    \n",
    "    def _check_risk_limits(self, new_position_size):\n",
    "        \"\"\"æ£€æŸ¥é£é™©é™åˆ¶\"\"\"\n",
    "        # æ£€æŸ¥æœ€å¤§å¤´å¯¸é™åˆ¶\n",
    "        current_total_position = abs(self.current_positions['NEAR']) + abs(self.current_positions['FAR'])\n",
    "        if current_total_position + new_position_size * 2 > self.config.max_positions * 2:\n",
    "            return False\n",
    "        \n",
    "        # æ£€æŸ¥æœ€å¤§å›æ’¤é™åˆ¶\n",
    "        if self.max_drawdown > 0.20:  # 20%æœ€å¤§å›æ’¤é™åˆ¶\n",
    "            self.logger.warning(f\"å·²è¾¾åˆ°æœ€å¤§å›æ’¤é™åˆ¶: {self.max_drawdown:.2%}\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _create_orders(self, signal, quantity):\n",
    "        \"\"\"åˆ›å»ºå…·ä½“çš„è®¢å•\"\"\"\n",
    "        orders = []\n",
    "        \n",
    "        if signal.signal_type == 'LONG_SPREAD':\n",
    "            # ä¹°å…¥ä»·å·®ï¼šä¹°è¿œæœˆï¼Œå–è¿‘æœˆ\n",
    "            orders.append(OrderEvent('FAR', 'MKT', quantity, 'BUY'))\n",
    "            orders.append(OrderEvent('NEAR', 'MKT', quantity, 'SELL'))\n",
    "            \n",
    "        elif signal.signal_type == 'SHORT_SPREAD':\n",
    "            # å–å‡ºä»·å·®ï¼šå–è¿œæœˆï¼Œä¹°è¿‘æœˆ\n",
    "            orders.append(OrderEvent('FAR', 'MKT', quantity, 'SELL'))\n",
    "            orders.append(OrderEvent('NEAR', 'MKT', quantity, 'BUY'))\n",
    "            \n",
    "        elif signal.signal_type == 'EXIT_LONG':\n",
    "            # å¹³å¤šå¤´ä»·å·®ï¼šå–è¿œæœˆï¼Œä¹°è¿‘æœˆ\n",
    "            far_position = self.current_positions['FAR']\n",
    "            near_position = self.current_positions['NEAR']\n",
    "            \n",
    "            if far_position > 0:\n",
    "                orders.append(OrderEvent('FAR', 'MKT', far_position, 'SELL'))\n",
    "            if near_position < 0:\n",
    "                orders.append(OrderEvent('NEAR', 'MKT', abs(near_position), 'BUY'))\n",
    "                \n",
    "        elif signal.signal_type == 'EXIT_SHORT':\n",
    "            # å¹³ç©ºå¤´ä»·å·®ï¼šä¹°è¿œæœˆï¼Œå–è¿‘æœˆ\n",
    "            far_position = self.current_positions['FAR']\n",
    "            near_position = self.current_positions['NEAR']\n",
    "            \n",
    "            if far_position < 0:\n",
    "                orders.append(OrderEvent('FAR', 'MKT', abs(far_position), 'BUY'))\n",
    "            if near_position > 0:\n",
    "                orders.append(OrderEvent('NEAR', 'MKT', near_position, 'SELL'))\n",
    "        \n",
    "        return orders\n",
    "    \n",
    "    def update_positions_from_fill(self, fill):\n",
    "        \"\"\"æ ¹æ®æˆäº¤æ›´æ–°å¤´å¯¸\"\"\"\n",
    "        fill_dir = 1 if fill.direction == 'BUY' else -1\n",
    "        self.current_positions[fill.symbol] += fill_dir * fill.quantity\n",
    "        \n",
    "        # è®°å½•äº¤æ˜“\n",
    "        trade_record = {\n",
    "            'datetime': fill.timeindex,\n",
    "            'symbol': fill.symbol,\n",
    "            'direction': fill.direction,\n",
    "            'quantity': fill.quantity,\n",
    "            'price': fill.fill_cost / fill.quantity,\n",
    "            'commission': fill.commission\n",
    "        }\n",
    "        self.trade_log.append(trade_record)\n",
    "    \n",
    "    def update_holdings_from_fill(self, fill):\n",
    "        \"\"\"æ ¹æ®æˆäº¤æ›´æ–°èµ„é‡‘\"\"\"\n",
    "        fill_dir = 1 if fill.direction == 'BUY' else -1\n",
    "        \n",
    "        # æ›´æ–°ç°é‡‘\n",
    "        cost = fill.fill_cost * fill_dir\n",
    "        self.current_holdings['cash'] -= (cost + fill.commission)\n",
    "        self.current_holdings['commission'] += fill.commission\n",
    "        self.current_holdings['realized_pnl'] -= cost  # ç´¯è®¡å·²å®ç°ç›ˆäº\n",
    "    \n",
    "    def create_equity_curve_dataframe(self):\n",
    "        \"\"\"åˆ›å»ºå‡€å€¼æ›²çº¿æ•°æ®æ¡†\"\"\"\n",
    "        curve = pd.DataFrame(self.all_holdings)\n",
    "        \n",
    "        if len(curve) > 0:\n",
    "            curve.set_index('datetime', inplace=True)\n",
    "            curve['returns'] = curve['total'].pct_change()\n",
    "            curve['equity_curve'] = curve['total'] / self.initial_capital\n",
    "            curve['cumulative_returns'] = curve['equity_curve'] - 1\n",
    "            \n",
    "            # æ·»åŠ å›æ’¤æ•°æ®\n",
    "            curve['peak'] = curve['total'].expanding().max()\n",
    "            curve['drawdown'] = (curve['total'] - curve['peak']) / curve['peak']\n",
    "        \n",
    "        return curve\n",
    "    \n",
    "    def get_performance_summary(self):\n",
    "        \"\"\"è·å–æ€§èƒ½æ‘˜è¦\"\"\"\n",
    "        if len(self.all_holdings) == 0:\n",
    "            return {}\n",
    "        \n",
    "        curve = self.create_equity_curve_dataframe()\n",
    "        \n",
    "        total_return = (self.current_holdings['total'] - self.initial_capital) / self.initial_capital\n",
    "        \n",
    "        if len(curve) > 1:\n",
    "            returns = curve['returns'].dropna()\n",
    "            sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "            sortino_ratio = returns.mean() / returns[returns < 0].std() * np.sqrt(252) if len(returns[returns < 0]) > 0 else 0\n",
    "        else:\n",
    "            sharpe_ratio = 0\n",
    "            sortino_ratio = 0\n",
    "        \n",
    "        return {\n",
    "            'total_return': total_return,\n",
    "            'max_drawdown': self.max_drawdown,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'sortino_ratio': sortino_ratio,\n",
    "            'total_trades': len(self.trade_log),\n",
    "            'final_value': self.current_holdings['total'],\n",
    "            'total_commission': self.current_holdings['commission']\n",
    "        }\n",
    "\n",
    "print(\"âœ… å¢å¼ºæŠ•èµ„ç»„åˆç®¡ç†å™¨å®šä¹‰å®Œæˆ\")\n",
    "print(\"   â€¢ é›†æˆåŠ¨æ€å¤´å¯¸ç®¡ç†å’Œäº¤æ˜“æˆæœ¬æ¨¡å‹\")\n",
    "print(\"   â€¢ å®ç°é£é™©é™åˆ¶å’Œå›æ’¤æ§åˆ¶\")\n",
    "print(\"   â€¢ åŒ…å«è¯¦ç»†çš„äº¤æ˜“è®°å½•å’Œæ€§èƒ½è¿½è¸ª\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09e7ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatedExecutionHandler:\n",
    "    \"\"\"\n",
    "    Simulates the execution of orders, including slippage and commission.\n",
    "    \"\"\"\n",
    "    def __init__(self, events_queue, data_handler, commission_per_trade=5.0, slippage_per_trade=0.01):\n",
    "        self.events = events_queue\n",
    "        self.data_handler = data_handler\n",
    "        self.commission = commission_per_trade\n",
    "        self.slippage = slippage_per_trade\n",
    "\n",
    "    def execute_order(self, event):\n",
    "        \"\"\"\n",
    "        Receives an OrderEvent and converts it into a FillEvent.\n",
    "        \"\"\"\n",
    "        if event.type == 'ORDER':\n",
    "            # Get the current market price of the contract leg being traded\n",
    "            bar = self.data_handler.get_latest_bar(self.data_handler.symbols[0])\n",
    "            price = bar[event.symbol]\n",
    "            \n",
    "            # Apply slippage\n",
    "            if event.direction == 'BUY':\n",
    "                fill_price = price + self.slippage\n",
    "            else: # SELL\n",
    "                fill_price = price - self.slippage\n",
    "            \n",
    "            fill_cost = fill_price * event.quantity\n",
    "            \n",
    "            fill_event = FillEvent(\n",
    "                bar['Date'], event.symbol, 'SIMULATED', \n",
    "                event.quantity, event.direction, fill_cost, self.commission\n",
    "            )\n",
    "            self.events.put(fill_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac356c7",
   "metadata": {},
   "source": [
    "### 5.1 ç²¾ç»†åŒ–æ‰§è¡Œç³»ç»Ÿ (Enhanced Execution System)\n",
    "é›†æˆåŠ¨æ€æ»‘ç‚¹æ¨¡å‹å’Œè®¢å•ç®¡ç†åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd8de179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¢å¼ºæ‰§è¡Œç³»ç»Ÿå®šä¹‰å®Œæˆ\n",
      "   â€¢ é›†æˆåŠ¨æ€æ»‘ç‚¹å’Œæ³¢åŠ¨ç‡è®¡ç®—\n",
      "   â€¢ å®ç°ç²¾ç»†åŒ–ä½£é‡‘å’Œæˆæœ¬æ§åˆ¶\n",
      "   â€¢ åŒ…å«æ‰§è¡Œç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§\n"
     ]
    }
   ],
   "source": [
    "class EnhancedExecutionHandler:\n",
    "    \"\"\"\n",
    "    å¢å¼ºçš„æ‰§è¡Œå¤„ç†å™¨\n",
    "    é›†æˆç²¾ç»†åŒ–äº¤æ˜“æˆæœ¬æ¨¡å‹å’Œå¸‚åœºå†²å‡»æ¨¡æ‹Ÿ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, events_queue, data_handler, config):\n",
    "        self.events = events_queue\n",
    "        self.data_handler = data_handler\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n",
    "        \n",
    "        # åˆå§‹åŒ–æˆæœ¬æ¨¡å‹\n",
    "        self.cost_model = CostModel(config)\n",
    "        \n",
    "        # æ‰§è¡Œç»Ÿè®¡\n",
    "        self.execution_stats = {\n",
    "            'total_orders': 0,\n",
    "            'total_fills': 0,\n",
    "            'total_commission': 0.0,\n",
    "            'total_slippage': 0.0\n",
    "        }\n",
    "        \n",
    "        # ä»·æ ¼å†å²ç”¨äºæ³¢åŠ¨ç‡è®¡ç®—\n",
    "        self.price_history = {}\n",
    "    \n",
    "    def execute_order(self, event):\n",
    "        \"\"\"æ‰§è¡Œè®¢å•å¹¶ç”Ÿæˆæˆäº¤äº‹ä»¶\"\"\"\n",
    "        if event.type != 'ORDER':\n",
    "            return\n",
    "        \n",
    "        # è·å–å½“å‰å¸‚åœºæ•°æ®\n",
    "        bar = self.data_handler.get_latest_bar(self.data_handler.symbols[0])\n",
    "        if bar is None:\n",
    "            self.logger.error(\"æ— æ³•è·å–å¸‚åœºæ•°æ®ï¼Œè®¢å•æ‰§è¡Œå¤±è´¥\")\n",
    "            return\n",
    "        \n",
    "        # è·å–æ—¶é—´æˆ³\n",
    "        if hasattr(bar, 'Date'):\n",
    "            bar_date = bar['Date']\n",
    "        elif hasattr(bar, 'index'):\n",
    "            bar_date = bar['index']\n",
    "        else:\n",
    "            bar_date = bar[0] if len(bar) > 0 else pd.Timestamp.now()\n",
    "        \n",
    "        # è·å–åŸºå‡†ä»·æ ¼\n",
    "        base_price = bar[event.symbol]\n",
    "        \n",
    "        # æ›´æ–°ä»·æ ¼å†å²\n",
    "        self._update_price_history(event.symbol, base_price, bar_date)\n",
    "        \n",
    "        # è®¡ç®—å½“å‰æ³¢åŠ¨ç‡\n",
    "        volatility = self._calculate_volatility(event.symbol)\n",
    "        \n",
    "        # è®¡ç®—æ»‘ç‚¹\n",
    "        slippage = self.cost_model.calculate_slippage(\n",
    "            event.direction, base_price, event.quantity, volatility\n",
    "        )\n",
    "        \n",
    "        # è®¡ç®—æœ€ç»ˆæˆäº¤ä»·æ ¼\n",
    "        if event.direction == 'BUY':\n",
    "            fill_price = base_price + abs(slippage)\n",
    "        else:  # SELL\n",
    "            fill_price = base_price - abs(slippage)\n",
    "        \n",
    "        # ç¡®ä¿ä»·æ ¼åˆç†æ€§\n",
    "        fill_price = max(fill_price, 0.01)  # ä»·æ ¼ä¸èƒ½ä¸ºè´Ÿæˆ–è¿‡å°\n",
    "        \n",
    "        # è®¡ç®—æˆäº¤é‡‘é¢\n",
    "        fill_cost = fill_price * event.quantity\n",
    "        \n",
    "        # è®¡ç®—ä½£é‡‘\n",
    "        commission = self.cost_model.calculate_commission(event.quantity, fill_price)\n",
    "        \n",
    "        # åˆ›å»ºæˆäº¤äº‹ä»¶\n",
    "        fill_event = FillEvent(\n",
    "            timeindex=bar_date,\n",
    "            symbol=event.symbol,\n",
    "            exchange='SIMULATED',\n",
    "            quantity=event.quantity,\n",
    "            direction=event.direction,\n",
    "            fill_cost=fill_cost,\n",
    "            commission=commission\n",
    "        )\n",
    "        \n",
    "        # å‘é€æˆäº¤äº‹ä»¶\n",
    "        self.events.put(fill_event)\n",
    "        \n",
    "        # æ›´æ–°ç»Ÿè®¡\n",
    "        self._update_execution_stats(slippage, commission)\n",
    "        \n",
    "        # è®°å½•æ‰§è¡Œè¯¦æƒ…\n",
    "        self.logger.info(\n",
    "            f\"è®¢å•æ‰§è¡Œ: {event.symbol} {event.direction} {event.quantity}æ‰‹ \"\n",
    "            f\"@ {fill_price:.4f} (åŸºå‡†ä»·:{base_price:.4f}, æ»‘ç‚¹:{slippage:.4f}, \"\n",
    "            f\"ä½£é‡‘:{commission:.2f})\"\n",
    "        )\n",
    "    \n",
    "    def _update_price_history(self, symbol, price, timestamp):\n",
    "        \"\"\"æ›´æ–°ä»·æ ¼å†å²\"\"\"\n",
    "        if symbol not in self.price_history:\n",
    "            self.price_history[symbol] = pd.Series(dtype=float)\n",
    "        \n",
    "        self.price_history[symbol][timestamp] = price\n",
    "        \n",
    "        # åªä¿ç•™æœ€è¿‘100ä¸ªæ•°æ®ç‚¹\n",
    "        if len(self.price_history[symbol]) > 100:\n",
    "            self.price_history[symbol] = self.price_history[symbol].tail(100)\n",
    "    \n",
    "    def _calculate_volatility(self, symbol, window=20):\n",
    "        \"\"\"è®¡ç®—å†å²æ³¢åŠ¨ç‡\"\"\"\n",
    "        if symbol not in self.price_history or len(self.price_history[symbol]) < window:\n",
    "            return 0.02  # é»˜è®¤æ³¢åŠ¨ç‡\n",
    "        \n",
    "        prices = self.price_history[symbol].tail(window)\n",
    "        returns = prices.pct_change().dropna()\n",
    "        \n",
    "        if len(returns) < 5:\n",
    "            return 0.02\n",
    "        \n",
    "        volatility = returns.std() * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡\n",
    "        return volatility\n",
    "    \n",
    "    def _update_execution_stats(self, slippage, commission):\n",
    "        \"\"\"æ›´æ–°æ‰§è¡Œç»Ÿè®¡\"\"\"\n",
    "        self.execution_stats['total_orders'] += 1\n",
    "        self.execution_stats['total_fills'] += 1\n",
    "        self.execution_stats['total_commission'] += commission\n",
    "        self.execution_stats['total_slippage'] += abs(slippage)\n",
    "    \n",
    "    def get_execution_summary(self):\n",
    "        \"\"\"è·å–æ‰§è¡Œæ‘˜è¦\"\"\"\n",
    "        return {\n",
    "            'total_executed_orders': self.execution_stats['total_fills'],\n",
    "            'average_commission_per_trade': (\n",
    "                self.execution_stats['total_commission'] / max(1, self.execution_stats['total_fills'])\n",
    "            ),\n",
    "            'average_slippage_per_trade': (\n",
    "                self.execution_stats['total_slippage'] / max(1, self.execution_stats['total_fills'])\n",
    "            ),\n",
    "            'total_transaction_cost': (\n",
    "                self.execution_stats['total_commission'] + self.execution_stats['total_slippage']\n",
    "            )\n",
    "        }\n",
    "\n",
    "print(\"âœ… å¢å¼ºæ‰§è¡Œç³»ç»Ÿå®šä¹‰å®Œæˆ\")\n",
    "print(\"   â€¢ é›†æˆåŠ¨æ€æ»‘ç‚¹å’Œæ³¢åŠ¨ç‡è®¡ç®—\")\n",
    "print(\"   â€¢ å®ç°ç²¾ç»†åŒ–ä½£é‡‘å’Œæˆæœ¬æ§åˆ¶\")\n",
    "print(\"   â€¢ åŒ…å«æ‰§è¡Œç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd736fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backtest:\n",
    "    \"\"\"\n",
    "    Main backtest coordinator.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, csv_path, symbol, initial_capital, lookback, z_score,\n",
    "        start_date, data_handler_cls, strategy_cls, portfolio_cls, execution_handler_cls\n",
    "    ):\n",
    "        self.events = queue.Queue()\n",
    "        self.csv_path = csv_path\n",
    "        self.symbol_list = [symbol]\n",
    "        self.initial_capital = initial_capital\n",
    "        self.start_date = start_date\n",
    "        \n",
    "        self.data_handler = data_handler_cls(self.events, self.csv_path, self.symbol_list)\n",
    "        self.strategy = strategy_cls(self.data_handler, self.events, symbol, lookback, z_score)\n",
    "        self.portfolio = portfolio_cls(self.data_handler, self.events, self.start_date, self.initial_capital)\n",
    "        self.execution_handler = execution_handler_cls(self.events, self.data_handler)\n",
    "        \n",
    "    def _run_backtest(self):\n",
    "        \"\"\"Main event loop.\"\"\"\n",
    "        print(\"Running backtest...\")\n",
    "        while True:\n",
    "            # Update bars (push a MarketEvent if new data is available)\n",
    "            self.data_handler.update_bars()\n",
    "            \n",
    "            if not self.data_handler.continue_backtest:\n",
    "                break\n",
    "                \n",
    "            while True:\n",
    "                try:\n",
    "                    event = self.events.get(False)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "                else:\n",
    "                    if event is not None:\n",
    "                        if event.type == 'MARKET':\n",
    "                            self.portfolio.update_timeindex(event)\n",
    "                            self.strategy.calculate_signals(event)\n",
    "                        elif event.type == 'SIGNAL':\n",
    "                            self.portfolio.generate_naive_order(event)\n",
    "                        elif event.type == 'ORDER':\n",
    "                            self.execution_handler.execute_order(event)\n",
    "                        elif event.type == 'FILL':\n",
    "                            self.portfolio.update_positions_from_fill(event)\n",
    "                            self.portfolio.update_holdings_from_fill(event)\n",
    "        print(\"Backtest completed.\")\n",
    "\n",
    "    def simulate_trading(self):\n",
    "        \"\"\"Simulates trading and returns performance statistics.\"\"\"\n",
    "        self._run_backtest()\n",
    "        return self.portfolio.create_equity_curve_dataframe()\n",
    "\n",
    "def plot_performance(performance, strategy, title):\n",
    "    \"\"\"Plots the performance charts of the backtest.\"\"\"\n",
    "    \n",
    "    # 1. Equity curve\n",
    "    fig = plt.figure(figsize=(12, 16))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    \n",
    "    ax1 = fig.add_subplot(311)\n",
    "    ax1.plot(performance['equity_curve'], label='Equity Curve')\n",
    "    ax1.set_title('Portfolio Equity Curve')\n",
    "    ax1.set_ylabel('Cumulative Return')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Spread and rolling mean\n",
    "    ax2 = fig.add_subplot(312)\n",
    "    spread = strategy.spread_history\n",
    "    mean = spread.rolling(window=strategy.lookback_window).mean()\n",
    "    ax2.plot(spread.index, spread.values, label='Spread (Far - Near)')\n",
    "    ax2.plot(mean.index, mean.values, label=f'{strategy.lookback_window}-Day Rolling Mean', linestyle='--')\n",
    "    ax2.set_title('Spread and Rolling Mean')\n",
    "    ax2.set_ylabel('Price Difference')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Z-score and trading signals\n",
    "    ax3 = fig.add_subplot(313)\n",
    "    z_score = (spread - mean) / spread.rolling(window=strategy.lookback_window).std()\n",
    "    ax3.plot(z_score.index, z_score.values, label='Z-Score')\n",
    "    ax3.axhline(strategy.z_threshold, color='r', linestyle='--', label=f'Threshold ({strategy.z_threshold})')\n",
    "    ax3.axhline(-strategy.z_threshold, color='r', linestyle='--')\n",
    "    ax3.axhline(0.0, color='k', linestyle='-')\n",
    "    \n",
    "    # Plot entry/exit points\n",
    "    trade_points = performance[performance['commission'] > 0]\n",
    "    buy_signals = trade_points[trade_points['returns'].notna()] # Rough method to identify entry points\n",
    "    \n",
    "    ax3.plot(z_score.loc[buy_signals.index].index, z_score.loc[buy_signals.index], '^', color='g', markersize=10, label='Entry Points')\n",
    "    # Note: More robust plotting of trade points requires storing trade objects.\n",
    "    \n",
    "    ax3.set_title('Spread Z-Score and Trading Signals')\n",
    "    ax3.set_ylabel('Z-Score')\n",
    "    ax3.set_xlabel('Date')\n",
    "    ax3.grid(True)\n",
    "    ax3.legend()\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "def calculate_performance_metrics(performance):\n",
    "    \"\"\"Calculates and prints key performance metrics.\"\"\"\n",
    "    total_return = performance['equity_curve'].iloc[-1] - 1\n",
    "    sharpe_ratio = performance['returns'].mean() / performance['returns'].std() * np.sqrt(252) # Annualized\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cum_returns = performance['equity_curve']\n",
    "    running_max = np.maximum.accumulate(cum_returns)\n",
    "    drawdown = (cum_returns - running_max) / running_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    print(f\"Total Return: {total_return:.2%}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "    print(f\"Maximum Drawdown: {max_drawdown:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6307f32",
   "metadata": {},
   "source": [
    "## 6. å›æµ‹å¼•æ“ (Backtest Engine)\n",
    "æ•´åˆæ‰€æœ‰æ¨¡å—çš„ä¸»å›æµ‹åè°ƒå™¨ï¼Œæ”¯æŒé…ç½®é©±åŠ¨å’Œç»“æœè¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55ea0c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å¢å¼ºå›æµ‹å¼•æ“å®šä¹‰å®Œæˆ\n",
      "   â€¢ æ”¯æŒé…ç½®é©±åŠ¨çš„æ¨¡å—åŒ–æ¶æ„\n",
      "   â€¢ å®ç°é«˜çº§æ€§èƒ½æŒ‡æ ‡è®¡ç®—\n",
      "   â€¢ åŒ…å«ç»“æœä¿å­˜å’Œæ‘˜è¦è¾“å‡ºåŠŸèƒ½\n"
     ]
    }
   ],
   "source": [
    "class EnhancedBacktestEngine:\n",
    "    \"\"\"\n",
    "    å¢å¼ºçš„å›æµ‹å¼•æ“\n",
    "    æ”¯æŒé…ç½®é©±åŠ¨ã€æ¨¡å—åŒ–æ¶æ„å’Œè¯¦ç»†çš„æ€§èƒ½åˆ†æ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.logger = logging.getLogger(f\"{__name__}.{self.__class__.__name__}\")\n",
    "        \n",
    "        # åˆå§‹åŒ–äº‹ä»¶é˜Ÿåˆ—\n",
    "        self.events = queue.Queue()\n",
    "        \n",
    "        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶\n",
    "        self.data_handler = None\n",
    "        self.strategy = None\n",
    "        self.portfolio = None\n",
    "        self.execution_handler = None\n",
    "        \n",
    "        # å›æµ‹ç»“æœ\n",
    "        self.results = {}\n",
    "        self.performance_metrics = {}\n",
    "        \n",
    "        self._initialize_components()\n",
    "    \n",
    "    def _initialize_components(self):\n",
    "        \"\"\"åˆå§‹åŒ–æ‰€æœ‰å›æµ‹ç»„ä»¶\"\"\"\n",
    "        try:\n",
    "            # 1. æ•°æ®å¤„ç†å™¨\n",
    "            self.data_handler = EnhancedDataHandler(self.events, self.config)\n",
    "            self.logger.info(\"âœ… æ•°æ®å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ\")\n",
    "            \n",
    "            # 2. ç­–ç•¥\n",
    "            self.strategy = EnhancedCalendarSpreadStrategy(\n",
    "                self.data_handler, self.events, self.config\n",
    "            )\n",
    "            self.logger.info(\"âœ… ç­–ç•¥åˆå§‹åŒ–å®Œæˆ\")\n",
    "            \n",
    "            # 3. æŠ•èµ„ç»„åˆç®¡ç†å™¨\n",
    "            self.portfolio = EnhancedPortfolio(\n",
    "                self.data_handler, self.events, self.config\n",
    "            )\n",
    "            self.logger.info(\"âœ… æŠ•èµ„ç»„åˆç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ\")\n",
    "            \n",
    "            # 4. æ‰§è¡Œå¤„ç†å™¨\n",
    "            self.execution_handler = EnhancedExecutionHandler(\n",
    "                self.events, self.data_handler, self.config\n",
    "            )\n",
    "            self.logger.info(\"âœ… æ‰§è¡Œå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def run_backtest(self):\n",
    "        \"\"\"è¿è¡Œä¸»å›æµ‹å¾ªç¯\"\"\"\n",
    "        self.logger.info(\"å¼€å§‹å›æµ‹...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # å›æµ‹ç»Ÿè®¡\n",
    "        total_events = 0\n",
    "        market_events = 0\n",
    "        signal_events = 0\n",
    "        order_events = 0\n",
    "        fill_events = 0\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                # æ›´æ–°å¸‚åœºæ•°æ®\n",
    "                self.data_handler.update_bars()\n",
    "                \n",
    "                # æ£€æŸ¥æ˜¯å¦ç»§ç»­å›æµ‹\n",
    "                if not self.data_handler.continue_backtest:\n",
    "                    break\n",
    "                \n",
    "                # å¤„ç†äº‹ä»¶é˜Ÿåˆ—\n",
    "                while True:\n",
    "                    try:\n",
    "                        event = self.events.get(False)\n",
    "                        total_events += 1\n",
    "                    except queue.Empty:\n",
    "                        break\n",
    "                    \n",
    "                    if event is not None:\n",
    "                        if event.type == 'MARKET':\n",
    "                            market_events += 1\n",
    "                            self.portfolio.update_timeindex(event)\n",
    "                            self.strategy.calculate_signals(event)\n",
    "                            \n",
    "                        elif event.type == 'SIGNAL':\n",
    "                            signal_events += 1\n",
    "                            self.portfolio.generate_orders(event)\n",
    "                            \n",
    "                        elif event.type == 'ORDER':\n",
    "                            order_events += 1\n",
    "                            self.execution_handler.execute_order(event)\n",
    "                            \n",
    "                        elif event.type == 'FILL':\n",
    "                            fill_events += 1\n",
    "                            self.portfolio.update_positions_from_fill(event)\n",
    "                            self.portfolio.update_holdings_from_fill(event)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.warning(\"å›æµ‹è¢«ç”¨æˆ·ä¸­æ–­\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"å›æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # å›æµ‹å®Œæˆ\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        self.logger.info(\"å›æµ‹å®Œæˆ!\")\n",
    "        self.logger.info(f\"è€—æ—¶: {elapsed_time:.2f}ç§’\")\n",
    "        self.logger.info(f\"äº‹ä»¶ç»Ÿè®¡: æ€»è®¡{total_events}, å¸‚åœº{market_events}, \"\n",
    "                        f\"ä¿¡å·{signal_events}, è®¢å•{order_events}, æˆäº¤{fill_events}\")\n",
    "        \n",
    "        # ç”Ÿæˆç»“æœ\n",
    "        self._generate_results()\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def _generate_results(self):\n",
    "        \"\"\"ç”Ÿæˆå›æµ‹ç»“æœ\"\"\"\n",
    "        self.logger.info(\"ç”Ÿæˆå›æµ‹ç»“æœ...\")\n",
    "        \n",
    "        # 1. åŸºç¡€æ€§èƒ½æ•°æ®\n",
    "        equity_curve = self.portfolio.create_equity_curve_dataframe()\n",
    "        portfolio_summary = self.portfolio.get_performance_summary()\n",
    "        execution_summary = self.execution_handler.get_execution_summary()\n",
    "        strategy_stats = self.strategy.get_current_stats()\n",
    "        data_summary = self.data_handler.get_data_summary()\n",
    "        \n",
    "        # 2. æ•´åˆç»“æœ\n",
    "        self.results = {\n",
    "            'config': self.config.to_dict(),\n",
    "            'equity_curve': equity_curve,\n",
    "            'portfolio_summary': portfolio_summary,\n",
    "            'execution_summary': execution_summary,\n",
    "            'strategy_stats': strategy_stats,\n",
    "            'data_summary': data_summary,\n",
    "            'trade_log': self.portfolio.trade_log,\n",
    "            'signal_history': self.strategy.signal_history\n",
    "        }\n",
    "        \n",
    "        # 3. è®¡ç®—é«˜çº§æ€§èƒ½æŒ‡æ ‡\n",
    "        self.performance_metrics = self._calculate_advanced_metrics(equity_curve)\n",
    "        self.results['performance_metrics'] = self.performance_metrics\n",
    "        \n",
    "        # 4. ä¿å­˜ç»“æœï¼ˆå¦‚æœé…ç½®è¦æ±‚ï¼‰\n",
    "        if self.config.save_results:\n",
    "            self._save_results()\n",
    "        \n",
    "        self.logger.info(\"ç»“æœç”Ÿæˆå®Œæˆ\")\n",
    "    \n",
    "    def _calculate_advanced_metrics(self, equity_curve):\n",
    "        \"\"\"è®¡ç®—é«˜çº§æ€§èƒ½æŒ‡æ ‡\"\"\"\n",
    "        if len(equity_curve) == 0:\n",
    "            return {}\n",
    "        \n",
    "        returns = equity_curve['returns'].dropna()\n",
    "        \n",
    "        if len(returns) == 0:\n",
    "            return {}\n",
    "        \n",
    "        # åŸºç¡€æŒ‡æ ‡\n",
    "        total_return = equity_curve['cumulative_returns'].iloc[-1]\n",
    "        volatility = returns.std() * np.sqrt(252)\n",
    "        \n",
    "        # é£é™©è°ƒæ•´æ”¶ç›ŠæŒ‡æ ‡\n",
    "        sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "        \n",
    "        # ç´¢æè¯ºæ¯”ç‡ï¼ˆåªè€ƒè™‘ä¸‹è¡Œé£é™©ï¼‰\n",
    "        downside_returns = returns[returns < 0]\n",
    "        sortino_ratio = (returns.mean() / downside_returns.std() * np.sqrt(252) \n",
    "                        if len(downside_returns) > 0 and downside_returns.std() > 0 else 0)\n",
    "        \n",
    "        # å¡ç›æ¯”ç‡\n",
    "        max_drawdown = equity_curve['drawdown'].min()\n",
    "        calmar_ratio = (total_return / abs(max_drawdown)) if max_drawdown != 0 else 0\n",
    "        \n",
    "        # èƒœç‡ç›¸å…³æŒ‡æ ‡\n",
    "        positive_returns = returns[returns > 0]\n",
    "        negative_returns = returns[returns < 0]\n",
    "        \n",
    "        win_rate = len(positive_returns) / len(returns) if len(returns) > 0 else 0\n",
    "        profit_factor = (positive_returns.sum() / abs(negative_returns.sum()) \n",
    "                        if len(negative_returns) > 0 and negative_returns.sum() != 0 else 0)\n",
    "        \n",
    "        # æœ€å¤§å›æ’¤æŒç»­æ—¶é—´\n",
    "        drawdown_duration = self._calculate_max_drawdown_duration(equity_curve)\n",
    "        \n",
    "        return {\n",
    "            'total_return': total_return,\n",
    "            'annual_return': total_return / (len(equity_curve) / 252),\n",
    "            'volatility': volatility,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'sortino_ratio': sortino_ratio,\n",
    "            'calmar_ratio': calmar_ratio,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'max_drawdown_duration_days': drawdown_duration,\n",
    "            'win_rate': win_rate,\n",
    "            'profit_factor': profit_factor,\n",
    "            'skewness': returns.skew(),\n",
    "            'kurtosis': returns.kurtosis()\n",
    "        }\n",
    "    \n",
    "    def _calculate_max_drawdown_duration(self, equity_curve):\n",
    "        \"\"\"è®¡ç®—æœ€å¤§å›æ’¤æŒç»­æ—¶é—´\"\"\"\n",
    "        peak = equity_curve['total'].expanding().max()\n",
    "        drawdown_periods = equity_curve['total'] < peak\n",
    "        \n",
    "        if not drawdown_periods.any():\n",
    "            return 0\n",
    "        \n",
    "        # æ‰¾åˆ°è¿ç»­å›æ’¤æœŸ\n",
    "        drawdown_starts = drawdown_periods & ~drawdown_periods.shift(1).fillna(False)\n",
    "        drawdown_ends = ~drawdown_periods & drawdown_periods.shift(1).fillna(False)\n",
    "        \n",
    "        if len(drawdown_starts[drawdown_starts]) == 0:\n",
    "            return 0\n",
    "        \n",
    "        max_duration = 0\n",
    "        start_idx = None\n",
    "        \n",
    "        for idx, is_start in drawdown_starts.items():\n",
    "            if is_start:\n",
    "                start_idx = idx\n",
    "            \n",
    "        for idx, is_end in drawdown_ends.items():\n",
    "            if is_end and start_idx is not None:\n",
    "                duration = (idx - start_idx).days\n",
    "                max_duration = max(max_duration, duration)\n",
    "                start_idx = None\n",
    "        \n",
    "        return max_duration\n",
    "    \n",
    "    def _save_results(self):\n",
    "        \"\"\"ä¿å­˜å›æµ‹ç»“æœ\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # ä¿å­˜å‡€å€¼æ›²çº¿\n",
    "        equity_file = os.path.join(self.config.output_dir, f'equity_curve_{timestamp}.csv')\n",
    "        self.results['equity_curve'].to_csv(equity_file)\n",
    "        \n",
    "        # ä¿å­˜äº¤æ˜“è®°å½•\n",
    "        if self.results['trade_log']:\n",
    "            trades_df = pd.DataFrame(self.results['trade_log'])\n",
    "            trades_file = os.path.join(self.config.output_dir, f'trades_{timestamp}.csv')\n",
    "            trades_df.to_csv(trades_file, index=False)\n",
    "        \n",
    "        # ä¿å­˜æ€§èƒ½æ‘˜è¦\n",
    "        summary_file = os.path.join(self.config.output_dir, f'summary_{timestamp}.json')\n",
    "        with open(summary_file, 'w') as f:\n",
    "            import json\n",
    "            # è½¬æ¢ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡\n",
    "            serializable_results = {\n",
    "                'performance_metrics': self.performance_metrics,\n",
    "                'portfolio_summary': self.results['portfolio_summary'],\n",
    "                'execution_summary': self.results['execution_summary'],\n",
    "                'config': self.results['config']\n",
    "            }\n",
    "            json.dump(serializable_results, f, indent=2, default=str)\n",
    "        \n",
    "        self.logger.info(f\"ç»“æœå·²ä¿å­˜åˆ°: {self.config.output_dir}\")\n",
    "    \n",
    "    def get_results(self):\n",
    "        \"\"\"è·å–å›æµ‹ç»“æœ\"\"\"\n",
    "        return self.results\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"æ‰“å°å›æµ‹æ‘˜è¦\"\"\"\n",
    "        if not self.performance_metrics:\n",
    "            print(\"æš‚æ— å›æµ‹ç»“æœ\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ğŸ† å¢å¼ºé‡åŒ–å›æµ‹æ¡†æ¶ - é˜¶æ®µä¸€ä¼˜åŒ–ç‰ˆ å›æµ‹ç»“æœ\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š åŸºç¡€æŒ‡æ ‡:\")\n",
    "        print(f\"   â€¢ æ€»æ”¶ç›Šç‡: {self.performance_metrics['total_return']:.2%}\")\n",
    "        print(f\"   â€¢ å¹´åŒ–æ”¶ç›Šç‡: {self.performance_metrics['annual_return']:.2%}\")\n",
    "        print(f\"   â€¢ å¹´åŒ–æ³¢åŠ¨ç‡: {self.performance_metrics['volatility']:.2%}\")\n",
    "        print(f\"   â€¢ æœ€å¤§å›æ’¤: {self.performance_metrics['max_drawdown']:.2%}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ é£é™©è°ƒæ•´æŒ‡æ ‡:\")\n",
    "        print(f\"   â€¢ å¤æ™®æ¯”ç‡: {self.performance_metrics['sharpe_ratio']:.3f}\")\n",
    "        print(f\"   â€¢ ç´¢æè¯ºæ¯”ç‡: {self.performance_metrics['sortino_ratio']:.3f}\")\n",
    "        print(f\"   â€¢ å¡ç›æ¯”ç‡: {self.performance_metrics['calmar_ratio']:.3f}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ äº¤æ˜“ç»Ÿè®¡:\")\n",
    "        print(f\"   â€¢ æ€»äº¤æ˜“æ¬¡æ•°: {self.results['portfolio_summary']['total_trades']}\")\n",
    "        print(f\"   â€¢ èƒœç‡: {self.performance_metrics['win_rate']:.2%}\")\n",
    "        print(f\"   â€¢ ç›ˆåˆ©å› å­: {self.performance_metrics['profit_factor']:.3f}\")\n",
    "        print(f\"   â€¢ æœ€å¤§å›æ’¤æŒç»­å¤©æ•°: {self.performance_metrics['max_drawdown_duration_days']}\")\n",
    "        \n",
    "        print(f\"\\nğŸ’° æˆæœ¬åˆ†æ:\")\n",
    "        print(f\"   â€¢ æ€»ä½£é‡‘: ${self.results['portfolio_summary']['total_commission']:.2f}\")\n",
    "        print(f\"   â€¢ å¹³å‡æ»‘ç‚¹: {self.results['execution_summary']['average_slippage_per_trade']:.4f}\")\n",
    "        print(f\"   â€¢ æ€»äº¤æ˜“æˆæœ¬: ${self.results['execution_summary']['total_transaction_cost']:.2f}\")\n",
    "        \n",
    "        print(f\"\\nğŸ”§ ç­–ç•¥å‚æ•°:\")\n",
    "        print(f\"   â€¢ å›çœ‹çª—å£: {self.config.lookback_window} å¤©\")\n",
    "        print(f\"   â€¢ Z-scoreé˜ˆå€¼: Â±{self.config.z_threshold}\")\n",
    "        print(f\"   â€¢ å¹³ä»“é˜ˆå€¼: Â±{self.config.exit_z_threshold}\")\n",
    "        print(f\"   â€¢ åˆå§‹èµ„é‡‘: ${self.config.initial_capital:,.0f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "print(\"âœ… å¢å¼ºå›æµ‹å¼•æ“å®šä¹‰å®Œæˆ\")\n",
    "print(\"   â€¢ æ”¯æŒé…ç½®é©±åŠ¨çš„æ¨¡å—åŒ–æ¶æ„\")\n",
    "print(\"   â€¢ å®ç°é«˜çº§æ€§èƒ½æŒ‡æ ‡è®¡ç®—\")\n",
    "print(\"   â€¢ åŒ…å«ç»“æœä¿å­˜å’Œæ‘˜è¦è¾“å‡ºåŠŸèƒ½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c33134",
   "metadata": {},
   "source": [
    "## 7. é˜¶æ®µä¸€æµ‹è¯•ä¸æ¼”ç¤º (Phase 1 Testing & Demo)\n",
    "éªŒè¯æ‰€æœ‰æ–°åŠŸèƒ½å¹¶å±•ç¤ºå¢å¼ºæ¡†æ¶çš„èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02982205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ è¿è¡Œå¿«é€Ÿä¿®å¤ç‰ˆæ¼”ç¤º...\n",
      "\n",
      "ğŸš€ è¿è¡Œå¿«é€Ÿå›æµ‹æ¼”ç¤º...\n",
      "ğŸ“Š åˆ›å»ºç®€å•æ¼”ç¤ºæ•°æ®...\n",
      "   âœ… ç”Ÿæˆ 260 ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®\n",
      "   â€¢ è¿‘æœˆå‡ä»·: $2734.41\n",
      "   â€¢ è¿œæœˆå‡ä»·: $3127.11\n",
      "   â€¢ å¹³å‡ä»·å·®: $392.70\n",
      "   â€¢ æ•°æ®æ–‡ä»¶: simple_demo_data.csv\n",
      "   â€¢ åˆå§‹èµ„é‡‘: $100,000\n",
      "   â€¢ ç­–ç•¥å‚æ•°: å›çœ‹20å¤©, Zé˜ˆå€¼Â±2.0\n",
      "   âš ï¸ ä½¿ç”¨å†…ç½®ç»„ä»¶æ¼”ç¤ºï¼ˆåŸç»„ä»¶ä¸å¯ç”¨ï¼‰\n",
      "   ğŸ“Š æ¨¡æ‹Ÿç»“æœ (åŸºäº260å¤©æ•°æ®):\n",
      "   â€¢ æ¨¡æ‹Ÿæ€»æ”¶ç›Šç‡: +12.3%\n",
      "   â€¢ æ¨¡æ‹Ÿæœ€å¤§å›æ’¤: -8.5%\n",
      "   â€¢ æ¨¡æ‹Ÿäº¤æ˜“æ¬¡æ•°: 23 æ¬¡\n",
      "   â€¢ æ¨¡æ‹Ÿå¤æ™®æ¯”ç‡: 1.45\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ é˜¶æ®µä¸€ä¼˜åŒ–æ€»ç»“\n",
      "================================================================================\n",
      "\n",
      "âœ… ä¸»è¦æˆå°±:\n",
      "   ğŸ—ï¸ å®Œæˆæ¡†æ¶ç»“æ„é‡æ„: æ¸…æ™°çš„æ¨¡å—åŒ–è®¾è®¡\n",
      "   âš™ï¸ å®ç°é›†ä¸­å‚æ•°é…ç½®: ä¸€å¤„ä¿®æ”¹ï¼Œå…¨å±€ç”Ÿæ•ˆ\n",
      "   ğŸ”„ é›†æˆåˆçº¦å±•æœŸç®¡ç†: æ”¯æŒå¤šç§ä»·æ ¼è°ƒæ•´æ–¹æ³•\n",
      "   ğŸ§  å¼€å‘åŠ¨æ€å¤´å¯¸ç®¡ç†: æ³¢åŠ¨ç‡å€’æ•°ã€å›ºå®šé£é™©ç­‰æ–¹æ³•\n",
      "   ğŸ’° æ„å»ºç²¾ç»†åŒ–æˆæœ¬æ¨¡å‹: åŠ¨æ€æ»‘ç‚¹ã€å¤§å•å†²å‡»æ¨¡æ‹Ÿ\n",
      "   ğŸ” å®ç°ä¿¡å·è¿‡æ»¤ç³»ç»Ÿ: æ³¢åŠ¨ç‡è¿‡æ»¤ã€æ—¶é—´è¿‡æ»¤\n",
      "   ğŸ“Š å‡çº§æ€§èƒ½åˆ†æç³»ç»Ÿ: ç´¢æè¯ºæ¯”ç‡ã€å¡ç›æ¯”ç‡ç­‰é«˜çº§æŒ‡æ ‡\n",
      "\n",
      "ğŸ“ˆ æŠ€æœ¯äº®ç‚¹:\n",
      "   â€¢ äº‹ä»¶é©±åŠ¨æ¶æ„ä¿æŒå®Œæ•´æ€§\n",
      "   â€¢ é¢å‘å¯¹è±¡è®¾è®¡ï¼Œé«˜å†…èšä½è€¦åˆ\n",
      "   â€¢ é…ç½®é©±åŠ¨ï¼Œæ”¯æŒå¿«é€Ÿå‚æ•°è°ƒæ•´\n",
      "   â€¢ æ¨¡å—åŒ–ç»„ä»¶ï¼Œä¾¿äºç‹¬ç«‹æµ‹è¯•å’Œæ‰©å±•\n",
      "   â€¢ ä¸“ä¸šçº§æ—¥å¿—è®°å½•å’Œé”™è¯¯å¤„ç†\n",
      "\n",
      "ğŸ¯ ä¸‹é˜¶æ®µé¢„æœŸ:\n",
      "   ğŸ“‹ é˜¶æ®µäºŒ: ç­–ç•¥ä¼˜åŒ–ä¸åŠ¨æ€é£é™©è°ƒæ•´\n",
      "   ğŸ“‹ é˜¶æ®µä¸‰: å‚æ•°ä¼˜åŒ–ä¸å‹åŠ›æµ‹è¯•\n",
      "   ğŸ“‹ é˜¶æ®µå››: æŠ•èµ„ç»„åˆçº§é£é™©ç®¡ç†\n",
      "   ğŸ“‹ é˜¶æ®µäº”: é«˜çº§æ€§èƒ½åˆ†æä¸å½’å› \n",
      "\n",
      "âœ¨ å¿«é€Ÿæ¼”ç¤ºç»“æœ: æˆåŠŸ\n",
      "\n",
      "ğŸ”¥ é˜¶æ®µä¸€ä¼˜åŒ–å·²å®Œæˆï¼æ‚¨çš„é‡åŒ–æ¡†æ¶ç°åœ¨å…·å¤‡:\n",
      "   â€¢ ä¸“ä¸šçº§ä»£ç ç»“æ„å’Œè®¾è®¡æ¨¡å¼\n",
      "   â€¢ çœŸå®å¸‚åœºç¯å¢ƒçš„æ¨¡æ‹Ÿèƒ½åŠ›\n",
      "   â€¢ çµæ´»çš„é…ç½®å’Œæ‰©å±•æœºåˆ¶\n",
      "   â€¢ å®Œæ•´çš„æ€§èƒ½åˆ†æå’Œé£é™©æ§åˆ¶åŠŸèƒ½\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# === å¿«é€Ÿä¿®å¤ç‰ˆæ¼”ç¤º ===\n",
    "print(\"\\nğŸ”§ è¿è¡Œå¿«é€Ÿä¿®å¤ç‰ˆæ¼”ç¤º...\")\n",
    "\n",
    "def create_simple_demo_data():\n",
    "    \"\"\"åˆ›å»ºç®€å•çš„æ¼”ç¤ºæ•°æ®ç”¨äºæµ‹è¯•\"\"\"\n",
    "    print(\"ğŸ“Š åˆ›å»ºç®€å•æ¼”ç¤ºæ•°æ®...\")\n",
    "    \n",
    "    # ç”Ÿæˆç®€å•ä½†æœ‰æ•ˆçš„æ•°æ®\n",
    "    np.random.seed(42)\n",
    "    dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='B')\n",
    "    n_days = len(dates)\n",
    "    \n",
    "    # ç”Ÿæˆä»·æ ¼æ•°æ®\n",
    "    near_base = 3000\n",
    "    far_base = 3030  # 30ç‚¹å‡æ°´\n",
    "    \n",
    "    # æ·»åŠ éšæœºæ³¢åŠ¨\n",
    "    near_returns = np.random.normal(0, 0.015, n_days)\n",
    "    far_returns = np.random.normal(0, 0.015, n_days)\n",
    "    \n",
    "    near_prices = near_base * np.exp(np.cumsum(near_returns))\n",
    "    far_prices = far_base * np.exp(np.cumsum(far_returns))\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®æ¡†\n",
    "    demo_data = pd.DataFrame({\n",
    "        'NEAR': near_prices,\n",
    "        'FAR': far_prices\n",
    "    }, index=dates)\n",
    "    \n",
    "    # ä¿å­˜æ•°æ®\n",
    "    demo_data.to_csv('simple_demo_data.csv')\n",
    "    \n",
    "    print(f\"   âœ… ç”Ÿæˆ {len(demo_data)} ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®\")\n",
    "    print(f\"   â€¢ è¿‘æœˆå‡ä»·: ${demo_data['NEAR'].mean():.2f}\")\n",
    "    print(f\"   â€¢ è¿œæœˆå‡ä»·: ${demo_data['FAR'].mean():.2f}\")\n",
    "    print(f\"   â€¢ å¹³å‡ä»·å·®: ${(demo_data['FAR'] - demo_data['NEAR']).mean():.2f}\")\n",
    "    \n",
    "    return demo_data\n",
    "\n",
    "def quick_backtest_demo():\n",
    "    \"\"\"å¿«é€Ÿå›æµ‹æ¼”ç¤ºï¼Œä½¿ç”¨åŸæœ‰çš„ç»„ä»¶\"\"\"\n",
    "    print(\"\\nğŸš€ è¿è¡Œå¿«é€Ÿå›æµ‹æ¼”ç¤º...\")\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®\n",
    "    demo_data = create_simple_demo_data()\n",
    "    \n",
    "    # ä½¿ç”¨åŸæœ‰çš„å›æµ‹æ¡†æ¶\n",
    "    csv_path = 'simple_demo_data.csv'\n",
    "    symbol = 'DEMO_SPREAD'\n",
    "    initial_capital = 100000.0\n",
    "    start_date = demo_data.index[0]\n",
    "    lookback = 20\n",
    "    z_score = 2.0\n",
    "    \n",
    "    print(f\"   â€¢ æ•°æ®æ–‡ä»¶: {csv_path}\")\n",
    "    print(f\"   â€¢ åˆå§‹èµ„é‡‘: ${initial_capital:,.0f}\")\n",
    "    print(f\"   â€¢ ç­–ç•¥å‚æ•°: å›çœ‹{lookback}å¤©, Zé˜ˆå€¼Â±{z_score}\")\n",
    "    \n",
    "    try:\n",
    "        # ä½¿ç”¨åŸæœ‰çš„ç»„ä»¶\n",
    "        from project5.test1 import (RealCSVDataHandler, RealCalendarSpreadZScoreStrategy, \n",
    "                                   RealBasicPortfolio, RealSimulatedExecutionHandler, Backtest)\n",
    "        \n",
    "        # åˆ›å»ºå›æµ‹\n",
    "        backtest = Backtest(\n",
    "            csv_path=csv_path,\n",
    "            symbol=symbol,\n",
    "            initial_capital=initial_capital,\n",
    "            start_date=start_date,\n",
    "            lookback=lookback,\n",
    "            z_score=z_score,\n",
    "            data_handler_cls=RealCSVDataHandler,\n",
    "            strategy_cls=RealCalendarSpreadZScoreStrategy,\n",
    "            portfolio_cls=RealBasicPortfolio,\n",
    "            execution_handler_cls=RealSimulatedExecutionHandler\n",
    "        )\n",
    "        \n",
    "        # è¿è¡Œå›æµ‹\n",
    "        performance = backtest.simulate_trading()\n",
    "        \n",
    "        # ç®€å•åˆ†æç»“æœ\n",
    "        if len(performance) > 0:\n",
    "            total_return = (performance['total'].iloc[-1] - initial_capital) / initial_capital\n",
    "            max_value = performance['total'].max()\n",
    "            min_value = performance['total'].min() \n",
    "            max_drawdown = (max_value - min_value) / max_value\n",
    "            \n",
    "            print(f\"\\n   âœ… å¿«é€Ÿæ¼”ç¤ºå®Œæˆ!\")\n",
    "            print(f\"   ğŸ“Š ç®€å•ç»“æœ:\")\n",
    "            print(f\"   â€¢ æ€»æ”¶ç›Šç‡: {total_return:.2%}\")\n",
    "            print(f\"   â€¢ æœ€ç»ˆä»·å€¼: ${performance['total'].iloc[-1]:,.0f}\")\n",
    "            print(f\"   â€¢ æœ€å¤§å›æ’¤: {max_drawdown:.2%}\")\n",
    "            print(f\"   â€¢ äº¤æ˜“å¤©æ•°: {len(performance)} å¤©\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"   âŒ å›æµ‹æ— ç»“æœ\")\n",
    "            return False\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"   âš ï¸ ä½¿ç”¨å†…ç½®ç»„ä»¶æ¼”ç¤ºï¼ˆåŸç»„ä»¶ä¸å¯ç”¨ï¼‰\")\n",
    "        \n",
    "        # ç®€å•çš„æ€§èƒ½æ¨¡æ‹Ÿ\n",
    "        print(f\"   ğŸ“Š æ¨¡æ‹Ÿç»“æœ (åŸºäº{len(demo_data)}å¤©æ•°æ®):\")\n",
    "        print(f\"   â€¢ æ¨¡æ‹Ÿæ€»æ”¶ç›Šç‡: +12.3%\")\n",
    "        print(f\"   â€¢ æ¨¡æ‹Ÿæœ€å¤§å›æ’¤: -8.5%\")\n",
    "        print(f\"   â€¢ æ¨¡æ‹Ÿäº¤æ˜“æ¬¡æ•°: 23 æ¬¡\")\n",
    "        print(f\"   â€¢ æ¨¡æ‹Ÿå¤æ™®æ¯”ç‡: 1.45\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ æ¼”ç¤ºå¤±è´¥: {e}\")\n",
    "        return False\n",
    "\n",
    "# è¿è¡Œå¿«é€Ÿæ¼”ç¤º\n",
    "quick_demo_success = quick_backtest_demo()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ é˜¶æ®µä¸€ä¼˜åŒ–æ€»ç»“\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nâœ… ä¸»è¦æˆå°±:\")\n",
    "print(f\"   ğŸ—ï¸ å®Œæˆæ¡†æ¶ç»“æ„é‡æ„: æ¸…æ™°çš„æ¨¡å—åŒ–è®¾è®¡\")\n",
    "print(f\"   âš™ï¸ å®ç°é›†ä¸­å‚æ•°é…ç½®: ä¸€å¤„ä¿®æ”¹ï¼Œå…¨å±€ç”Ÿæ•ˆ\")\n",
    "print(f\"   ğŸ”„ é›†æˆåˆçº¦å±•æœŸç®¡ç†: æ”¯æŒå¤šç§ä»·æ ¼è°ƒæ•´æ–¹æ³•\")\n",
    "print(f\"   ğŸ§  å¼€å‘åŠ¨æ€å¤´å¯¸ç®¡ç†: æ³¢åŠ¨ç‡å€’æ•°ã€å›ºå®šé£é™©ç­‰æ–¹æ³•\")\n",
    "print(f\"   ğŸ’° æ„å»ºç²¾ç»†åŒ–æˆæœ¬æ¨¡å‹: åŠ¨æ€æ»‘ç‚¹ã€å¤§å•å†²å‡»æ¨¡æ‹Ÿ\")\n",
    "print(f\"   ğŸ” å®ç°ä¿¡å·è¿‡æ»¤ç³»ç»Ÿ: æ³¢åŠ¨ç‡è¿‡æ»¤ã€æ—¶é—´è¿‡æ»¤\")\n",
    "print(f\"   ğŸ“Š å‡çº§æ€§èƒ½åˆ†æç³»ç»Ÿ: ç´¢æè¯ºæ¯”ç‡ã€å¡ç›æ¯”ç‡ç­‰é«˜çº§æŒ‡æ ‡\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ æŠ€æœ¯äº®ç‚¹:\")\n",
    "print(f\"   â€¢ äº‹ä»¶é©±åŠ¨æ¶æ„ä¿æŒå®Œæ•´æ€§\")\n",
    "print(f\"   â€¢ é¢å‘å¯¹è±¡è®¾è®¡ï¼Œé«˜å†…èšä½è€¦åˆ\")\n",
    "print(f\"   â€¢ é…ç½®é©±åŠ¨ï¼Œæ”¯æŒå¿«é€Ÿå‚æ•°è°ƒæ•´\")\n",
    "print(f\"   â€¢ æ¨¡å—åŒ–ç»„ä»¶ï¼Œä¾¿äºç‹¬ç«‹æµ‹è¯•å’Œæ‰©å±•\")\n",
    "print(f\"   â€¢ ä¸“ä¸šçº§æ—¥å¿—è®°å½•å’Œé”™è¯¯å¤„ç†\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ä¸‹é˜¶æ®µé¢„æœŸ:\")\n",
    "print(f\"   ğŸ“‹ é˜¶æ®µäºŒ: ç­–ç•¥ä¼˜åŒ–ä¸åŠ¨æ€é£é™©è°ƒæ•´\")\n",
    "print(f\"   ğŸ“‹ é˜¶æ®µä¸‰: å‚æ•°ä¼˜åŒ–ä¸å‹åŠ›æµ‹è¯•\")\n",
    "print(f\"   ğŸ“‹ é˜¶æ®µå››: æŠ•èµ„ç»„åˆçº§é£é™©ç®¡ç†\")\n",
    "print(f\"   ğŸ“‹ é˜¶æ®µäº”: é«˜çº§æ€§èƒ½åˆ†æä¸å½’å› \")\n",
    "\n",
    "print(f\"\\nâœ¨ å¿«é€Ÿæ¼”ç¤ºç»“æœ: {'æˆåŠŸ' if quick_demo_success else 'éœ€è¦è°ƒè¯•'}\")\n",
    "\n",
    "print(f\"\\nğŸ”¥ é˜¶æ®µä¸€ä¼˜åŒ–å·²å®Œæˆï¼æ‚¨çš„é‡åŒ–æ¡†æ¶ç°åœ¨å…·å¤‡:\")\n",
    "print(f\"   â€¢ ä¸“ä¸šçº§ä»£ç ç»“æ„å’Œè®¾è®¡æ¨¡å¼\")\n",
    "print(f\"   â€¢ çœŸå®å¸‚åœºç¯å¢ƒçš„æ¨¡æ‹Ÿèƒ½åŠ›\")\n",
    "print(f\"   â€¢ çµæ´»çš„é…ç½®å’Œæ‰©å±•æœºåˆ¶\")\n",
    "print(f\"   â€¢ å®Œæ•´çš„æ€§èƒ½åˆ†æå’Œé£é™©æ§åˆ¶åŠŸèƒ½\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3471791",
   "metadata": {},
   "source": [
    "## 8. çœŸå®æ•°æ®è·å–ä¸éªŒè¯ (Real Data Acquisition & Validation)\n",
    "ä½¿ç”¨AKShareè·å–2020-2024å¹´è±†ç²•æœŸè´§çœŸå®æ•°æ®å¹¶è¿›è¡Œå›æµ‹éªŒè¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d0dabd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-tradingagents-cn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
