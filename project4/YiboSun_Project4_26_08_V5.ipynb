{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "c9b1c76a",
   "source": [
    "## Project Summary V5 â€” Dual-Factor VIX Regime Classification\n",
    "\n",
    "This V5 notebook upgrades the V4 framework with a sophisticated VIX regime system:\n",
    "\n",
    "- **Dual-factor regime**: combines VIX time-proportion (noise filter) with VIX/VIX3M term structure inversion\n",
    "- **Three regimes**: Normal (full exposure), Elevated (reduced), Panic (minimal)\n",
    "- **Adaptive thresholds**: rolling 252-day 75th percentile with absolute floor of 20\n",
    "- **Graceful fallback**: degrades safely when VIX3M data unavailable\n",
    "- Retains V4 improvements: conviction weighting, conditional short leg, lower momentum thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "19805227",
   "source": [
    "### Data Collection\n",
    "\n",
    "In this project, we use three datasets: adj_close.csv (Yahoo Finance API), volume.csv (Yahoo Finance API), and VIX.csv proxy from `^VIX` and `^VIX3M` (3-month volatility, for term structure) in Yahoo Finance, with IRX (`^IRX`) for cash return proxy. Benchmarks include both **XLK** and **SPY**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "1f85f729",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# load environment (for any other API keys you may have)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "f42d8aaf",
   "source": [
    "# ç»Ÿä¸€ä½¿ç”¨ Yahoo Finance API èŽ·å–æ•°æ®\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "faabb0fd",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# UNIFIED DATA FETCHER - Yahoo Finance API (Direct Requests)\n",
    "# ============================================================\n",
    "# No external API keys required, no rate limits like Tiingo\n",
    "# Fetches all stock data, VIX, and IRX equivalent (^IRX) in one place\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_yahoo_data(ticker, start_dt, end_dt, headers):\n",
    "    \"\"\"\n",
    "    Fetch historical data for a single ticker from Yahoo Finance API.\n",
    "    Returns tuple of (adj_close_series, volume_series) or (None, None) if failed.\n",
    "    \"\"\"\n",
    "    start_ts = int(start_dt.timestamp())\n",
    "    end_ts = int(end_dt.timestamp())\n",
    "    \n",
    "    url = f'https://query1.finance.yahoo.com/v8/finance/chart/{ticker}?period1={start_ts}&period2={end_ts}&interval=1d'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'chart' in data and 'result' in data['chart'] and data['chart']['result']:\n",
    "            result = data['chart']['result'][0]\n",
    "            timestamps = result.get('timestamp', [])\n",
    "            \n",
    "            if timestamps and len(timestamps) > 10:\n",
    "                quote = result['indicators']['quote'][0]\n",
    "                adjclose = result['indicators'].get('adjclose', [{}])[0].get('adjclose', quote.get('close', []))\n",
    "                vol = quote.get('volume', [])\n",
    "                \n",
    "                # Create date index (normalized to remove time component)\n",
    "                dates = pd.to_datetime(timestamps, unit='s').normalize()\n",
    "                \n",
    "                # Create Series\n",
    "                adj_close_series = pd.Series(adjclose, index=dates, name=ticker)\n",
    "                volume_series = pd.Series(vol, index=dates, name=ticker)\n",
    "                \n",
    "                # Ensure timezone-naive\n",
    "                if adj_close_series.index.tz is not None:\n",
    "                    adj_close_series.index = adj_close_series.index.tz_localize(None)\n",
    "                if volume_series.index.tz is not None:\n",
    "                    volume_series.index = volume_series.index.tz_localize(None)\n",
    "                \n",
    "                # Remove duplicates\n",
    "                adj_close_series = adj_close_series[~adj_close_series.index.duplicated(keep='first')]\n",
    "                volume_series = volume_series[~volume_series.index.duplicated(keep='first')]\n",
    "                \n",
    "                return adj_close_series, volume_series\n",
    "        \n",
    "        return None, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Error: {str(e)[:50]}\")\n",
    "        return None, None\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# XLK constituents + benchmark ETF + VIX + IRX\n",
    "stock_tickers = [\n",
    "    'AAPL', 'ACN', 'ADBE', 'ADI', 'AKAM', 'AMD', 'AMAT', 'ANET', 'APH', 'AVGO',\n",
    "    'CDNS', 'CDW', 'CRWD', 'CRM', 'CSCO', 'CTSH', 'DDOG', 'DELL', 'ENPH', 'EPAM',\n",
    "    'FICO', 'FFIV', 'FSLR', 'FTNT', 'GEN', 'GDDY', 'GLW', 'HPE', 'HPQ', 'IBM',\n",
    "    'INTC', 'INTU', 'IT', 'JBL', 'KEYS', 'KLAC', 'LRCX', 'MCHP', 'MPWR', 'MSI',\n",
    "    'MSFT', 'MU', 'NOW', 'NVDA', 'NXPI', 'ON', 'ORCL', 'PANW', 'PLTR', 'PTC',\n",
    "    'QCOM', 'ROP', 'SMCI', 'SNPS', 'STX', 'SWKS', 'TEL', 'TER', 'TDY', 'TXN',\n",
    "    'TYL', 'TRMB', 'VRSN', 'WDC', 'WDAY', 'ZBRA'\n",
    "]\n",
    "\n",
    "# Add benchmark and market indicators\n",
    "benchmark_tickers = ['XLK', 'SPY']           # XLK ETF benchmark\n",
    "market_indicators = ['^VIX', '^VIX3M', '^IRX']  # VIX and 13-week T-bill rate\n",
    "\n",
    "# Combine all tickers\n",
    "all_tickers = stock_tickers + benchmark_tickers + market_indicators\n",
    "\n",
    "# Date range\n",
    "start_dt = datetime(2019, 12, 1)\n",
    "end_dt = datetime(2026, 1, 30)\n",
    "\n",
    "# HTTP headers\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ðŸ“Š UNIFIED DATA FETCHER - Yahoo Finance API\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"ðŸ“… Date range: {start_dt.date()} to {end_dt.date()}\")\n",
    "print(f\"ðŸ“ˆ Total tickers to fetch: {len(all_tickers)}\")\n",
    "print(f\"   - Stocks: {len(stock_tickers)}\")\n",
    "print(f\"   - Benchmark: {benchmark_tickers}\")\n",
    "print(f\"   - Market Indicators: {market_indicators}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ============================================================\n",
    "# FETCH ALL DATA\n",
    "# ============================================================\n",
    "\n",
    "adj_close_data = {}\n",
    "volume_data = {}\n",
    "failed_tickers = []\n",
    "\n",
    "for i, ticker in enumerate(all_tickers):\n",
    "    print(f\"[{i+1}/{len(all_tickers)}] Downloading {ticker}...\", end=\" \")\n",
    "    \n",
    "    adj_series, vol_series = fetch_yahoo_data(ticker, start_dt, end_dt, headers)\n",
    "    \n",
    "    if adj_series is not None and len(adj_series) > 100:\n",
    "        adj_close_data[ticker] = adj_series\n",
    "        volume_data[ticker] = vol_series\n",
    "        valid_count = adj_series.notna().sum()\n",
    "        print(f\"âœ… {valid_count} rows\")\n",
    "    else:\n",
    "        print(f\"âŒ Failed or insufficient data\")\n",
    "        failed_tickers.append(ticker)\n",
    "    \n",
    "    # Small delay to be respectful to Yahoo's servers\n",
    "    time.sleep(0.3)\n",
    "\n",
    "# ============================================================\n",
    "# CREATE DATAFRAMES\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"ðŸ“Š Creating unified DataFrames...\")\n",
    "\n",
    "# Create DataFrames\n",
    "adj_close = pd.DataFrame(adj_close_data)\n",
    "volume = pd.DataFrame(volume_data)\n",
    "\n",
    "# Ensure datetime index\n",
    "adj_close.index = pd.to_datetime(adj_close.index)\n",
    "volume.index = pd.to_datetime(volume.index)\n",
    "\n",
    "# Sort by date\n",
    "adj_close = adj_close.sort_index()\n",
    "volume = volume.sort_index()\n",
    "\n",
    "# Forward fill for short gaps (limit 5 days to avoid long gaps)\n",
    "adj_close = adj_close.ffill(limit=5)\n",
    "volume = volume.ffill(limit=5)\n",
    "\n",
    "# Remove VIX and IRX from volume (they don't have volume data)\n",
    "for indicator in ['^VIX', '^IRX']:\n",
    "    if indicator in volume.columns:\n",
    "        volume = volume.drop(columns=[indicator])\n",
    "\n",
    "# ============================================================\n",
    "# SAVE DATA\n",
    "# ============================================================\n",
    "\n",
    "adj_close.to_csv('adj_close.csv')\n",
    "volume.to_csv('volume.csv')\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… DATA DOWNLOAD COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"ðŸ“Š Successfully downloaded: {len(adj_close.columns)} tickers\")\n",
    "print(f\"âŒ Failed: {len(failed_tickers)} tickers\")\n",
    "if failed_tickers:\n",
    "    print(f\"   Failed list: {failed_tickers}\")\n",
    "print(f\"\\nðŸ“… Date range: {adj_close.index[0].strftime('%Y-%m-%d')} to {adj_close.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"ðŸ“ˆ Total trading days: {len(adj_close)}\")\n",
    "\n",
    "# Check key indicators\n",
    "print(f\"\\nðŸ“Š Key Indicators Status:\")\n",
    "for indicator in ['XLK', '^VIX', '^IRX']:\n",
    "    if indicator in adj_close.columns:\n",
    "        count = adj_close[indicator].notna().sum()\n",
    "        latest = adj_close[indicator].dropna().iloc[-1] if count > 0 else 'N/A'\n",
    "        print(f\"   {indicator}: {count} valid rows, latest value = {latest:.4f}\" if isinstance(latest, (int, float)) else f\"   {indicator}: {count} valid rows\")\n",
    "    else:\n",
    "        print(f\"   {indicator}: âŒ Not available\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ Data saved to:\")\n",
    "print(f\"   - adj_close.csv ({adj_close.shape})\")\n",
    "print(f\"   - volume.csv ({volume.shape})\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "8645467a",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA VERIFICATION & QUALITY CHECK\n",
    "# ============================================================\n",
    "\n",
    "# Reload to verify\n",
    "adj_close = pd.read_csv('adj_close.csv', index_col=0, parse_dates=True)\n",
    "volume = pd.read_csv('volume.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ðŸ“Š DATA QUALITY VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"\\n1 Overall Statistics:\")\n",
    "print(f\"   Adjusted Close: {adj_close.shape[0]} rows Ã— {adj_close.shape[1]} columns\")\n",
    "print(f\"   Volume: {volume.shape[0]} rows Ã— {volume.shape[1]} columns\")\n",
    "print(f\"   Date range: {adj_close.index[0].strftime('%Y-%m-%d')} to {adj_close.index[-1].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# VIX statistics\n",
    "print(f\"\\n2 VIX Data:\")\n",
    "if '^VIX' in adj_close.columns:\n",
    "    vix = adj_close['^VIX'].dropna()\n",
    "    print(f\"   Valid rows: {len(vix)}\")\n",
    "    print(f\"   Range: {vix.min():.2f} - {vix.max():.2f}\")\n",
    "    print(f\"   Mean: {vix.mean():.2f}, Std: {vix.std():.2f}\")\n",
    "    print(f\"   Latest: {vix.iloc[-1]:.2f}\")\n",
    "else:\n",
    "    print(\"   âŒ VIX not available\")\n",
    "\n",
    "# IRX statistics (13-week T-bill rate)\n",
    "print(f\"\\n3 IRX Data (Risk-free rate proxy):\")\n",
    "if '^IRX' in adj_close.columns:\n",
    "    irx = adj_close['^IRX'].dropna()\n",
    "    print(f\"   Valid rows: {len(irx)}\")\n",
    "    print(f\"   Range: {irx.min():.3f}% - {irx.max():.3f}%\")\n",
    "    print(f\"   Mean: {irx.mean():.3f}%, Std: {irx.std():.3f}%\")\n",
    "    print(f\"   Latest: {irx.iloc[-1]:.3f}%\")\n",
    "else:\n",
    "    print(\"   âŒ IRX not available\")\n",
    "\n",
    "# XLK statistics\n",
    "print(f\"\\n4 XLK Benchmark:\")\n",
    "if 'XLK' in adj_close.columns:\n",
    "    xlk = adj_close['XLK'].dropna()\n",
    "    print(f\"   Valid rows: {len(xlk)}\")\n",
    "    print(f\"   Price range: ${xlk.min():.2f} - ${xlk.max():.2f}\")\n",
    "    print(f\"   Latest: ${xlk.iloc[-1]:.2f}\")\n",
    "else:\n",
    "    print(\"   âŒ XLK not available\")\n",
    "\n",
    "# VIX3M statistics\n",
    "print(f\"\\n5 VIX3M Data:\")\n",
    "if '^VIX3M' in adj_close.columns:\n",
    "    vix3m = adj_close['^VIX3M'].dropna()\n",
    "    print(f\"   Valid rows: {len(vix3m)}\")\n",
    "    print(f\"   Range: {vix3m.min():.2f} - {vix3m.max():.2f}\")\n",
    "    print(f\"   Latest: {vix3m.iloc[-1]:.2f}\")\n",
    "else:\n",
    "    print(\"   VIX3M not available - will use single-factor regime\")\n",
    "\n",
    "# SPY statistics\n",
    "print(f\"\\n6 SPY Benchmark:\")\n",
    "if 'SPY' in adj_close.columns:\n",
    "    spy = adj_close['SPY'].dropna()\n",
    "    print(f\"   Valid rows: {len(spy)}\")\n",
    "    print(f\"   Price range: ${spy.min():.2f} - ${spy.max():.2f}\")\n",
    "    print(f\"   Latest: ${spy.iloc[-1]:.2f}\")\n",
    "else:\n",
    "    print(\"   âŒ SPY not available\")\n",
    "\n",
    "# Missing data check\n",
    "print(f\"\\n7 Missing Data Check:\")\n",
    "missing_pct = (adj_close.isna().sum() / len(adj_close) * 100).sort_values(ascending=False)\n",
    "high_missing = missing_pct[missing_pct > 5]\n",
    "if len(high_missing) > 0:\n",
    "    print(f\"   âš ï¸ Tickers with >5% missing data:\")\n",
    "    for ticker, pct in high_missing.items():\n",
    "        print(f\"      {ticker}: {pct:.1f}%\")\n",
    "else:\n",
    "    print(\"   âœ… All tickers have <5% missing data\")\n",
    "\n",
    "print(f\"\\nâœ… Data verification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "b7ef7731",
   "source": [
    "### Momentum calculation methods\n",
    "\n",
    "Calculate_momentum_scores, is designed to compute momentum scores for a universe of stocks based on historical price and volume data. It offers three distinct calculation methods: 'simple' (price change percentage), 'risk_adjusted' (momentum divided by annualized volatility), and 'volume_weighted' (momentum multiplied by a relative volume factor). "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "8828ad4e",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_momentum_scores(adj_close, volume, daily_returns, previous_date, lookback_months, method='simple'):\n",
    "    \"\"\"\n",
    "    Calculates momentum scores for all valid stocks on a given date.\n",
    "    \n",
    "    Parameters:\n",
    "    - adj_close: DataFrame of adjusted close prices (loaded from the CSV )\n",
    "    - volume: DataFrame of trading volumes\n",
    "    - daily_returns: DataFrame of daily returns (adj_close.pct_change())\n",
    "    - previous_date: The date for calculation (end of the previous month, pd.Timestamp)\n",
    "    - lookback_months: The lookback period in months (e.g., 3, 6, 12)\n",
    "    - method: 'simple', 'risk_adjusted', or 'volume_weighted'\n",
    "    \n",
    "    Returns:\n",
    "    - A Series of scores indexed by ticker (higher is better momentum)\n",
    "    \n",
    "    Example usage:\n",
    "    scores = calculate_momentum_scores(adj_close, volume, daily_returns, pd.Timestamp('2025-07-31'), 6, 'simple')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle timezone issues - unify by removing timezone information\n",
    "    if adj_close.index.tz is not None:\n",
    "        adj_close_tz_naive = adj_close.copy()\n",
    "        adj_close_tz_naive.index = adj_close.index.tz_localize(None)\n",
    "    else:\n",
    "        adj_close_tz_naive = adj_close\n",
    "    \n",
    "    if volume.index.tz is not None:\n",
    "        volume_tz_naive = volume.copy()\n",
    "        volume_tz_naive.index = volume.index.tz_localize(None)\n",
    "    else:\n",
    "        volume_tz_naive = volume\n",
    "    \n",
    "    if daily_returns.index.tz is not None:\n",
    "        daily_returns_tz_naive = daily_returns.copy()\n",
    "        daily_returns_tz_naive.index = daily_returns.index.tz_localize(None)\n",
    "    else:\n",
    "        daily_returns_tz_naive = daily_returns\n",
    "    \n",
    "    # Ensure previous_date is also timezone-naive\n",
    "    if hasattr(previous_date, 'tz') and previous_date.tz is not None:\n",
    "        previous_date = previous_date.tz_localize(None)\n",
    "    \n",
    "    # Find the lookback start date (approximately N months ago, taking the closest trading day)\n",
    "    lookback_start = previous_date - pd.DateOffset(months=lookback_months)\n",
    "    available_dates = adj_close_tz_naive.index[adj_close_tz_naive.index >= lookback_start]\n",
    "    if len(available_dates) == 0:\n",
    "        print(f\"Warning: No data found after {lookback_start}\")\n",
    "        return pd.Series(dtype=float)\n",
    "    lookback_start = available_dates[0]\n",
    "    \n",
    "    # Extract lookback period data, including only stocks with no NaN values\n",
    "    close_lookback = adj_close_tz_naive.loc[lookback_start:previous_date]\n",
    "    \n",
    "    # Exclude indices and ETFs, keeping only individual stocks\n",
    "    exclude_symbols = ['XLK', 'SPY', '^VIX', '^VIX3M', '^IRX']\n",
    "    valid_stocks = []\n",
    "    for col in close_lookback.columns:\n",
    "        if col not in exclude_symbols and close_lookback[col].notna().all():\n",
    "            valid_stocks.append(col)\n",
    "    \n",
    "    valid_stocks = pd.Index(valid_stocks)\n",
    "    \n",
    "    if len(valid_stocks) < 10:  # Minimum stock count threshold to avoid invalid calculations\n",
    "        print(f\"Warning: Too few valid stocks ({len(valid_stocks)}) for effective calculation\")\n",
    "        return pd.Series(dtype=float)\n",
    "    \n",
    "    # Basic momentum: price rate of change\n",
    "    try:\n",
    "        close_t = adj_close_tz_naive.loc[previous_date, valid_stocks]\n",
    "        close_tk = adj_close_tz_naive.loc[lookback_start, valid_stocks]\n",
    "        mom = close_t / close_tk - 1\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Date {previous_date} or {lookback_start} not in data\")\n",
    "        return pd.Series(dtype=float)\n",
    "    \n",
    "    if method == 'simple':\n",
    "        scores = mom\n",
    "    elif method == 'risk_adjusted':\n",
    "        # Calculate annualized volatility with better error handling\n",
    "        daily_ret_lb = daily_returns_tz_naive.loc[lookback_start:previous_date, valid_stocks]\n",
    "        vol = daily_ret_lb.std() * np.sqrt(252)  # Annualize\n",
    "        \n",
    "        # Replace zeros and very small volatilities to avoid extreme ratios\n",
    "        vol = vol.replace(0, np.nan)\n",
    "        vol = vol.where(vol > 0.01, np.nan)  # Filter out extremely low volatility stocks\n",
    "        \n",
    "        scores = mom / vol\n",
    "        # Filter out extreme values\n",
    "        scores = scores.where(np.abs(scores) <= 10, np.nan)  # Cap at reasonable range\n",
    "        \n",
    "    elif method == 'volume_weighted':\n",
    "        # Baseline volume: past 12 months or available period\n",
    "        baseline_start = previous_date - pd.DateOffset(months=12)\n",
    "        available_baseline_dates = adj_close_tz_naive.index[adj_close_tz_naive.index >= baseline_start]\n",
    "        if len(available_baseline_dates) == 0:\n",
    "            baseline_start = adj_close_tz_naive.index[0]  # Use the earliest available date\n",
    "        else:\n",
    "            baseline_start = available_baseline_dates[0]\n",
    "            \n",
    "        # Select only stocks that exist in the volume data\n",
    "        volume_valid_stocks = valid_stocks.intersection(volume_tz_naive.columns)\n",
    "        \n",
    "        vol_lb = volume_tz_naive.loc[lookback_start:previous_date, volume_valid_stocks].mean()\n",
    "        vol_baseline = volume_tz_naive.loc[baseline_start:previous_date, volume_valid_stocks].mean()\n",
    "        \n",
    "        # Avoid division by zero in volume calculations\n",
    "        vol_baseline = vol_baseline.replace(0, np.nan)\n",
    "        volume_factor = vol_lb / vol_baseline  # Relative volume\n",
    "        \n",
    "        # Cap volume factor to reasonable range\n",
    "        volume_factor = volume_factor.where((volume_factor >= 0.1) & (volume_factor <= 10), 1.0)\n",
    "        \n",
    "        # Calculate scores only for stocks with volume data\n",
    "        scores = pd.Series(index=valid_stocks, dtype=float)\n",
    "        for stock in volume_valid_stocks:\n",
    "            if stock in mom.index and not pd.isna(volume_factor[stock]) and volume_factor[stock] > 0:\n",
    "                scores[stock] = mom[stock] * volume_factor[stock]\n",
    "            elif stock in mom.index:\n",
    "                scores[stock] = mom[stock]  # If no volume data, use basic momentum\n",
    "        \n",
    "        scores = scores.dropna()\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid method: {method}\")\n",
    "    \n",
    "    # Final cleanup: remove infinite values and extreme outliers\n",
    "    scores = scores.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Filter out extreme outliers (beyond 3 standard deviations)\n",
    "    if len(scores.dropna()) > 5:\n",
    "        mean_score = scores.mean()\n",
    "        std_score = scores.std()\n",
    "        if std_score > 0:\n",
    "            scores = scores.where(np.abs(scores - mean_score) <= 3 * std_score, np.nan)\n",
    "    \n",
    "    return scores.dropna()  # Drop any remaining NaNs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "3971d30c",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reload data\n",
    "adj_close = pd.read_csv('adj_close.csv', index_col=0, parse_dates=True)\n",
    "volume = pd.read_csv('volume.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# Handle timezone issues - unify by removing timezone information\n",
    "if adj_close.index.tz is not None:\n",
    "    adj_close.index = adj_close.index.tz_localize(None)\n",
    "if volume.index.tz is not None:\n",
    "    volume.index = volume.index.tz_localize(None)\n",
    "\n",
    "# Fix FutureWarning - explicitly specify fill_method=None\n",
    "daily_returns = adj_close.pct_change(fill_method=None)\n",
    "\n",
    "print(\"Data loading complete:\")\n",
    "print(f\"adj_close shape: {adj_close.shape}\")\n",
    "print(f\"volume shape: {volume.shape}\")\n",
    "print(f\"Date range: {adj_close.index[0]} to {adj_close.index[-1]}\")\n",
    "\n",
    "# Test case: End of July 2025, 6-month lookback, simple method\n",
    "test_date = pd.Timestamp('2026-01-30')  # Assume this is the month-end; if no data, take the nearest\n",
    "\n",
    "# Ensure test_date is timezone-naive\n",
    "if hasattr(test_date, 'tz') and test_date.tz is not None:\n",
    "    test_date = test_date.tz_localize(None)\n",
    "\n",
    "if test_date not in adj_close.index:\n",
    "    available_dates = adj_close.index[adj_close.index <= test_date]\n",
    "    if len(available_dates) > 0:\n",
    "        test_date = available_dates[-1]  # Take the most recent trading day\n",
    "    else:\n",
    "        test_date = adj_close.index[-1]  # If no suitable date, take the latest date\n",
    "\n",
    "print(f\"\\nUsing test date: {test_date}\")\n",
    "\n",
    "# Simple Momentum Scores\n",
    "print(\"\\n=== Simple Momentum Scores ===\")\n",
    "scores_simple = calculate_momentum_scores(adj_close, volume, daily_returns, test_date, 6, 'simple')\n",
    "if len(scores_simple) > 0:\n",
    "    print(f\"Simple momentum scores (top 5):\\n{scores_simple.sort_values(ascending=False).head(5)}\")\n",
    "else:\n",
    "    print(\"Simple momentum calculation failed\")\n",
    "\n",
    "# Risk-Adjusted Momentum Scores\n",
    "print(\"\\n=== Risk-Adjusted Momentum Scores ===\")\n",
    "scores_risk = calculate_momentum_scores(adj_close, volume, daily_returns, test_date, 6, 'risk_adjusted')\n",
    "if len(scores_risk) > 0:\n",
    "    print(f\"Risk-adjusted momentum scores (top 5):\\n{scores_risk.sort_values(ascending=False).head(5)}\")\n",
    "else:\n",
    "    print(\"Risk-adjusted momentum calculation failed\")\n",
    "\n",
    "# Volume-Weighted Momentum Scores\n",
    "print(\"\\n=== Volume-Weighted Momentum Scores ===\")\n",
    "scores_vol = calculate_momentum_scores(adj_close, volume, daily_returns, test_date, 6, 'volume_weighted')\n",
    "if len(scores_vol) > 0:\n",
    "    print(f\"Volume-weighted momentum scores (top 5):\\n{scores_vol.sort_values(ascending=False).head(5)}\")\n",
    "else:\n",
    "    print(\"Volume-weighted momentum calculation failed\")\n",
    "\n",
    "print(f\"\\n=== Test Complete ===\")\n",
    "print(f\"Number of valid stocks: {len(scores_simple)} (simple), {len(scores_risk)} (risk-adjusted), {len(scores_vol)} (volume-weighted)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "9720d410",
   "source": [
    "### V5 Dual-Factor VIX Regime Classification\n",
    "\n",
    "V5 replaces the V4 single-point VIX gating with a dual-factor monthly regime classifier:\n",
    "\n",
    "**Factor 1 â€” Time-Proportion (Noise Filter)**\n",
    "- Threshold: `thr = max(20, rolling_252d_75th_percentile(VIX))`\n",
    "- Metric: proportion of trading days in month where VIX > thr\n",
    "- Trigger: proportion > 25%\n",
    "\n",
    "**Factor 2 â€” Term Structure Inversion (VIX/VIX3M)**\n",
    "- Normal (contango): VIX < VIX3M, ratio < 1\n",
    "- Elevated: monthly avg ratio > 0.97\n",
    "- Panic (backwardation): monthly avg ratio > 1.00\n",
    "\n",
    "**Three Regimes:**\n",
    "\n",
    "| Regime | Condition | w_vix |\n",
    "|--------|-----------|-------|\n",
    "| Normal | Neither factor triggers | 1.00 |\n",
    "| Elevated | Exactly one factor triggers | 0.75 |\n",
    "| Panic | Both factors trigger (high time-proportion AND term structure inversion) | 0.35 |\n",
    "\n",
    "**Fallback**: If VIX3M unavailable, max regime is Elevated (no Panic).\n",
    "\n",
    "Position sizing formula (unchanged from V4):\n",
    "`equity_weight = w_vix * (0.40 * w_mom + 0.35 * w_trend + 0.25 * 1.0)`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "d0cbb60d",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def classify_trend(adj_close, signal_date):\n",
    "    if 'XLK' not in adj_close.columns:\n",
    "        return 'Mixed'\n",
    "    idx = adj_close.index[adj_close.index <= signal_date]\n",
    "    if len(idx) == 0:\n",
    "        return 'Mixed'\n",
    "    sdate = idx[-1]\n",
    "\n",
    "    def lb_ret(months):\n",
    "        start = sdate - pd.DateOffset(months=months)\n",
    "        prior_idx = adj_close.index[adj_close.index <= start]\n",
    "        if len(prior_idx) == 0:\n",
    "            return np.nan\n",
    "        p0 = adj_close.at[prior_idx[-1], 'XLK']\n",
    "        p1 = adj_close.at[sdate, 'XLK']\n",
    "        if pd.isna(p0) or pd.isna(p1) or p0 == 0:\n",
    "            return np.nan\n",
    "        return p1 / p0 - 1\n",
    "\n",
    "    r3 = lb_ret(3)\n",
    "    r6 = lb_ret(6)\n",
    "    r12 = lb_ret(12)\n",
    "    positives = int(r3 > 0) + int(r6 > 0) + int(r12 > 0)\n",
    "    if positives == 3:\n",
    "        return 'Strong Uptrend'\n",
    "    if positives == 2:\n",
    "        return 'Uptrend'\n",
    "    if positives == 1:\n",
    "        return 'Mixed'\n",
    "    return 'Downtrend'\n",
    "\n",
    "\n",
    "def calculate_position_size_v3(vix_level, momentum_signal, trend_strength):\n",
    "    if pd.isna(vix_level):\n",
    "        w_vix = 0.75\n",
    "    elif vix_level < 15:\n",
    "        w_vix = 1.0\n",
    "    elif vix_level < 20:\n",
    "        w_vix = 1.0\n",
    "    elif vix_level < 25:\n",
    "        w_vix = 0.75\n",
    "    elif vix_level < 30:\n",
    "        w_vix = 0.50\n",
    "    elif vix_level < 40:\n",
    "        w_vix = 0.25\n",
    "    else:\n",
    "        w_vix = 0.0\n",
    "\n",
    "    if pd.isna(momentum_signal):\n",
    "        w_mom = 0.50\n",
    "    elif momentum_signal > 1.5:\n",
    "        w_mom = 1.0\n",
    "    elif momentum_signal > 1.0:\n",
    "        w_mom = 0.85\n",
    "    elif momentum_signal > 0.5:\n",
    "        w_mom = 0.70\n",
    "    elif momentum_signal > 0.0:\n",
    "        w_mom = 0.50\n",
    "    else:\n",
    "        w_mom = 0.25\n",
    "\n",
    "    trend_map = {\n",
    "        'Strong Uptrend': 1.0,\n",
    "        'Uptrend': 0.80,\n",
    "        'Mixed': 0.50,\n",
    "        'Downtrend': 0.25,\n",
    "    }\n",
    "    w_trend = trend_map.get(trend_strength, 0.50)\n",
    "\n",
    "    equity_weight = w_vix * (0.4 * w_mom + 0.4 * w_trend + 0.2 * 1.0)\n",
    "    equity_weight = float(np.clip(equity_weight, 0.0, 1.0))\n",
    "    cash_weight = 1.0 - equity_weight\n",
    "\n",
    "    return {\n",
    "        'equity_weight': equity_weight,\n",
    "        'cash_weight': cash_weight,\n",
    "        'signal_details': {\n",
    "            'vix_level': float(vix_level) if pd.notna(vix_level) else np.nan,\n",
    "            'momentum_signal': float(momentum_signal) if pd.notna(momentum_signal) else np.nan,\n",
    "            'trend_strength': trend_strength,\n",
    "            'w_vix': float(w_vix),\n",
    "            'w_mom': float(w_mom),\n",
    "            'w_trend': float(w_trend),\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_monthly_vix_regime(\n",
    "    vix_daily,\n",
    "    vix3m_daily,\n",
    "    signal_date,\n",
    "    lookback_days=252,\n",
    "    q=0.75,\n",
    "    vix_floor=20.0,\n",
    "    p_thr=0.25,\n",
    "    r_elev=0.97,\n",
    "    r_panic=1.00,\n",
    "    min_days=10,\n",
    "    prev_regime='Normal',\n",
    "):\n",
    "    \"\"\"\n",
    "    Dual-factor monthly VIX regime classifier.\n",
    "\n",
    "    Factor 1: Time-proportion of days VIX > adaptive threshold\n",
    "    Factor 2: VIX/VIX3M term structure ratio\n",
    "\n",
    "    Returns (regime_str, w_vix_float)\n",
    "    \"\"\"\n",
    "    w_map = {'Normal': 1.0, 'Elevated': 0.75, 'Panic': 0.35}\n",
    "\n",
    "    vix_upto = vix_daily.loc[:signal_date].dropna()\n",
    "    if len(vix_upto) < 30:\n",
    "        return prev_regime, w_map.get(prev_regime, 1.0)\n",
    "\n",
    "    # Adaptive threshold: rolling 252d 75th percentile with floor\n",
    "    window = vix_upto.iloc[-lookback_days:] if len(vix_upto) > lookback_days else vix_upto\n",
    "    thr_vix = max(vix_floor, float(window.quantile(q)))\n",
    "\n",
    "    # This month's daily VIX\n",
    "    month_period = signal_date.to_period('M')\n",
    "    month_mask = vix_upto.index.to_period('M') == month_period\n",
    "    vix_month = vix_upto.loc[month_mask]\n",
    "\n",
    "    if len(vix_month) < min_days:\n",
    "        return prev_regime, w_map.get(prev_regime, 1.0)\n",
    "\n",
    "    # Factor 1: time-proportion\n",
    "    p_high = float((vix_month > thr_vix).mean())\n",
    "    high_time = (p_high > p_thr)\n",
    "\n",
    "    # Factor 2: term structure ratio\n",
    "    r_avg = None\n",
    "    if vix3m_daily is not None and len(vix3m_daily) > 0:\n",
    "        vix3m_upto = vix3m_daily.loc[:signal_date].dropna()\n",
    "        common = vix_month.index.intersection(vix3m_upto.index)\n",
    "        if len(common) >= min_days:\n",
    "            ratio = (vix_month.loc[common] / vix3m_upto.loc[common])\n",
    "            ratio = ratio.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            if len(ratio) >= min_days:\n",
    "                r_avg = float(ratio.mean())\n",
    "\n",
    "    # Classify regime\n",
    "    if r_avg is None:\n",
    "        # Fallback: no VIX3M data, cap at Elevated\n",
    "        regime = 'Elevated' if high_time else 'Normal'\n",
    "    else:\n",
    "        inv_panic = (r_avg > r_panic)\n",
    "        flat_elev = (r_avg > r_elev)\n",
    "\n",
    "        if high_time and inv_panic:\n",
    "            regime = 'Panic'\n",
    "        elif high_time or flat_elev:\n",
    "            regime = 'Elevated'\n",
    "        else:\n",
    "            regime = 'Normal'\n",
    "\n",
    "    return regime, w_map[regime]\n",
    "\n",
    "\n",
    "def calculate_position_size_v5(regime, w_vix, momentum_signal, trend_strength):\n",
    "    \"\"\"V5 position sizing using regime-based VIX weight.\"\"\"\n",
    "    # Momentum signal weight (same thresholds as V4)\n",
    "    if pd.isna(momentum_signal):\n",
    "        w_mom = 0.50\n",
    "    elif momentum_signal > 0.8:\n",
    "        w_mom = 1.0\n",
    "    elif momentum_signal > 0.4:\n",
    "        w_mom = 0.90\n",
    "    elif momentum_signal > 0.0:\n",
    "        w_mom = 0.75\n",
    "    elif momentum_signal > -0.3:\n",
    "        w_mom = 0.50\n",
    "    else:\n",
    "        w_mom = 0.20\n",
    "\n",
    "    trend_map = {\n",
    "        'Strong Uptrend': 1.0,\n",
    "        'Uptrend': 0.80,\n",
    "        'Mixed': 0.50,\n",
    "        'Downtrend': 0.25,\n",
    "    }\n",
    "    w_trend = trend_map.get(trend_strength, 0.50)\n",
    "\n",
    "    # Same formula as V4 but w_vix comes from regime classifier\n",
    "    equity_weight = w_vix * (0.40 * w_mom + 0.35 * w_trend + 0.25 * 1.0)\n",
    "    equity_weight = float(np.clip(equity_weight, 0.0, 1.0))\n",
    "    cash_weight = 1.0 - equity_weight\n",
    "\n",
    "    return {\n",
    "        'equity_weight': equity_weight,\n",
    "        'cash_weight': cash_weight,\n",
    "        'signal_details': {\n",
    "            'regime': regime,\n",
    "            'w_vix': float(w_vix),\n",
    "            'momentum_signal': float(momentum_signal) if pd.notna(momentum_signal) else np.nan,\n",
    "            'trend_strength': trend_strength,\n",
    "            'w_mom': float(w_mom),\n",
    "            'w_trend': float(w_trend),\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "2b60ca78",
   "source": [
    "### Strategy Backtesting: V5 and V4 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "e01d94fe",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def backtest_strategy_v3(\n",
    "    adj_close,\n",
    "    volume,\n",
    "    lookback_months=6,\n",
    "    method='simple',\n",
    "    decile=0.3,\n",
    "    tc_bps=5,\n",
    "    holding_period=1,\n",
    "    winsor_q=0.01,\n",
    "):\n",
    "    daily_returns = adj_close.pct_change(fill_method=None)\n",
    "\n",
    "    month_ends = adj_close.resample('M').last().index\n",
    "    valid_month_ends = []\n",
    "    for me in month_ends:\n",
    "        month_data = adj_close[(adj_close.index.month == me.month) & (adj_close.index.year == me.year)]\n",
    "        if len(month_data) > 0:\n",
    "            valid_month_ends.append(month_data.index[-1])\n",
    "    valid_month_ends = pd.DatetimeIndex(valid_month_ends).unique().sort_values()\n",
    "\n",
    "    if len(valid_month_ends) <= lookback_months + 1:\n",
    "        return pd.DataFrame(columns=[\n",
    "            'strategy_returns', 'equity_returns', 'cash_returns',\n",
    "            'equity_weight', 'cash_weight', 'num_holdings', 'turnover'\n",
    "        ])\n",
    "\n",
    "    def _get_ret(symbol, start_date, end_date):\n",
    "        if symbol not in adj_close.columns:\n",
    "            return np.nan\n",
    "        try:\n",
    "            p0 = adj_close.at[start_date, symbol]\n",
    "            p1 = adj_close.at[end_date, symbol]\n",
    "            if pd.isna(p0) or pd.isna(p1) or p0 == 0:\n",
    "                return np.nan\n",
    "            return p1 / p0 - 1\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    def _cash_return(prev_date, curr_date):\n",
    "        if '^IRX' not in adj_close.columns:\n",
    "            return 0.0\n",
    "        rf = adj_close['^IRX'].loc[(adj_close.index > prev_date) & (adj_close.index <= curr_date)]\n",
    "        if len(rf) == 0:\n",
    "            return 0.0\n",
    "        daily_rf = pd.to_numeric(rf, errors='coerce') / 100.0 / 252.0\n",
    "        daily_rf = daily_rf.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "        return float((1.0 + daily_rf).prod() - 1.0)\n",
    "\n",
    "    out_rows = []\n",
    "    out_index = []\n",
    "\n",
    "    current_holdings = pd.Index([])\n",
    "    equity_weight = 0.0\n",
    "    cash_weight = 1.0\n",
    "    prev_asset_weights = {'CASH': 1.0}\n",
    "\n",
    "    start_i = lookback_months\n",
    "    for i in range(start_i, len(valid_month_ends)):\n",
    "        current_date = valid_month_ends[i]\n",
    "        previous_date = valid_month_ends[i - 1]\n",
    "\n",
    "        rebalance_now = ((i - start_i) % holding_period == 0) or (len(current_holdings) == 0)\n",
    "        turnover = 0.0\n",
    "\n",
    "        if rebalance_now:\n",
    "            signal_date = previous_date\n",
    "            scores = calculate_momentum_scores(\n",
    "                adj_close,\n",
    "                volume,\n",
    "                daily_returns,\n",
    "                signal_date,\n",
    "                lookback_months,\n",
    "                method,\n",
    "            )\n",
    "\n",
    "            scores = scores.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            if len(scores) > 0:\n",
    "                top_n = max(1, int(len(scores) * decile))\n",
    "                selected = scores.sort_values(ascending=False).head(top_n)\n",
    "                current_holdings = selected.index\n",
    "                mom_signal = float(selected.mean()) if len(selected) > 0 else 0.0\n",
    "            else:\n",
    "                current_holdings = pd.Index([])\n",
    "                mom_signal = 0.0\n",
    "\n",
    "            if '^VIX' in adj_close.columns:\n",
    "                vix_series = adj_close['^VIX'].loc[adj_close.index <= signal_date].dropna()\n",
    "                vix_level = float(vix_series.iloc[-1]) if len(vix_series) > 0 else np.nan\n",
    "            else:\n",
    "                vix_level = np.nan\n",
    "\n",
    "            trend_strength = classify_trend(adj_close, signal_date)\n",
    "            sizing = calculate_position_size_v3(vix_level, mom_signal, trend_strength)\n",
    "            equity_weight = sizing['equity_weight']\n",
    "            cash_weight = sizing['cash_weight']\n",
    "\n",
    "            new_asset_weights = {'CASH': cash_weight}\n",
    "            if len(current_holdings) > 0 and equity_weight > 0:\n",
    "                per_stock = equity_weight / len(current_holdings)\n",
    "                for s in current_holdings:\n",
    "                    new_asset_weights[s] = per_stock\n",
    "\n",
    "            all_assets = set(prev_asset_weights) | set(new_asset_weights)\n",
    "            l1 = sum(abs(new_asset_weights.get(a, 0.0) - prev_asset_weights.get(a, 0.0)) for a in all_assets)\n",
    "            turnover = 0.5 * l1\n",
    "            prev_asset_weights = new_asset_weights\n",
    "\n",
    "        stock_rets = []\n",
    "        for sym in current_holdings:\n",
    "            r = _get_ret(sym, previous_date, current_date)\n",
    "            if pd.notna(r) and np.isfinite(r):\n",
    "                stock_rets.append(r)\n",
    "\n",
    "        if len(stock_rets) > 0:\n",
    "            stock_rets = pd.Series(stock_rets)\n",
    "            if len(stock_rets) > 5:\n",
    "                lo = stock_rets.quantile(winsor_q)\n",
    "                hi = stock_rets.quantile(1 - winsor_q)\n",
    "                stock_rets = stock_rets.clip(lo, hi)\n",
    "            equity_ret = float(stock_rets.mean())\n",
    "        else:\n",
    "            equity_ret = 0.0\n",
    "\n",
    "        cash_ret = _cash_return(previous_date, current_date)\n",
    "        tc = (tc_bps / 10000.0) * turnover\n",
    "        strategy_ret = equity_weight * equity_ret + cash_weight * cash_ret - tc\n",
    "\n",
    "        out_index.append(current_date)\n",
    "        out_rows.append({\n",
    "            'strategy_returns': strategy_ret,\n",
    "            'equity_returns': equity_ret,\n",
    "            'cash_returns': cash_ret,\n",
    "            'equity_weight': equity_weight,\n",
    "            'cash_weight': cash_weight,\n",
    "            'num_holdings': int(len(current_holdings)),\n",
    "            'turnover': turnover,\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(out_rows, index=pd.DatetimeIndex(out_index))\n",
    "    out = out.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    return out\n",
    "\n",
    "\n",
    "def backtest_strategy_v5(\n",
    "    adj_close,\n",
    "    volume,\n",
    "    lookback_months=6,\n",
    "    method='simple',\n",
    "    decile=0.3,\n",
    "    tc_bps=5,\n",
    "    holding_period=1,\n",
    "    winsor_q=0.01,\n",
    "):\n",
    "    daily_returns = adj_close.pct_change(fill_method=None)\n",
    "\n",
    "    month_ends = adj_close.resample('M').last().index\n",
    "    valid_month_ends = []\n",
    "    for me in month_ends:\n",
    "        month_data = adj_close[(adj_close.index.month == me.month) & (adj_close.index.year == me.year)]\n",
    "        if len(month_data) > 0:\n",
    "            valid_month_ends.append(month_data.index[-1])\n",
    "    valid_month_ends = pd.DatetimeIndex(valid_month_ends).unique().sort_values()\n",
    "\n",
    "    if len(valid_month_ends) <= lookback_months + 1:\n",
    "        return pd.DataFrame(columns=[\n",
    "            'strategy_returns', 'equity_returns', 'cash_returns',\n",
    "            'equity_weight', 'cash_weight', 'num_holdings', 'turnover'\n",
    "        ])\n",
    "\n",
    "    def _get_ret(symbol, start_date, end_date):\n",
    "        if symbol not in adj_close.columns:\n",
    "            return np.nan\n",
    "        try:\n",
    "            p0 = adj_close.at[start_date, symbol]\n",
    "            p1 = adj_close.at[end_date, symbol]\n",
    "            if pd.isna(p0) or pd.isna(p1) or p0 == 0:\n",
    "                return np.nan\n",
    "            return p1 / p0 - 1\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    def _cash_return(prev_date, curr_date):\n",
    "        if '^IRX' not in adj_close.columns:\n",
    "            return 0.0\n",
    "        rf = adj_close['^IRX'].loc[(adj_close.index > prev_date) & (adj_close.index <= curr_date)]\n",
    "        if len(rf) == 0:\n",
    "            return 0.0\n",
    "        daily_rf = pd.to_numeric(rf, errors='coerce') / 100.0 / 252.0\n",
    "        daily_rf = daily_rf.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "        return float((1.0 + daily_rf).prod() - 1.0)\n",
    "\n",
    "    out_rows = []\n",
    "    out_index = []\n",
    "\n",
    "    current_holdings = pd.Index([])\n",
    "    equity_weight = 0.0\n",
    "    cash_weight = 1.0\n",
    "    prev_asset_weights = {'CASH': 1.0}\n",
    "    current_asset_weights = {'CASH': 1.0}\n",
    "    prev_regime = 'Normal'\n",
    "\n",
    "    start_i = lookback_months\n",
    "    for i in range(start_i, len(valid_month_ends)):\n",
    "        current_date = valid_month_ends[i]\n",
    "        previous_date = valid_month_ends[i - 1]\n",
    "\n",
    "        rebalance_now = ((i - start_i) % holding_period == 0) or (len(current_holdings) == 0)\n",
    "        turnover = 0.0\n",
    "\n",
    "        if rebalance_now:\n",
    "            signal_date = previous_date\n",
    "            scores = calculate_momentum_scores(\n",
    "                adj_close,\n",
    "                volume,\n",
    "                daily_returns,\n",
    "                signal_date,\n",
    "                lookback_months,\n",
    "                method,\n",
    "            )\n",
    "\n",
    "            scores = scores.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            if len(scores) > 0:\n",
    "                top_n = max(1, int(len(scores) * decile))\n",
    "                selected = scores.sort_values(ascending=False).head(top_n)\n",
    "                current_holdings = selected.index\n",
    "                mom_signal = float(selected.mean()) if len(selected) > 0 else 0.0\n",
    "            else:\n",
    "                current_holdings = pd.Index([])\n",
    "                mom_signal = 0.0\n",
    "\n",
    "            # V5: Dual-factor regime classification\n",
    "            vix_daily = adj_close['^VIX'] if '^VIX' in adj_close.columns else pd.Series(dtype=float)\n",
    "            vix3m_daily = adj_close['^VIX3M'] if '^VIX3M' in adj_close.columns else None\n",
    "\n",
    "            regime, w_vix = compute_monthly_vix_regime(\n",
    "                vix_daily, vix3m_daily, signal_date,\n",
    "                prev_regime=prev_regime,\n",
    "            )\n",
    "            prev_regime = regime\n",
    "\n",
    "            trend_strength = classify_trend(adj_close, signal_date)\n",
    "            sizing = calculate_position_size_v5(regime, w_vix, mom_signal, trend_strength)\n",
    "            equity_weight = sizing['equity_weight']\n",
    "            cash_weight = sizing['cash_weight']\n",
    "\n",
    "            weights = {}\n",
    "\n",
    "            # V4 Change 4: momentum-weighted stock allocation\n",
    "            if len(current_holdings) > 0 and equity_weight > 0 and len(scores) > 0:\n",
    "                held_scores = scores.loc[scores.index.isin(current_holdings)]\n",
    "                if len(held_scores) > 0:\n",
    "                    shifted = held_scores - held_scores.min() + 0.01\n",
    "                    if float(shifted.sum()) > 0:\n",
    "                        stock_weights = (shifted / shifted.sum()) * equity_weight\n",
    "                        for ticker in current_holdings:\n",
    "                            if ticker in stock_weights.index:\n",
    "                                weights[ticker] = float(stock_weights[ticker])\n",
    "                            else:\n",
    "                                weights[ticker] = equity_weight / len(current_holdings)\n",
    "                    else:\n",
    "                        per_stock = equity_weight / len(current_holdings)\n",
    "                        for ticker in current_holdings:\n",
    "                            weights[ticker] = per_stock\n",
    "                else:\n",
    "                    per_stock = equity_weight / len(current_holdings)\n",
    "                    for ticker in current_holdings:\n",
    "                        weights[ticker] = per_stock\n",
    "\n",
    "            # V4 Change 5: conditional short leg in downtrend regimes\n",
    "            if trend_strength == 'Downtrend' and regime != 'Panic' and len(scores) > 0:\n",
    "                n_short = max(1, int(len(scores) * 0.10))\n",
    "                short_tickers = scores.nsmallest(n_short).index.tolist()\n",
    "                short_weight = 0.15 * cash_weight\n",
    "                if len(short_tickers) > 0:\n",
    "                    per_short = short_weight / len(short_tickers)\n",
    "                    for t in short_tickers:\n",
    "                        weights[t] = weights.get(t, 0.0) - per_short\n",
    "\n",
    "            new_asset_weights = {'CASH': cash_weight}\n",
    "            for k, v in weights.items():\n",
    "                if pd.notna(v) and np.isfinite(v):\n",
    "                    new_asset_weights[k] = float(v)\n",
    "\n",
    "            all_assets = set(prev_asset_weights) | set(new_asset_weights)\n",
    "            l1 = sum(abs(new_asset_weights.get(a, 0.0) - prev_asset_weights.get(a, 0.0)) for a in all_assets)\n",
    "            turnover = 0.5 * l1\n",
    "            prev_asset_weights = new_asset_weights\n",
    "            current_asset_weights = new_asset_weights\n",
    "\n",
    "        # Realized returns for all non-cash positions (long and short weights)\n",
    "        realized = {}\n",
    "        for sym, w in current_asset_weights.items():\n",
    "            if sym == 'CASH':\n",
    "                continue\n",
    "            r = _get_ret(sym, previous_date, current_date)\n",
    "            if pd.notna(r) and np.isfinite(r):\n",
    "                realized[sym] = float(r)\n",
    "\n",
    "        if len(realized) > 0:\n",
    "            ret_series = pd.Series(realized)\n",
    "            if len(ret_series) > 5:\n",
    "                lo = ret_series.quantile(winsor_q)\n",
    "                hi = ret_series.quantile(1 - winsor_q)\n",
    "                ret_series = ret_series.clip(lo, hi)\n",
    "\n",
    "            common = [s for s in ret_series.index if s in current_asset_weights and s != 'CASH']\n",
    "            if len(common) > 0:\n",
    "                w_series = pd.Series({s: current_asset_weights[s] for s in common}, dtype=float)\n",
    "                weighted_stock_ret = float((w_series * ret_series.loc[common]).sum())\n",
    "                gross_exposure = float(w_series.abs().sum())\n",
    "                equity_ret = float(weighted_stock_ret / gross_exposure) if gross_exposure > 0 else 0.0\n",
    "            else:\n",
    "                weighted_stock_ret = 0.0\n",
    "                equity_ret = 0.0\n",
    "        else:\n",
    "            weighted_stock_ret = 0.0\n",
    "            equity_ret = 0.0\n",
    "\n",
    "        cash_ret = _cash_return(previous_date, current_date)\n",
    "        tc = (tc_bps / 10000.0) * turnover\n",
    "        strategy_ret = weighted_stock_ret + cash_weight * cash_ret - tc\n",
    "\n",
    "        out_index.append(current_date)\n",
    "        out_rows.append({\n",
    "            'strategy_returns': strategy_ret,\n",
    "            'equity_returns': equity_ret,\n",
    "            'cash_returns': cash_ret,\n",
    "            'equity_weight': equity_weight,\n",
    "            'cash_weight': cash_weight,\n",
    "            'num_holdings': int(len(current_holdings)),\n",
    "            'turnover': turnover,\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(out_rows, index=pd.DatetimeIndex(out_index))\n",
    "    out = out.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "19347200",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reload data\n",
    "adj_close = pd.read_csv('adj_close.csv', index_col=0, parse_dates=True)\n",
    "volume = pd.read_csv('volume.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "if adj_close.index.tz is not None:\n",
    "    adj_close.index = adj_close.index.tz_localize(None)\n",
    "if volume.index.tz is not None:\n",
    "    volume.index = volume.index.tz_localize(None)\n",
    "\n",
    "ret_simple_v5 = backtest_strategy_v5(adj_close, volume, lookback_months=6, method='simple', decile=0.3, holding_period=1)\n",
    "ret_risk_v5 = backtest_strategy_v5(adj_close, volume, lookback_months=6, method='risk_adjusted', decile=0.3, holding_period=1)\n",
    "ret_vol_v5 = backtest_strategy_v5(adj_close, volume, lookback_months=6, method='volume_weighted', decile=0.3, holding_period=1)\n",
    "\n",
    "for name, df_ in [\n",
    "    ('Simple', ret_simple_v5),\n",
    "    ('Risk-Adjusted', ret_risk_v5),\n",
    "    ('Volume-Weighted', ret_vol_v5),\n",
    "]:\n",
    "    r = df_['strategy_returns'] if 'strategy_returns' in df_.columns else pd.Series(dtype=float)\n",
    "    ann_ret = (1 + r.mean()) ** 12 - 1 if len(r) > 0 else 0.0\n",
    "    ann_vol = r.std() * np.sqrt(12) if len(r) > 1 else np.nan\n",
    "    sharpe = ann_ret / ann_vol if pd.notna(ann_vol) and ann_vol > 0 else np.nan\n",
    "    print(f\"{name}: months={len(r)}, ann_ret={ann_ret:.2%}, ann_vol={ann_vol:.2%}, sharpe={sharpe:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "dd33a8a7",
   "source": [
    "### Holding Period Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "aae536d0",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def analyze_holding_periods(adj_close, volume, backtest_fn, methods=None, holding_periods=None, lookback_months=6):\n",
    "    if methods is None:\n",
    "        methods = ['simple', 'risk_adjusted', 'volume_weighted']\n",
    "    if holding_periods is None:\n",
    "        holding_periods = [1, 2, 3, 6]\n",
    "\n",
    "    train_end = pd.Timestamp('2024-12-31')\n",
    "    rows = []\n",
    "\n",
    "    for m in methods:\n",
    "        for hp in holding_periods:\n",
    "            bt = backtest_fn(\n",
    "                adj_close,\n",
    "                volume,\n",
    "                lookback_months=lookback_months,\n",
    "                method=m,\n",
    "                decile=0.3,\n",
    "                tc_bps=5,\n",
    "                holding_period=hp,\n",
    "            )\n",
    "            r = bt['strategy_returns']\n",
    "            r_train = r[r.index <= train_end]\n",
    "            if len(r_train) < 12:\n",
    "                continue\n",
    "\n",
    "            ann_ret = (1 + r_train.mean()) ** 12 - 1\n",
    "            ann_vol = r_train.std() * np.sqrt(12)\n",
    "            sharpe = ann_ret / ann_vol if ann_vol > 0 else np.nan\n",
    "            max_dd = ((1 + r_train).cumprod() / (1 + r_train).cumprod().cummax() - 1).min()\n",
    "\n",
    "            rows.append({\n",
    "                'method': m,\n",
    "                'holding_period': hp,\n",
    "                'months': len(r_train),\n",
    "                'annual_return': ann_ret,\n",
    "                'annual_volatility': ann_vol,\n",
    "                'sharpe': sharpe,\n",
    "                'max_drawdown': max_dd,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values('sharpe', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "fe2fa805",
   "execution_count": null,
   "outputs": [],
   "source": [
    "holding_period_results_v5 = analyze_holding_periods(adj_close, volume, backtest_strategy_v5)\n",
    "holding_period_results_v3 = analyze_holding_periods(adj_close, volume, backtest_strategy_v3)\n",
    "\n",
    "print(\"V5 holding period grid:\")\n",
    "print(holding_period_results_v5.round(4))\n",
    "print(\"\\nV3 holding period grid:\")\n",
    "print(holding_period_results_v3.round(4))\n",
    "\n",
    "best_config_v5 = holding_period_results_v5.iloc[0]\n",
    "best_config_v3 = holding_period_results_v3.iloc[0]\n",
    "\n",
    "print(\"\\nBest V5 config:\")\n",
    "print(best_config_v5)\n",
    "print(\"\\nBest V3 config:\")\n",
    "print(best_config_v3)\n",
    "\n",
    "best_strategy_v5_df = backtest_strategy_v5(\n",
    "    adj_close,\n",
    "    volume,\n",
    "    lookback_months=6,\n",
    "    method=best_config_v5['method'],\n",
    "    decile=0.3,\n",
    "    tc_bps=5,\n",
    "    holding_period=int(best_config_v5['holding_period']),\n",
    ")\n",
    "\n",
    "best_strategy_v3_df = backtest_strategy_v3(\n",
    "    adj_close,\n",
    "    volume,\n",
    "    lookback_months=6,\n",
    "    method=best_config_v3['method'],\n",
    "    decile=0.3,\n",
    "    tc_bps=5,\n",
    "    holding_period=int(best_config_v3['holding_period']),\n",
    ")\n",
    "\n",
    "best_v5_returns = best_strategy_v5_df['strategy_returns']\n",
    "best_v3_returns = best_strategy_v3_df['strategy_returns']"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "d2b20661",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Momentum decay analysis (score vs forward returns)\")\n",
    "\n",
    "daily_returns = adj_close.pct_change(fill_method=None)\n",
    "month_ends = adj_close.resample('M').last().index\n",
    "valid_month_ends = []\n",
    "for me in month_ends:\n",
    "    m = adj_close[(adj_close.index.month == me.month) & (adj_close.index.year == me.year)]\n",
    "    if len(m) > 0:\n",
    "        valid_month_ends.append(m.index[-1])\n",
    "valid_month_ends = pd.DatetimeIndex(valid_month_ends).unique().sort_values()\n",
    "\n",
    "score_forward_corr = {}\n",
    "for h in [1, 2, 3, 4, 5, 6]:\n",
    "    corr_list = []\n",
    "    for i in range(6, len(valid_month_ends) - h):\n",
    "        d0 = valid_month_ends[i]\n",
    "        d1 = valid_month_ends[i + h]\n",
    "        scores = calculate_momentum_scores(adj_close, volume, daily_returns, d0, 6, method='simple')\n",
    "        if len(scores) == 0:\n",
    "            continue\n",
    "\n",
    "        fwd = (adj_close.loc[d1, scores.index] / adj_close.loc[d0, scores.index] - 1).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        common = scores.index.intersection(fwd.index)\n",
    "        if len(common) >= 10:\n",
    "            c = scores.loc[common].corr(fwd.loc[common])\n",
    "            if pd.notna(c):\n",
    "                corr_list.append(c)\n",
    "\n",
    "    score_forward_corr[h] = float(np.mean(corr_list)) if len(corr_list) > 0 else np.nan\n",
    "\n",
    "for h, c in score_forward_corr.items():\n",
    "    print(f\"Forward {h}M correlation: {c:.4f}\")\n",
    "\n",
    "print(\"\\nAutocorrelation of strategy returns (best V5 config):\")\n",
    "sr = best_strategy_v5_df['strategy_returns']\n",
    "for lag in [1, 2, 3, 4, 5, 6]:\n",
    "    print(f\"Lag {lag}: {sr.autocorr(lag=lag):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "50aaedf5",
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "c1ba7a3f",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_annual_metrics(monthly_returns, rf_monthly=None):\n",
    "    monthly_returns = monthly_returns.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(monthly_returns) == 0:\n",
    "        return {\n",
    "            'months': 0,\n",
    "            'annual_return': np.nan,\n",
    "            'annual_volatility': np.nan,\n",
    "            'sharpe_ratio': np.nan,\n",
    "            'max_drawdown': np.nan,\n",
    "            'win_rate': np.nan,\n",
    "        }\n",
    "\n",
    "    ann_ret = (1 + monthly_returns.mean()) ** 12 - 1\n",
    "    ann_vol = monthly_returns.std() * np.sqrt(12)\n",
    "\n",
    "    if rf_monthly is None:\n",
    "        rf_ann = 0.0\n",
    "    else:\n",
    "        rf_aligned = rf_monthly.reindex(monthly_returns.index, method='ffill').fillna(0.0)\n",
    "        rf_ann = ((1 + rf_aligned.mean()) ** 12 - 1)\n",
    "\n",
    "    sharpe = (ann_ret - rf_ann) / ann_vol if ann_vol > 0 else np.nan\n",
    "    wealth = (1 + monthly_returns).cumprod()\n",
    "    max_dd = (wealth / wealth.cummax() - 1).min()\n",
    "\n",
    "    return {\n",
    "        'months': len(monthly_returns),\n",
    "        'annual_return': ann_ret,\n",
    "        'annual_volatility': ann_vol,\n",
    "        'sharpe_ratio': sharpe,\n",
    "        'max_drawdown': max_dd,\n",
    "        'win_rate': (monthly_returns > 0).mean(),\n",
    "    }\n",
    "\n",
    "\n",
    "rf_daily = adj_close['^IRX'] / 100 / 252 if '^IRX' in adj_close.columns else pd.Series(0.0, index=adj_close.index)\n",
    "rf_monthly = rf_daily.resample('M').apply(lambda x: (1 + x).prod() - 1 if len(x) > 0 else 0)\n",
    "\n",
    "xlk_monthly_returns = adj_close['XLK'].resample('M').last().pct_change(fill_method=None).dropna()\n",
    "spy_monthly_returns = adj_close['SPY'].resample('M').last().pct_change(fill_method=None).dropna()\n",
    "\n",
    "strategy_map = {\n",
    "    'V5 Simple (6m, hp1)': ret_simple_v5['strategy_returns'],\n",
    "    'V5 Risk-Adj (6m, hp1)': ret_risk_v5['strategy_returns'],\n",
    "    'V5 Volume-Wtd (6m, hp1)': ret_vol_v5['strategy_returns'],\n",
    "    'V5 Best Holding Config': best_v5_returns,\n",
    "    'V3 Best Holding Config': best_v3_returns,\n",
    "    'XLK Benchmark': xlk_monthly_returns,\n",
    "    'SPY Benchmark': spy_monthly_returns,\n",
    "}\n",
    "\n",
    "results_summary = {}\n",
    "for name, r in strategy_map.items():\n",
    "    m = calculate_annual_metrics(r, rf_monthly=rf_monthly)\n",
    "    results_summary[name] = m\n",
    "    print(\n",
    "        f\"{name}: months={m['months']}, ann_ret={m['annual_return']:.2%}, \"\n",
    "        f\"ann_vol={m['annual_volatility']:.2%}, sharpe={m['sharpe_ratio']:.3f}, \"\n",
    "        f\"maxDD={m['max_drawdown']:.2%}, win={m['win_rate']:.1%}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "95519345",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_summary).T\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "5f3d52d8",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# V5 vs V3 vs Benchmarks Summary Table\n",
    "comparison = pd.DataFrame({\n",
    "    'V5 Best': calculate_annual_metrics(best_v5_returns, rf_monthly=rf_monthly),\n",
    "    'V3 Best': calculate_annual_metrics(best_v3_returns, rf_monthly=rf_monthly),\n",
    "    'XLK': calculate_annual_metrics(xlk_monthly_returns, rf_monthly=rf_monthly),\n",
    "    'SPY': calculate_annual_metrics(spy_monthly_returns, rf_monthly=rf_monthly),\n",
    "}).T\n",
    "print(\"\\n=== V5 vs V3 vs Benchmarks ===\")\n",
    "print(comparison.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "15b8ae9a",
   "source": [
    "## Market Regime Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "0e19c87b",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "from scipy.stats import ttest_1samp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ðŸ” Market Regime Analysis - Data Preparation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load data and calculate benchmarks\n",
    "adj_close = pd.read_csv('adj_close.csv', index_col=0, parse_dates=True)\n",
    "volume = pd.read_csv('volume.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# Handle timezone issues\n",
    "if adj_close.index.tz is not None:\n",
    "    adj_close.index = adj_close.index.tz_localize(None)\n",
    "if volume.index.tz is not None:\n",
    "    volume.index = volume.index.tz_localize(None)\n",
    "\n",
    "# Calculate monthly data for market regime classification\n",
    "print(\"ðŸ“Š Calculating market benchmarks...\")\n",
    "\n",
    "# XLK/SPY monthly returns (market benchmarks)\n",
    "# Use 'M' for pandas 1.x compatibility (pandas 2.x uses 'ME')\n",
    "xlk_monthly = adj_close['XLK'].resample('M').last().pct_change(fill_method=None).dropna()\n",
    "\n",
    "# VIX monthly average (volatility regime indicator)\n",
    "vix_monthly = adj_close['^VIX'].resample('M').mean()\n",
    "\n",
    "# Risk-free rate monthly (from IRX)\n",
    "rf_daily = adj_close['^IRX'] / 100 / 252  # Convert to daily decimal\n",
    "rf_monthly = rf_daily.resample('M').apply(lambda x: (1 + x).prod() - 1 if len(x) > 0 else 0)\n",
    "\n",
    "spy_monthly = adj_close['SPY'].resample('M').last().pct_change(fill_method=None).dropna()\n",
    "print(f\"âœ… XLK monthly returns: {len(xlk_monthly)} months\")\n",
    "print(f\"âœ… SPY monthly returns: {len(spy_monthly)} months\")\n",
    "print(f\"âœ… VIX monthly data: {len(vix_monthly)} months\") \n",
    "print(f\"âœ… Risk-free rate monthly: {len(rf_monthly)} months\")\n",
    "\n",
    "# Get strategy returns for analysis\n",
    "print(\"\\nðŸ“ˆ Running strategy backtests for regime analysis...\")\n",
    "strategies = {}\n",
    "methods = ['simple', 'risk_adjusted', 'volume_weighted']\n",
    "lookbacks = [3, 6, 12]\n",
    "\n",
    "# Train/Test split to avoid data snooping\n",
    "train_end = pd.Timestamp('2024-12-31')\n",
    "print(f\"Train/Test split: train <= {train_end.date()}, test > {train_end.date()}\")\n",
    "\n",
    "# Test different combinations to find optimal parameters\n",
    "best_sharpe = -999\n",
    "best_strategy = None\n",
    "best_params = None\n",
    "valid_strategies = {}\n",
    "\n",
    "for method in methods:\n",
    "    for lb in lookbacks:\n",
    "        try:\n",
    "            strategy_returns = backtest_strategy_v5(adj_close, volume, lookback_months=lb, method=method, decile=0.3)\n",
    "            strategy_returns = strategy_returns['strategy_returns']\n",
    "            strategy_returns_train = strategy_returns[strategy_returns.index <= train_end]\n",
    "            if len(strategy_returns_train) > 24:  # Need sufficient data for analysis\n",
    "                # Calculate Sharpe ratio with improved numerical stability\n",
    "                \n",
    "                # Remove any extreme outliers first\n",
    "                returns_clean = strategy_returns_train.copy()\n",
    "                q1 = returns_clean.quantile(0.01)\n",
    "                q99 = returns_clean.quantile(0.99)\n",
    "                returns_clean = returns_clean.clip(q1, q99)\n",
    "                \n",
    "                annual_ret = returns_clean.mean() * 12\n",
    "                annual_vol = returns_clean.std() * np.sqrt(12)\n",
    "                \n",
    "                # Align rf_monthly with strategy returns and clean\n",
    "                rf_aligned = rf_monthly.reindex(returns_clean.index, method='ffill').fillna(0)\n",
    "                rf_aligned = rf_aligned.clip(0, 0.1)  # Cap risk-free rate at reasonable range\n",
    "                rf_annual = rf_aligned.mean() * 12\n",
    "                \n",
    "                # Calculate Sharpe with numerical stability checks\n",
    "                if annual_vol > 0.001 and not np.isnan(annual_vol) and not np.isinf(annual_vol):\n",
    "                    sharpe = (annual_ret - rf_annual) / annual_vol\n",
    "                    \n",
    "                    # Sanity check for Sharpe ratios\n",
    "                    if -10 <= sharpe <= 10 and not np.isnan(sharpe) and not np.isinf(sharpe):\n",
    "                        strategies[f\"{method}_{lb}m\"] = {\n",
    "                            'returns': strategy_returns,\n",
    "                            'sharpe': sharpe,\n",
    "                            'annual_return': annual_ret,\n",
    "                            'annual_volatility': annual_vol\n",
    "                        }\n",
    "                        valid_strategies[f\"{method}_{lb}m\"] = sharpe\n",
    "                        \n",
    "                        if sharpe > best_sharpe:\n",
    "                            best_sharpe = sharpe\n",
    "                            best_strategy = f\"{method}_{lb}m\"\n",
    "                            best_params = (method, lb)\n",
    "                        \n",
    "                        print(f\"  {method} ({lb}m): Sharpe = {sharpe:.3f}, Ann.Ret = {annual_ret:.2%}\")\n",
    "                    else:\n",
    "                        print(f\"  âŒ {method} ({lb}m): Invalid Sharpe = {sharpe:.3f}\")\n",
    "                else:\n",
    "                    print(f\"  âŒ {method} ({lb}m): Invalid volatility = {annual_vol:.6f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ {method} ({lb}m): Error - {str(e)[:50]}...\")\n",
    "\n",
    "# Fallback if no valid strategy found\n",
    "if best_strategy is None and len(strategies) > 0:\n",
    "    # Use the first available strategy as fallback\n",
    "    best_strategy = list(strategies.keys())[0]\n",
    "    best_sharpe = strategies[best_strategy]['sharpe']\n",
    "    print(f\"\\nâš ï¸ Using fallback strategy due to calculation issues\")\n",
    "\n",
    "if best_strategy is not None:\n",
    "    print(f\"\\nðŸ† Best Strategy: {best_strategy} (Sharpe: {best_sharpe:.3f})\")\n",
    "    primary_strategy = strategies[best_strategy]['returns']\n",
    "    primary_strategy = primary_strategy[primary_strategy.index > train_end]\n",
    "else:\n",
    "    print(f\"\\nâŒ No valid strategy found. Creating simple 6-month strategy.\")\n",
    "    # Create a simple fallback strategy\n",
    "    primary_strategy = backtest_strategy_v5(adj_close, volume, lookback_months=6, method='simple', decile=0.3)\n",
    "    primary_strategy = primary_strategy['strategy_returns']\n",
    "    primary_strategy = primary_strategy[primary_strategy.index > train_end]\n",
    "    best_strategy = \"simple_6m_fallback\"\n",
    "    \n",
    "    # Calculate fallback stats\n",
    "    if len(primary_strategy) > 0:\n",
    "        annual_ret = primary_strategy.mean() * 12\n",
    "        annual_vol = primary_strategy.std() * np.sqrt(12)\n",
    "        rf_annual = rf_monthly.mean() * 12\n",
    "        best_sharpe = (annual_ret - rf_annual) / annual_vol if annual_vol > 0 else 0\n",
    "        print(f\"Fallback strategy stats: Return={annual_ret:.2%}, Vol={annual_vol:.2%}, Sharpe={best_sharpe:.3f}\")\n",
    "\n",
    "print(f\"\\nâœ… Strategy selection complete. Using {len(primary_strategy)} months of data.\")\n",
    "\n",
    "primary_strategy_df = backtest_strategy_v5(adj_close, volume, lookback_months=best_params[1] if best_params else 6, method=best_params[0] if best_params else 'simple', decile=0.3)\n",
    "primary_strategy_df = primary_strategy_df[primary_strategy_df.index > train_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "dce0a4ae",
   "source": [
    "### Market Regime Classification with VIX"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "1c7e0564",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\nðŸŒŠ Enhanced Market Regime Classification\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Align data to strategy timeline\n",
    "strategy_index = primary_strategy_df.index\n",
    "print(f\"Strategy timeline: {strategy_index[0]} to {strategy_index[-1]} ({len(strategy_index)} months)\")\n",
    "\n",
    "# ============================================================\n",
    "# 1. VOLATILITY REGIME CLASSIFICATION (VIX-based, 4 levels)\n",
    "# ============================================================\n",
    "# Use absolute VIX thresholds based on historical norms\n",
    "# VIX < 15: Very Low (complacent market)\n",
    "# VIX 15-20: Low (normal calm)\n",
    "# VIX 20-25: Moderate (elevated uncertainty)\n",
    "# VIX 25-30: High (fear)\n",
    "# VIX > 30: Extreme (panic)\n",
    "\n",
    "vix_aligned = vix_monthly.reindex(strategy_index, method='ffill')\n",
    "vix_aligned = vix_aligned.fillna(vix_monthly.mean())\n",
    "\n",
    "print(f\"\\nðŸ“Š VIX Regime Thresholds (absolute levels):\")\n",
    "print(f\"  Very Low Vol: VIX < 15 (Complacent)\")\n",
    "print(f\"  Low Vol: 15 â‰¤ VIX < 20 (Normal)\")\n",
    "print(f\"  Moderate Vol: 20 â‰¤ VIX < 25 (Elevated)\")\n",
    "print(f\"  High Vol: 25 â‰¤ VIX < 30 (Fear)\")\n",
    "print(f\"  Extreme Vol: VIX â‰¥ 30 (Panic)\")\n",
    "\n",
    "volatility_regime = pd.cut(vix_aligned, \n",
    "                          bins=[0, 15, 20, 25, 30, np.inf], \n",
    "                          labels=['Very Low Vol', 'Low Vol', 'Moderate Vol', 'High Vol', 'Extreme Vol'])\n",
    "\n",
    "# ============================================================\n",
    "# 2. MARKET TREND CLASSIFICATION (Multi-timeframe, 5 levels)\n",
    "# ============================================================\n",
    "# Use both short-term (3m) and long-term (12m) momentum\n",
    "\n",
    "# Calculate rolling returns using FULL historical data\n",
    "xlk_rolling_3m_full = xlk_monthly.rolling(window=3, min_periods=3).apply(lambda x: (1 + x).prod() - 1)\n",
    "xlk_rolling_6m_full = xlk_monthly.rolling(window=6, min_periods=6).apply(lambda x: (1 + x).prod() - 1)\n",
    "xlk_rolling_12m_full = xlk_monthly.rolling(window=12, min_periods=12).apply(lambda x: (1 + x).prod() - 1)\n",
    "\n",
    "# Shift to avoid look-ahead bias\n",
    "xlk_rolling_3m_full = xlk_rolling_3m_full.shift(1)\n",
    "xlk_rolling_6m_full = xlk_rolling_6m_full.shift(1)\n",
    "xlk_rolling_12m_full = xlk_rolling_12m_full.shift(1)\n",
    "\n",
    "# Align to strategy timeline\n",
    "xlk_rolling_3m = xlk_rolling_3m_full.reindex(strategy_index, method='ffill')\n",
    "xlk_rolling_6m = xlk_rolling_6m_full.reindex(strategy_index, method='ffill')\n",
    "xlk_rolling_12m = xlk_rolling_12m_full.reindex(strategy_index, method='ffill')\n",
    "xlk_aligned = xlk_monthly.reindex(strategy_index, method='ffill').fillna(0)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ XLK Rolling Returns (aligned to test period):\")\n",
    "print(f\"  3-month valid: {xlk_rolling_3m.notna().sum()} / {len(xlk_rolling_3m)}\")\n",
    "print(f\"  6-month valid: {xlk_rolling_6m.notna().sum()} / {len(xlk_rolling_6m)}\")\n",
    "print(f\"  12-month valid: {xlk_rolling_12m.notna().sum()} / {len(xlk_rolling_12m)}\")\n",
    "\n",
    "# Market Trend Classification (based on 12-month returns with finer granularity)\n",
    "# Strong Bull: > 20%\n",
    "# Bull: 5% ~ 20%\n",
    "# Sideways: -5% ~ 5%\n",
    "# Bear: -20% ~ -5%\n",
    "# Strong Bear: < -20%\n",
    "\n",
    "def classify_trend_12m(ret_12m):\n",
    "    if pd.isna(ret_12m):\n",
    "        return 'Unknown'\n",
    "    elif ret_12m > 0.20:\n",
    "        return 'Strong Bull'\n",
    "    elif ret_12m > 0.05:\n",
    "        return 'Bull'\n",
    "    elif ret_12m > -0.05:\n",
    "        return 'Sideways'\n",
    "    elif ret_12m > -0.20:\n",
    "        return 'Bear'\n",
    "    else:\n",
    "        return 'Strong Bear'\n",
    "\n",
    "market_regime = xlk_rolling_12m.apply(classify_trend_12m)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Market Trend Thresholds (12-month):\")\n",
    "print(f\"  Strong Bull: > +20%\")\n",
    "print(f\"  Bull: +5% ~ +20%\")\n",
    "print(f\"  Sideways: -5% ~ +5%\")\n",
    "print(f\"  Bear: -20% ~ -5%\")\n",
    "print(f\"  Strong Bear: < -20%\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. SHORT-TERM MOMENTUM CLASSIFICATION (3-month, for timing)\n",
    "# ============================================================\n",
    "def classify_momentum_3m(ret_3m):\n",
    "    if pd.isna(ret_3m):\n",
    "        return 'Unknown'\n",
    "    elif ret_3m > 0.10:\n",
    "        return 'Strong Up'\n",
    "    elif ret_3m > 0.02:\n",
    "        return 'Up'\n",
    "    elif ret_3m > -0.02:\n",
    "        return 'Flat'\n",
    "    elif ret_3m > -0.10:\n",
    "        return 'Down'\n",
    "    else:\n",
    "        return 'Strong Down'\n",
    "\n",
    "short_term_momentum = xlk_rolling_3m.apply(classify_momentum_3m)\n",
    "\n",
    "print(f\"\\nâš¡ Short-term Momentum Thresholds (3-month):\")\n",
    "print(f\"  Strong Up: > +10%\")\n",
    "print(f\"  Up: +2% ~ +10%\")\n",
    "print(f\"  Flat: -2% ~ +2%\")\n",
    "print(f\"  Down: -10% ~ -2%\")\n",
    "print(f\"  Strong Down: < -10%\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. TREND STRENGTH INDICATOR (Combining 3m, 6m, 12m)\n",
    "# ============================================================\n",
    "def calculate_trend_strength(row):\n",
    "    \"\"\"\n",
    "    Count how many timeframes are positive:\n",
    "    - 3 positive = Strong Trend Up\n",
    "    - 2 positive = Trend Up\n",
    "    - 1-2 positive = Mixed\n",
    "    - 0-1 positive = Trend Down\n",
    "    - 0 positive = Strong Trend Down\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    if row['xlk_3m'] > 0: count += 1\n",
    "    if row['xlk_6m'] > 0: count += 1\n",
    "    if row['xlk_12m'] > 0: count += 1\n",
    "    \n",
    "    if count == 3:\n",
    "        return 'Strong Uptrend'\n",
    "    elif count == 2:\n",
    "        return 'Uptrend'\n",
    "    elif count == 1:\n",
    "        return 'Mixed'\n",
    "    else:\n",
    "        return 'Downtrend'\n",
    "\n",
    "trend_df = pd.DataFrame({\n",
    "    'xlk_3m': xlk_rolling_3m,\n",
    "    'xlk_6m': xlk_rolling_6m,\n",
    "    'xlk_12m': xlk_rolling_12m\n",
    "}, index=strategy_index)\n",
    "\n",
    "trend_strength = trend_df.apply(calculate_trend_strength, axis=1)\n",
    "\n",
    "# ============================================================\n",
    "# 5. COMBINED REGIME (Vol + Trend + Momentum)\n",
    "# ============================================================\n",
    "combined_regime = pd.Series(\n",
    "    volatility_regime.astype(str) + \" | \" + market_regime.astype(str) + \" | \" + short_term_momentum.astype(str),\n",
    "    index=strategy_index\n",
    ")\n",
    "\n",
    "# Simplified combined (Vol + Trend only)\n",
    "combined_simple = pd.Series(\n",
    "    volatility_regime.astype(str) + \" + \" + market_regime.astype(str),\n",
    "    index=strategy_index\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# PRINT DISTRIBUTIONS\n",
    "# ============================================================\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š REGIME DISTRIBUTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nðŸŒ¡ï¸ Volatility Regime Distribution (5 levels):\")\n",
    "print(volatility_regime.value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Market Trend Distribution (5 levels):\")\n",
    "trend_order = ['Strong Bull', 'Bull', 'Sideways', 'Bear', 'Strong Bear', 'Unknown']\n",
    "for trend in trend_order:\n",
    "    count = (market_regime == trend).sum()\n",
    "    if count > 0:\n",
    "        print(f\"  {trend:12s}: {count} months\")\n",
    "\n",
    "print(f\"\\nâš¡ Short-term Momentum Distribution (5 levels):\")\n",
    "mom_order = ['Strong Up', 'Up', 'Flat', 'Down', 'Strong Down', 'Unknown']\n",
    "for mom in mom_order:\n",
    "    count = (short_term_momentum == mom).sum()\n",
    "    if count > 0:\n",
    "        print(f\"  {mom:12s}: {count} months\")\n",
    "\n",
    "print(f\"\\nðŸ”„ Trend Strength Distribution (Multi-timeframe):\")\n",
    "print(trend_strength.value_counts())\n",
    "\n",
    "print(f\"\\nðŸ”€ Combined Regime Distribution (Vol + Trend):\")\n",
    "print(combined_simple.value_counts())\n",
    "\n",
    "# Create comprehensive regime dataframe with all new classifications\n",
    "regime_data = pd.DataFrame({\n",
    "    'strategy_returns': primary_strategy_df['strategy_returns'],\n",
    "    'equity_weight': primary_strategy_df['equity_weight'],\n",
    "    'cash_weight': primary_strategy_df['cash_weight'],\n",
    "    'xlk_returns': xlk_aligned,\n",
    "    'spy_returns': spy_monthly.reindex(strategy_index, method='ffill').fillna(0),\n",
    "    'vix_level': vix_aligned,\n",
    "    'volatility_regime': volatility_regime,\n",
    "    'market_regime': market_regime,\n",
    "    'short_term_momentum': short_term_momentum,\n",
    "    'trend_strength': trend_strength,\n",
    "    'combined_regime': combined_simple,  # Use simplified version\n",
    "    'full_regime': combined_regime,  # Full 3-factor version\n",
    "    'xlk_rolling_3m': xlk_rolling_3m,\n",
    "    'xlk_rolling_6m': xlk_rolling_6m,\n",
    "    'xlk_rolling_12m': xlk_rolling_12m\n",
    "}, index=strategy_index)\n",
    "\n",
    "regime_data = regime_data.dropna(subset=['strategy_returns', 'xlk_returns', 'vix_level'])\n",
    "print(f\"\\nâœ… Final dataset: {len(regime_data)} months of complete data\")\n",
    "print(f\"ðŸ“Š Regime dimensions: {regime_data.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "744166be",
   "source": [
    "### Strategy Performance by Market Regime"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "c65c232a",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Strategy Performance by Market Regime\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Performance by Volatility Regime (5 levels)\n",
    "print(\"\\n1ï¸âƒ£ Performance by Volatility Regime (5 levels):\")\n",
    "vol_regimes_present = regime_data['volatility_regime'].dropna().unique()\n",
    "vol_performance = regime_data.groupby('volatility_regime')['strategy_returns'].agg([\n",
    "    'count', 'mean', 'std', \n",
    "    lambda x: (x > 0).mean(),  # win rate\n",
    "    'min', 'max'\n",
    "]).round(4)\n",
    "vol_performance.columns = ['Months', 'Avg_Monthly_Return', 'Volatility', 'Win_Rate', 'Min_Return', 'Max_Return']\n",
    "vol_performance['Annualized_Return'] = (1 + vol_performance['Avg_Monthly_Return']) ** 12 - 1\n",
    "vol_performance['Annualized_Volatility'] = vol_performance['Volatility'] * np.sqrt(12)\n",
    "vol_performance['Sharpe_Ratio'] = vol_performance['Annualized_Return'] / vol_performance['Annualized_Volatility']\n",
    "vol_performance = vol_performance[vol_performance['Months'] > 0]  # Only show regimes with data\n",
    "\n",
    "print(vol_performance[['Months', 'Annualized_Return', 'Annualized_Volatility', 'Sharpe_Ratio', 'Win_Rate']])\n",
    "\n",
    "# 2. Performance by Market Trend (5 levels)\n",
    "print(\"\\n2ï¸âƒ£ Performance by Market Trend (5 levels):\")\n",
    "market_performance = regime_data.groupby('market_regime')['strategy_returns'].agg([\n",
    "    'count', 'mean', 'std', \n",
    "    lambda x: (x > 0).mean(),\n",
    "    'min', 'max'\n",
    "]).round(4)\n",
    "market_performance.columns = ['Months', 'Avg_Monthly_Return', 'Volatility', 'Win_Rate', 'Min_Return', 'Max_Return']\n",
    "market_performance['Annualized_Return'] = (1 + market_performance['Avg_Monthly_Return']) ** 12 - 1\n",
    "market_performance['Annualized_Volatility'] = market_performance['Volatility'] * np.sqrt(12)\n",
    "market_performance['Sharpe_Ratio'] = market_performance['Annualized_Return'] / market_performance['Annualized_Volatility']\n",
    "market_performance = market_performance[market_performance['Months'] > 0]\n",
    "\n",
    "print(market_performance[['Months', 'Annualized_Return', 'Annualized_Volatility', 'Sharpe_Ratio', 'Win_Rate']])\n",
    "\n",
    "# 3. Performance by Short-term Momentum\n",
    "print(\"\\n3ï¸âƒ£ Performance by Short-term Momentum (3-month):\")\n",
    "if 'short_term_momentum' in regime_data.columns:\n",
    "    momentum_performance = regime_data.groupby('short_term_momentum')['strategy_returns'].agg([\n",
    "        'count', 'mean', 'std', \n",
    "        lambda x: (x > 0).mean()\n",
    "    ]).round(4)\n",
    "    momentum_performance.columns = ['Months', 'Avg_Monthly_Return', 'Volatility', 'Win_Rate']\n",
    "    momentum_performance['Annualized_Return'] = (1 + momentum_performance['Avg_Monthly_Return']) ** 12 - 1\n",
    "    momentum_performance = momentum_performance[momentum_performance['Months'] > 0]\n",
    "    momentum_performance = momentum_performance.sort_values('Annualized_Return', ascending=False)\n",
    "    print(momentum_performance)\n",
    "\n",
    "# 4. Performance by Trend Strength (Multi-timeframe)\n",
    "print(\"\\n4ï¸âƒ£ Performance by Trend Strength (Multi-timeframe):\")\n",
    "if 'trend_strength' in regime_data.columns:\n",
    "    trend_performance = regime_data.groupby('trend_strength')['strategy_returns'].agg([\n",
    "        'count', 'mean', 'std', \n",
    "        lambda x: (x > 0).mean()\n",
    "    ]).round(4)\n",
    "    trend_performance.columns = ['Months', 'Avg_Monthly_Return', 'Volatility', 'Win_Rate']\n",
    "    trend_performance['Annualized_Return'] = (1 + trend_performance['Avg_Monthly_Return']) ** 12 - 1\n",
    "    trend_performance = trend_performance[trend_performance['Months'] > 0]\n",
    "    trend_performance = trend_performance.sort_values('Annualized_Return', ascending=False)\n",
    "    print(trend_performance)\n",
    "\n",
    "# 5. Combined Regime Analysis (Vol + Trend)\n",
    "print(\"\\n5ï¸âƒ£ Performance by Combined Regime (Vol + Trend):\")\n",
    "combined_performance = regime_data.groupby('combined_regime')['strategy_returns'].agg([\n",
    "    'count', 'mean', 'std', \n",
    "    lambda x: (x > 0).mean()\n",
    "]).round(4)\n",
    "combined_performance.columns = ['Months', 'Avg_Monthly_Return', 'Volatility', 'Win_Rate']\n",
    "combined_performance['Annualized_Return'] = (1 + combined_performance['Avg_Monthly_Return']) ** 12 - 1\n",
    "combined_performance = combined_performance[combined_performance['Months'] > 0]\n",
    "combined_performance = combined_performance.sort_values('Annualized_Return', ascending=False)\n",
    "\n",
    "print(combined_performance)\n",
    "\n",
    "# 6. Statistical Significance Tests\n",
    "print(\"\\n6ï¸âƒ£ Statistical Significance Tests:\")\n",
    "for regime_type in regime_data['volatility_regime'].unique():\n",
    "    if pd.notna(regime_type):\n",
    "        subset = regime_data[regime_data['volatility_regime'] == regime_type]['strategy_returns']\n",
    "        if len(subset) >= 3:  # Relaxed minimum samples\n",
    "            t_stat, p_value = ttest_1samp(subset, 0)\n",
    "            significance = \"***\" if p_value < 0.01 else \"**\" if p_value < 0.05 else \"*\" if p_value < 0.1 else \"\"\n",
    "            print(f\"  {regime_type}: t-stat={t_stat:.2f}, p-value={p_value:.4f} {significance}\")\n",
    "\n",
    "# 7. Key Insights Summary\n",
    "print(\"\\n7ï¸âƒ£ Key Insights Summary:\")\n",
    "# Best performing regime\n",
    "if len(combined_performance) > 0:\n",
    "    best_regime = combined_performance['Annualized_Return'].idxmax()\n",
    "    best_return = combined_performance.loc[best_regime, 'Annualized_Return']\n",
    "    print(f\"  ðŸ† Best Regime: {best_regime} (Ann. Return: {best_return:.2%})\")\n",
    "\n",
    "# Worst performing regime\n",
    "if len(combined_performance) > 0:\n",
    "    worst_regime = combined_performance['Annualized_Return'].idxmin()\n",
    "    worst_return = combined_performance.loc[worst_regime, 'Annualized_Return']\n",
    "    print(f\"  âš ï¸ Worst Regime: {worst_regime} (Ann. Return: {worst_return:.2%})\")\n",
    "\n",
    "# 8. Momentum Effectiveness Analysis\n",
    "print(\"\\n8ï¸âƒ£ Momentum Effectiveness by Market Condition:\")\n",
    "print(\"\\nCorrelation between Strategy Returns and Market Returns:\")\n",
    "for regime in regime_data['market_regime'].unique():\n",
    "    subset = regime_data[regime_data['market_regime'] == regime]\n",
    "    if len(subset) >= 3:\n",
    "        corr = subset['strategy_returns'].corr(subset['xlk_returns'])\n",
    "        print(f\"  {regime}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\nStrategy Beta (relative to XLK) by Volatility Regime:\")\n",
    "for regime in regime_data['volatility_regime'].unique():\n",
    "    if pd.notna(regime):\n",
    "        subset = regime_data[regime_data['volatility_regime'] == regime]\n",
    "        if len(subset) > 10:\n",
    "            # Simple beta calculation\n",
    "            covariance = subset['strategy_returns'].cov(subset['xlk_returns'])\n",
    "            market_variance = subset['xlk_returns'].var()\n",
    "            beta = covariance / market_variance if market_variance > 0 else 0\n",
    "            print(f\"  {regime}: {beta:.3f}\")\n",
    "\n",
    "# 9. Cash Allocation by Regime\n",
    "print(\"\\n9ï¸âƒ£ Cash Allocation by Regime:\")\n",
    "if 'equity_weight' in regime_data.columns:\n",
    "    cash_by_regime = regime_data.groupby('combined_regime')['equity_weight'].mean().sort_values(ascending=False)\n",
    "    print(cash_by_regime.rename('avg_equity_weight'))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "d49ab129",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# V5 VIX Regime Analysis\n",
    "vix_daily = adj_close['^VIX'] if '^VIX' in adj_close.columns else pd.Series(dtype=float)\n",
    "vix3m_daily = adj_close['^VIX3M'] if '^VIX3M' in adj_close.columns else None\n",
    "\n",
    "# Compute regimes for all months\n",
    "month_ends = adj_close.resample('M').last().index\n",
    "regimes = []\n",
    "prev_r = 'Normal'\n",
    "for me in month_ends:\n",
    "    r, w = compute_monthly_vix_regime(vix_daily, vix3m_daily, me, prev_regime=prev_r)\n",
    "    regimes.append({'date': me, 'regime': r, 'w_vix': w})\n",
    "    prev_r = r\n",
    "\n",
    "regime_df = pd.DataFrame(regimes).set_index('date')\n",
    "print(\"VIX Regime Distribution:\")\n",
    "print(regime_df['regime'].value_counts())\n",
    "print(f\"\\nRegime timeline (last 12 months):\")\n",
    "print(regime_df.tail(12))\n",
    "\n",
    "# If VIX3M available, show term structure stats\n",
    "if vix3m_daily is not None and '^VIX3M' in adj_close.columns:\n",
    "    ratio = (adj_close['^VIX'] / adj_close['^VIX3M']).dropna()\n",
    "    print(f\"\\nVIX/VIX3M ratio stats:\")\n",
    "    print(f\"  Mean: {ratio.mean():.3f}\")\n",
    "    print(f\"  Median: {ratio.median():.3f}\")\n",
    "    print(f\"  Days in backwardation (>1.0): {(ratio > 1.0).sum()} ({(ratio > 1.0).mean():.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "fba18f32",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Regime color timeline\n",
    "regime_colors = {'Normal': 'green', 'Elevated': 'orange', 'Panic': 'red'}\n",
    "fig = go.Figure()\n",
    "\n",
    "for regime_name, color in regime_colors.items():\n",
    "    mask = regime_df['regime'] == regime_name\n",
    "    subset = regime_df[mask]\n",
    "    if len(subset) > 0:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=subset.index,\n",
    "            y=subset['w_vix'],\n",
    "            mode='markers',\n",
    "            name=regime_name,\n",
    "            marker=dict(color=color, size=8),\n",
    "        ))\n",
    "\n",
    "# Add VIX line on secondary axis\n",
    "vix_monthly = adj_close['^VIX'].resample('M').last() if '^VIX' in adj_close.columns else pd.Series(dtype=float)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=vix_monthly.index, y=vix_monthly.values,\n",
    "    mode='lines', name='VIX (monthly)',\n",
    "    yaxis='y2', line=dict(color='gray', dash='dot'),\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='V5 VIX Regime Classification Timeline',\n",
    "    yaxis=dict(title='w_vix (Position Weight)'),\n",
    "    yaxis2=dict(title='VIX Level', overlaying='y', side='right'),\n",
    "    template='plotly_white',\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "3b01f487",
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "487aa854",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "viz_index = best_strategy_v5_df.index.intersection(best_strategy_v3_df.index)\n",
    "cum_df = pd.DataFrame({\n",
    "    'V5': best_v5_returns.reindex(viz_index, fill_value=0.0),\n",
    "    'V3': best_v3_returns.reindex(viz_index, fill_value=0.0),\n",
    "    'XLK': xlk_monthly_returns.reindex(viz_index, method='ffill').fillna(0.0),\n",
    "    'SPY': spy_monthly_returns.reindex(viz_index, method='ffill').fillna(0.0),\n",
    "}).dropna()\n",
    "\n",
    "cum = (1 + cum_df).cumprod() - 1\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=cum.index, y=cum['V5'], mode='lines', name='V5 Best'))\n",
    "fig.add_trace(go.Scatter(x=cum.index, y=cum['V3'], mode='lines', name='V3 Best'))\n",
    "fig.add_trace(go.Scatter(x=cum.index, y=cum['XLK'], mode='lines', name='XLK'))\n",
    "fig.add_trace(go.Scatter(x=cum.index, y=cum['SPY'], mode='lines', name='SPY'))\n",
    "fig.update_layout(title='Cumulative Returns: V5 vs V3 vs XLK vs SPY', yaxis_title='Cumulative Return', template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "224d5581",
   "execution_count": null,
   "outputs": [],
   "source": [
    "roll_12m_v5 = (1 + best_v5_returns).rolling(12).apply(np.prod, raw=True) - 1\n",
    "roll_12m_v3 = (1 + best_v3_returns).rolling(12).apply(np.prod, raw=True) - 1\n",
    "roll_12m_xlk = (1 + xlk_monthly_returns.reindex(best_v5_returns.index, method='ffill').fillna(0.0)).rolling(12).apply(np.prod, raw=True) - 1\n",
    "vix_monthly = adj_close['^VIX'].resample('M').last() if '^VIX' in adj_close.columns else pd.Series(index=best_v5_returns.index, dtype=float)\n",
    "vix_plot = vix_monthly.reindex(best_v5_returns.index, method='ffill')\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "fig.add_trace(go.Scatter(x=roll_12m_v5.index, y=roll_12m_v5, mode='lines', name='V5 12M'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=roll_12m_v3.index, y=roll_12m_v3, mode='lines', name='V3 12M'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=roll_12m_xlk.index, y=roll_12m_xlk, mode='lines', name='XLK 12M'), secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=vix_plot.index, y=vix_plot, mode='lines', name='VIX', line=dict(dash='dot')), secondary_y=True)\n",
    "fig.update_layout(title='Rolling 12M Returns with VIX Overlay', template='plotly_white')\n",
    "fig.update_yaxes(title_text='Rolling 12M Return', secondary_y=False)\n",
    "fig.update_yaxes(title_text='VIX', secondary_y=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "1801e769",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alloc_df_v5 = best_strategy_v5_df[['equity_weight', 'cash_weight']].copy()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=alloc_df_v5.index,\n",
    "    y=alloc_df_v5['equity_weight'],\n",
    "    mode='lines',\n",
    "    stackgroup='one',\n",
    "    name='Equity Weight'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=alloc_df_v5.index,\n",
    "    y=alloc_df_v5['cash_weight'],\n",
    "    mode='lines',\n",
    "    stackgroup='one',\n",
    "    name='Cash Weight'\n",
    "))\n",
    "fig.update_layout(title='V5 Dynamic Allocation Over Time', yaxis_title='Portfolio Weight', template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "48a7e35e",
   "execution_count": null,
   "outputs": [],
   "source": [
    "heat_df = holding_period_results_v5.pivot(index='method', columns='holding_period', values='sharpe')\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=heat_df.values,\n",
    "    x=heat_df.columns.astype(str),\n",
    "    y=heat_df.index,\n",
    "    colorscale='RdYlGn',\n",
    "    colorbar=dict(title='Sharpe')\n",
    "))\n",
    "fig.update_layout(title='V5 Holding Period Grid Search Heatmap (Sharpe)', xaxis_title='Holding Period (months)', yaxis_title='Method', template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "id": "5459d054",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alloc_v5 = best_strategy_v5_df[['equity_weight', 'cash_weight']].copy()\n",
    "alloc_v3 = best_strategy_v3_df[['equity_weight', 'cash_weight']].copy()\n",
    "\n",
    "common_idx = alloc_v5.index.intersection(alloc_v3.index)\n",
    "alloc_v5 = alloc_v5.reindex(common_idx).ffill().fillna(0.0)\n",
    "alloc_v3 = alloc_v3.reindex(common_idx).ffill().fillna(0.0)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('V5 Allocation', 'V3 Allocation'))\n",
    "fig.add_trace(go.Scatter(x=alloc_v5.index, y=alloc_v5['equity_weight'], mode='lines', stackgroup='one', name='V5 Equity', showlegend=True), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=alloc_v5.index, y=alloc_v5['cash_weight'], mode='lines', stackgroup='one', name='V5 Cash', showlegend=True), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=alloc_v3.index, y=alloc_v3['equity_weight'], mode='lines', stackgroup='one', name='V3 Equity', showlegend=True), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=alloc_v3.index, y=alloc_v3['cash_weight'], mode='lines', stackgroup='one', name='V3 Cash', showlegend=True), row=1, col=2)\n",
    "fig.update_layout(title='V5 vs V3 Allocation Comparison', yaxis_title='Portfolio Weight', template='plotly_white')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}